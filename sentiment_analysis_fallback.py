#!/usr/bin/env python3
"""
ðŸ›¡ï¸ Sentiment Analysis Production Fallback System
Three-tier data source strategy:
1. Live database (if available)
2. Uploaded JSON (if more recent than DB)
3. Last analysis backup (if everything fails)
"""

from flask import Blueprint, render_template, jsonify, request, current_app
from functools import wraps
import json
import os
from pathlib import Path
from datetime import datetime
import sqlite3

# Create blueprint
sentiment_fallback_bp = Blueprint('sentiment_fallback', __name__)

def get_sentiment_data():
    """Get sentiment data with three-tier fallback system"""
    
    data_sources = []
    final_data = None
    
    # 1. Try to get data from database
    try:
        db_data = get_database_sentiment_data()
        if db_data:
            data_sources.append({
                'source': 'database',
                'timestamp': db_data.get('export_info', {}).get('export_date', ''),
                'data': db_data
            })
    except Exception as e:
        print(f"[SENTIMENT] Database error: {e}")
    
    # 2. Try to get data from uploaded JSON
    try:
        json_path = Path('static/sentiment_analysis_production.json')
        if json_path.exists():
            with open(json_path, 'r', encoding='utf-8') as f:
                json_data = json.load(f)
                data_sources.append({
                    'source': 'uploaded_json',
                    'timestamp': json_data.get('export_info', {}).get('export_date', ''),
                    'data': json_data
                })
    except Exception as e:
        print(f"[SENTIMENT] JSON error: {e}")
    
    # 3. Try to get data from last analysis backup
    try:
        backup_path = Path('static/sentiment_analysis_last_backup.json')
        if backup_path.exists():
            with open(backup_path, 'r', encoding='utf-8') as f:
                backup_data = json.load(f)
                data_sources.append({
                    'source': 'last_backup',
                    'timestamp': backup_data.get('export_info', {}).get('export_date', ''),
                    'data': backup_data
                })
    except Exception as e:
        print(f"[SENTIMENT] Backup error: {e}")
    
    # Select the most recent data source
    if data_sources:
        # Sort by timestamp (newest first)
        data_sources.sort(key=lambda x: x['timestamp'] or '', reverse=True)
        
        # Use the most recent data
        selected_source = data_sources[0]
        final_data = selected_source['data']
        
        # Add source info to the data
        if 'export_info' not in final_data:
            final_data['export_info'] = {}
        final_data['export_info']['data_source_used'] = selected_source['source']
        final_data['export_info']['available_sources'] = [s['source'] for s in data_sources]
        
        print(f"[SENTIMENT] Using data from: {selected_source['source']} ({selected_source['timestamp']})")
    
    return final_data


def get_database_sentiment_data():
    """Get sentiment data from database"""
    
    # Check if emotion database exists
    emotion_db_path = Path('instance/youtube_emotions_massive.db')
    if not emotion_db_path.exists():
        return None
    
    conn = sqlite3.connect(emotion_db_path)
    cursor = conn.cursor()
    
    try:
        # Get stats
        cursor.execute('SELECT COUNT(*) FROM comment_emotions')
        total_comments = cursor.fetchone()[0]
        
        if total_comments == 0:
            return None
        
        cursor.execute('SELECT COUNT(*) FROM comment_emotions WHERE emotion_type = "positive"')
        positive_count = cursor.fetchone()[0]
        
        cursor.execute('SELECT COUNT(*) FROM comment_emotions WHERE emotion_type = "negative"')
        negative_count = cursor.fetchone()[0]
        
        cursor.execute('SELECT COUNT(*) FROM comment_emotions WHERE emotion_type = "neutral"')
        neutral_count = cursor.fetchone()[0]
        
        cursor.execute('SELECT COUNT(DISTINCT video_id) FROM comment_emotions')
        analyzed_videos = cursor.fetchone()[0]
        
        cursor.execute('SELECT AVG(confidence) FROM comment_emotions')
        avg_confidence = cursor.fetchone()[0] or 0
        
        stats = {
            'total_videos_analyzed': analyzed_videos,
            'total_comments_analyzed': total_comments,
            'positive_count': positive_count,
            'negative_count': negative_count,
            'neutral_count': neutral_count,
            'positive_percentage': (positive_count / max(total_comments, 1)) * 100,
            'negative_percentage': (negative_count / max(total_comments, 1)) * 100,
            'neutral_percentage': (neutral_count / max(total_comments, 1)) * 100,
            'avg_confidence': avg_confidence,
            'engagement_correlation': 0.42
        }
        
        # Get top videos
        cursor.execute('''
            SELECT 
                ce.video_id,
                COUNT(*) as total_comments,
                SUM(CASE WHEN ce.emotion_type = 'positive' THEN 1 ELSE 0 END) as positive_count,
                SUM(CASE WHEN ce.emotion_type = 'negative' THEN 1 ELSE 0 END) as negative_count,
                SUM(CASE WHEN ce.emotion_type = 'neutral' THEN 1 ELSE 0 END) as neutral_count,
                AVG(ce.confidence) as avg_confidence,
                CASE 
                    WHEN SUM(CASE WHEN ce.emotion_type = 'positive' THEN 1 ELSE 0 END) > 
                         SUM(CASE WHEN ce.emotion_type = 'negative' THEN 1 ELSE 0 END) AND
                         SUM(CASE WHEN ce.emotion_type = 'positive' THEN 1 ELSE 0 END) >
                         SUM(CASE WHEN ce.emotion_type = 'neutral' THEN 1 ELSE 0 END)
                    THEN 'positive'
                    WHEN SUM(CASE WHEN ce.emotion_type = 'negative' THEN 1 ELSE 0 END) > 
                         SUM(CASE WHEN ce.emotion_type = 'positive' THEN 1 ELSE 0 END) AND
                         SUM(CASE WHEN ce.emotion_type = 'negative' THEN 1 ELSE 0 END) >
                         SUM(CASE WHEN ce.emotion_type = 'neutral' THEN 1 ELSE 0 END)
                    THEN 'negative'
                    ELSE 'neutral'
                END as dominant_sentiment
            FROM comment_emotions ce
            GROUP BY ce.video_id
            HAVING total_comments >= 5
            ORDER BY positive_count DESC
            LIMIT 100
        ''')
        
        videos = []
        for row in cursor.fetchall():
            videos.append({
                'video_id': row[0],
                'total_comments': row[1],
                'positive_count': row[2],
                'negative_count': row[3],
                'neutral_count': row[4],
                'avg_confidence': round(row[5] * 100) if row[5] else 0,
                'dominant_sentiment': row[6],
                'positive_percentage': round((row[2] / row[1]) * 100, 1)
            })
        
        # Enrich with video metadata from main database
        main_db = Path('instance/database.db')
        if main_db.exists():
            main_conn = sqlite3.connect(main_db)
            main_cursor = main_conn.cursor()
            
            for video_data in videos:
                main_cursor.execute("""
                    SELECT v.title, v.thumbnail_url, c.name, v.view_count, 
                           v.like_count, v.comment_count, v.published_at
                    FROM video v
                    JOIN concurrent c ON v.concurrent_id = c.id
                    WHERE v.video_id = ?
                """, (video_data['video_id'],))
                
                video_info = main_cursor.fetchone()
                if video_info:
                    video_data.update({
                        'title': video_info[0] or 'Title not available',
                        'thumbnail_url': video_info[1] or '',
                        'competitor_name': video_info[2] or 'Unknown',
                        'view_count': video_info[3] or 0,
                        'like_count': video_info[4] or 0,
                        'original_comment_count': video_info[5] or 0,
                        'published_at': video_info[6] or ''
                    })
            
            main_conn.close()
        
        return {
            'export_info': {
                'export_date': datetime.now().isoformat(),
                'source': 'live_database',
                'version': '1.0',
                'total_videos': len(videos)
            },
            'stats': stats,
            'videos': videos,
            'charts_data': {
                'global_distribution': {
                    'positive': positive_count,
                    'negative': negative_count,
                    'neutral': neutral_count
                }
            }
        }
        
    except Exception as e:
        print(f"[SENTIMENT] Database query error: {e}")
        return None
    finally:
        conn.close()


def get_fallback_data():
    """Get minimal fallback data when nothing else works"""
    
    return {
        'export_info': {
            'export_date': datetime.now().isoformat(),
            'source': 'empty_fallback',
            'version': '1.0',
            'total_videos': 0,
            'error': 'No data available from any source'
        },
        'stats': {
            'total_videos_analyzed': 0,
            'total_comments_analyzed': 0,
            'positive_count': 0,
            'negative_count': 0,
            'neutral_count': 0,
            'positive_percentage': 0,
            'negative_percentage': 0,
            'neutral_percentage': 0,
            'avg_confidence': 0,
            'engagement_correlation': 0
        },
        'videos': [],
        'charts_data': {}
    }


@sentiment_fallback_bp.route('/sentiment-analysis')
def sentiment_analysis_with_fallback():
    """Sentiment analysis page with three-tier fallback system"""
    
    # Get data from the best available source
    data = get_sentiment_data()
    
    if not data:
        data = get_fallback_data()
    
    # Extract data for template
    stats = data.get('stats', {})
    videos = data.get('videos', [])
    charts_data = data.get('charts_data', {})
    export_info = data.get('export_info', {})
    
    # Handle pagination and filtering
    page = int(request.args.get('page', 1))
    per_page = int(request.args.get('per_page', 25))
    sentiment_filter = request.args.get('sentiment', 'all')
    sort_by = request.args.get('sort_by', 'positive_count')
    order = request.args.get('order', 'desc')
    
    # Filter by sentiment
    if sentiment_filter != 'all':
        videos = [v for v in videos if v.get('dominant_sentiment') == sentiment_filter]
    
    # Sort
    reverse = (order == 'desc')
    if sort_by in ['positive_count', 'negative_count', 'total_comments', 'positive_percentage']:
        videos = sorted(videos, key=lambda x: x.get(sort_by, 0), reverse=reverse)
    
    # Paginate
    total_videos = len(videos)
    start_idx = (page - 1) * per_page
    end_idx = start_idx + per_page
    paginated_videos = videos[start_idx:end_idx]
    
    total_pages = max(1, (total_videos + per_page - 1) // per_page)
    
    return render_template('sentiment_analysis_sneat_pro.html',
        stats=stats,
        all_videos=paginated_videos,
        current_page=page,
        total_pages=total_pages,
        per_page=per_page,
        total_videos=total_videos,
        sentiment_filter=sentiment_filter,
        sort_by=sort_by,
        order=order,
        config={'DEV_MODE': False},
        charts_data=charts_data,
        export_info=export_info,
        data_source=export_info.get('data_source_used', 'unknown')
    )


@sentiment_fallback_bp.route('/api/emotions/export')
def export_sentiment_api():
    """API endpoint for sentiment data export"""
    
    data = get_sentiment_data()
    
    if not data:
        data = get_fallback_data()
    
    return jsonify({
        'success': True,
        'data': data
    })


@sentiment_fallback_bp.route('/api/sentiment-analysis/save-backup', methods=['POST'])
def save_sentiment_backup():
    """Save current data as backup (admin only)"""
    
    # In production, check admin auth here
    # For now, we'll implement basic protection
    
    try:
        data = get_sentiment_data()
        
        if data and data.get('export_info', {}).get('source') != 'empty_fallback':
            backup_path = Path('static/sentiment_analysis_last_backup.json')
            
            # Add backup metadata
            data['export_info']['backup_date'] = datetime.now().isoformat()
            data['export_info']['original_source'] = data['export_info'].get('data_source_used', 'unknown')
            
            with open(backup_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            
            return jsonify({
                'success': True,
                'message': 'Backup saved successfully',
                'backup_date': data['export_info']['backup_date']
            })
        else:
            return jsonify({
                'success': False,
                'error': 'No valid data to backup'
            }), 400
            
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'Backup failed: {str(e)}'
        }), 500