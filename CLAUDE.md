# YT Channel Analyzer - Structure du Projet

## Vue d'ensemble
Application Flask d'analyse de cha√Ænes YouTube avec syst√®me de classification s√©mantique et d'analyse concurrentielle.

## üèóÔ∏è Architecture D√©veloppement vs Production - S√âPARATION DES ENVIRONNEMENTS

### ‚ö†Ô∏è PRINCIPE FONDAMENTAL : DEV AVEC ML, PRODUCTION L√âG√àRE

**Architecture duale** : D√©veloppement local avec tous les mod√®les ML, production avec affichage uniquement.

#### üî¨ **Environnement D√âVELOPPEMENT**
- **Mod√®les ML activ√©s** : sentence-transformers, torch, classifications s√©mantiques
- **Calculs complets** : Entra√Ænement, analyse, classification automatique
- **Base compl√®te** : Toutes les fonctionnalit√©s disponibles
- **Performance** : Acceptable car ressources locales d√©di√©es

#### üöÄ **Environnement PRODUCTION**
- **ML d√©sactiv√©** : Aucun t√©l√©chargement de mod√®les (438MB+ √©vit√©s)
- **Mode patterns** : Classification par mots-cl√©s multilingues uniquement
- **Affichage rapide** : Interface utilisateur r√©active
- **S√©curit√©** : Impossible de charger accidentellement les mod√®les

### üîß Configuration par Variables d'Environnement

#### Fichiers de configuration
- **`.env.development`** : `YTA_ENVIRONMENT=development`, `YTA_ENABLE_ML=true`
- **`.env.production`** : `YTA_ENVIRONMENT=production`, `YTA_ENABLE_ML=false`
- **`config.py`** : Gestionnaire centralis√© des configurations

#### Variables d'environnement cl√©s
```bash
# Mode de fonctionnement
YTA_ENVIRONMENT=production          # development | production
YTA_ENABLE_ML=false                # true | false

# S√©curit√© production (emp√™che t√©l√©chargements)
TRANSFORMERS_OFFLINE=1
HF_HUB_OFFLINE=1
```

### üöÄ Scripts de D√©marrage

#### D√©veloppement local
```bash
# Avec script d√©di√©
python run_development.py

# Ou avec variables
YTA_ENVIRONMENT=development YTA_ENABLE_ML=true python app.py
```

#### Production (Passenger)
```python
# passenger_wsgi_production.py
os.environ['YTA_ENVIRONMENT'] = 'production'
os.environ['YTA_ENABLE_ML'] = 'false'

# Force la d√©sactivation avant import
sys.modules['sentence_transformers'] = None
sys.modules['transformers'] = None
sys.modules['torch'] = None
```

### üîí **CONFIGURATION PASSENGER WSGI FONCTIONNELLE - NE PAS MODIFIER**

**‚ö†Ô∏è IMPORTANT : Cette configuration est la SEULE qui fonctionne en production sur cPanel/Passenger**

```python
import sys
import os

# Configuration du path
sys.path.insert(0, os.path.dirname(__file__))

# Forcer l'environnement production et d√©sactiver les mod√®les ML
os.environ['YTA_ENVIRONMENT'] = 'production'
os.environ['YTA_ENABLE_ML'] = 'false'
os.environ['TRANSFORMERS_OFFLINE'] = '1'
os.environ['HF_HUB_OFFLINE'] = '1'
os.environ['DISABLE_ML_MODELS'] = '1'

from dotenv import load_dotenv
# Charger le fichier .env.production
load_dotenv(os.path.join(os.path.dirname(__file__), '.env.production'))

from app import app

# Configuration compl√®te des sessions
app.config.update(
    SECRET_KEY=os.environ.get('FLASK_SECRET_KEY', 'your-flask-secret-key-unique-change-me-2025'),
    SESSION_COOKIE_NAME='ytanalyzer_session',
    SESSION_COOKIE_HTTPONLY=True,
    SESSION_COOKIE_SECURE=False,  # True si vous avez HTTPS
    SESSION_COOKIE_SAMESITE='Lax',
    PERMANENT_SESSION_LIFETIME=3600,
    SESSION_TYPE='filesystem',
    PERMANENT_SESSION=True
)

# Importer et enregistrer TOUS les blueprints
from blueprints.main import main_bp
from blueprints.auth import auth_bp
from blueprints.competitors import competitors_bp
from blueprints.admin import admin_bp
from blueprints.api import api_bp
from blueprints.insights import insights_bp
from yt_channel_analyzer.sentiment_pipeline.emotion_api import emotion_api
from yt_channel_analyzer.sentiment_pipeline.batch_api import batch_api

app.register_blueprint(main_bp)
app.register_blueprint(auth_bp)
app.register_blueprint(competitors_bp)
app.register_blueprint(admin_bp)
app.register_blueprint(api_bp)
app.register_blueprint(insights_bp)
app.register_blueprint(emotion_api)
app.register_blueprint(batch_api)

# Gestionnaire d'erreur simple pour debug
@app.errorhandler(500)
def internal_error(error):
    return """
    <h1>Erreur 500</h1>
    <p>Une erreur s'est produite. V√©rifiez les logs.</p>
    <a href="/login">Retour au login</a>
    """, 500

# IMPORTANT pour Passenger
application = app.wsgi_app
```

**üìå Notes importantes :**
- **NE PAS** utiliser `create_app()` - importer directement `app`
- **TOUS** les blueprints doivent √™tre import√©s et enregistr√©s manuellement
- La ligne finale `application = app.wsgi_app` est CRUCIALE pour Passenger
- Les variables d'environnement ML doivent √™tre d√©finies AVANT tout import

### üõ°Ô∏è Protection dans le Code

#### Classification.py - V√©rification automatique
```python
def _init_semantic_classifier(self):
    # V√©rification de la configuration avant tout chargement
    from config import config
    if not config.should_load_ml_models():
        print(f"üö´ Mod√®les ML d√©sactiv√©s (env: {config.ENVIRONMENT})")
        self.semantic_classifier = None
        return
```

#### D√©tection automatique d'environnement
1. **Variable explicite** : `YTA_ENVIRONMENT=production`
2. **Fallback environnement** : `YTA_ENABLE_ML=false`
3. **Protection r√©seau** : `TRANSFORMERS_OFFLINE=1`

### üìã Workflow Recommand√©

1. **üî¨ D√©veloppement local** : Tous calculs ML, classifications, entra√Ænements
2. **üìä Export des r√©sultats** : Classifications sauv√©es en base avec `classification_source`
3. **üöÄ D√©ploiement production** : Interface rapide utilisant les r√©sultats pr√©-calcul√©s
4. **üîÑ Synchronisation** : Base de donn√©es commune entre dev et prod

### ‚úÖ Avantages de cette Architecture

- **Performance production** : Chargement instantan√© (0s vs 40s)
- **D√©veloppement complet** : Tous les outils ML disponibles localement
- **S√©curit√©** : Impossible de charger les mod√®les en production
- **Maintenance** : Configuration centralis√©e via variables d'environnement
- **Flexibilit√©** : Basculement facile entre les modes

## üß† Hi√©rarchie de Classification - R√àGLE ABSOLUE

### ‚ö†Ô∏è PRIORIT√â ABSOLUE : HUMAIN > SENTENCE TRANSFORMER > PATTERNS

Cette hi√©rarchie est **FONDAMENTALE** et doit √™tre respect√©e dans **TOUS** les syst√®mes de classification :

1. **ü•á HUMAIN** (Priorit√© absolue)
   - `is_human_validated = 1` ET `classification_source = 'human'`
   - **INTOUCHABLE** : Jamais √©cras√© par l'IA ou les patterns
   - Source de v√©rit√© absolue pour l'entra√Ænement des mod√®les
   - "Ce que je fais √† la main est sup√©rieur aux sentence transformers, sup√©rieur aux patterns √† la noix"

2. **ü•à SENTENCE TRANSFORMER** (Priorit√© secondaire)
   - `classification_source = 'semantic'` ou `'ai'`
   - Utilise les embeddings s√©mantiques pour comprendre le sens
   - Peut √™tre √©cras√© par une validation humaine
   - Plus intelligent que les patterns de mots-cl√©s

3. **ü•â PATTERNS** (Priorit√© tertiaire)
   - `classification_source = 'keyword'` ou `'auto'`
   - R√®gles bas√©es sur des mots-cl√©s multilingues
   - Fallback quand les autres m√©thodes √©chouent
   - "Patterns √† la noix" mais utiles pour du volume

### üîí Protection des Classifications Humaines

#### ‚≠ê **CLASSIFICATION SUPERVIS√âE MANUELLE - 49 PLAYLISTS VALID√âES**

**TRAVAIL HUMAIN PR√âSERV√â** : 49 playlists classifi√©es manuellement et propag√©es aux vid√©os :
- **9 HERO** playlists ‚Üí vid√©os de marque/inspiration  
- **28 HUB** playlists ‚Üí contenu √©ducatif/engageant
- **12 HELP** playlists ‚Üí contenu d'aide/support

**Propagation automatique** : Les cat√©gories des playlists sont propag√©es aux 1291 vid√©os associ√©es
```sql
-- V√©rification du travail humain pr√©serv√©
SELECT COUNT(*) FROM playlist WHERE classification_source = 'human';  -- 49 playlists
SELECT COUNT(*) FROM video WHERE classification_source = 'human' OR classification_source LIKE '%propagat%';  -- 1291 vid√©os
```

#### Dans le code :
```python
# ‚úÖ CORRECT : V√©rifier la protection humaine (OBLIGATOIRE)
if is_human_validated != 1 and classification_source != 'human':
    # Seulement alors on peut reclassifier
    
# ‚≠ê PR√âSERVER : R√©cup√©ration des classifications humaines
def get_hhh_distribution(competitor_id):
    # Les vid√©os ont d√©j√† les cat√©gories propag√©es depuis les playlists manuelles
    cursor.execute("""
        SELECT 
            COUNT(CASE WHEN v.category = 'hero' THEN 1 END) as hero_count,
            COUNT(CASE WHEN v.category = 'hub' THEN 1 END) as hub_count,
            COUNT(CASE WHEN v.category = 'help' THEN 1 END) as help_count,
            COUNT(CASE WHEN v.category IS NOT NULL THEN 1 END) as categorized_videos
        FROM video v WHERE v.concurrent_id = ?
    """, (competitor_id,))
    
# ‚ùå INTERDIT : √âcraser les classifications humaines
UPDATE video SET category = ? WHERE classification_source = 'human'  -- JAMAIS !
```

#### Dans les requ√™tes SQL :
```sql
-- ‚úÖ CORRECT : Exclure les validations humaines des re-classifications
WHERE (is_human_validated = 0 OR is_human_validated IS NULL)
AND (classification_source != 'human' OR classification_source IS NULL)

-- ‚≠ê R√âCUP√âRATION : Utiliser les classifications propag√©es
SELECT v.category FROM video v WHERE v.concurrent_id = ?  -- Categories d√©j√† propag√©es

-- ‚ùå INTERDIT : Ignorer la protection humaine
WHERE category IS NULL OR category = 'uncategorized'  -- Peut √©craser le travail humain !
```

#### üìä **√âtat Actuel de la Classification par Cha√Æne Center Parcs** :
- **üá´üá∑ France** : 235/235 vid√©os cat√©goris√©es (57 hero, 164 hub, 14 help) ‚úÖ
- **üá≥üá± Netherlands** : 433/433 vid√©os cat√©goris√©es (213 hero, 175 hub, 45 help) ‚úÖ  
- **üá¨üáß UK** : 42/42 vid√©os cat√©goris√©es (13 hero, 29 hub, 0 help) ‚úÖ
- **üá©üá™ Germany** : 0/224 vid√©os cat√©goris√©es ‚ö†Ô∏è **CLASSIFICATION MANUELLE REQUISE**

## üìÖ PROBL√àME CRITIQUE DE DATES - IMPORTED_AT vs YOUTUBE_PUBLISHED_AT

### ‚ö†Ô∏è **BUG SYST√âMIQUE : DATES D'IMPORT UTILIS√âES AU LIEU DES VRAIES DATES YOUTUBE**

**PROBL√àME MAJEUR** : Les scripts d'import ont tendance √† utiliser `imported_at` (date d'import) au lieu de `youtube_published_at` (vraie date de publication YouTube), causant des calculs de fr√©quence compl√®tement erron√©s.

#### üö® **Sympt√¥mes Observ√©s** :
- **Fr√©quences absurdes** : 1645 vid√©os/semaine, 3031 vid√©os/semaine (impossible !)
- **Toutes les vid√©os** avec la m√™me date : `2025-07-05` (date d'import)
- **Calculs de tendances** fauss√©s car bas√©s sur la date d'import
- **Analyses temporelles** invalides

#### üìä **√âtat des Dates par Cha√Æne Center Parcs** :
```sql
-- V√©rification des dates probl√©matiques
SELECT c.name, 
       MIN(DATE(v.published_at)) as first_date, 
       MAX(DATE(v.published_at)) as last_date,
       COUNT(DISTINCT DATE(v.published_at)) as distinct_dates,
       COUNT(*) as total_videos
FROM video v 
JOIN concurrent c ON v.concurrent_id = c.id 
WHERE c.name LIKE '%Center Parcs%' 
GROUP BY c.id, c.name;
```

- **üá´üá∑ France** : 235 vid√©os TOUTES avec `2025-07-05` ‚Üí **DATES CORROMPUES**
- **üá≥üá± Netherlands** : 433 vid√©os TOUTES avec `2025-07-05` ‚Üí **DATES CORROMPUES**  
- **üá¨üáß UK** : 42 vid√©os TOUTES avec `2025-07-05` ‚Üí **DATES CORROMPUES**
- **üá©üá™ Germany** : 224 vid√©os avec dates r√©alistes `2012-09-27` √† `2025-07-21` ‚Üí **DATES CORRECTES**

#### üîß **Fonctions √† Auditer et Corriger** :
1. **Scripts d'import YouTube** : V√©rifier usage de `published_at` vs vraie date API
2. **Calculs de fr√©quence** : `video_frequency_metrics()`, `calculate_publishing_frequency()`
3. **Analyses temporelles** : `trend_analysis()`, `seasonal_patterns()`
4. **Services de m√©triques** : `brand_metrics_service.py`, `country_metrics_service.py`

#### ü§ñ **AGENT D√âDI√â √Ä CR√âER** :
```python
# Agent de Correction de Dates YouTube
class YouTubeDateCorrectionAgent:
    """
    Agent d√©di√© pour corriger toutes les dates d'import erron√©es
    et restaurer les vraies dates de publication YouTube
    """
    
    def audit_date_integrity(self):
        # Identifier toutes les vid√©os avec dates suspectes
        
    def fetch_real_youtube_dates(self):
        # R√©cup√©rer les vraies dates via YouTube API
        
    def batch_correct_dates(self):
        # Corriger en lot les dates corrompues
        
    def validate_frequency_calculations(self):
        # Re-calculer toutes les fr√©quences apr√®s correction
```

#### ‚öôÔ∏è **Colonnes de Tracking des Dates** :
- `published_at` : Date actuelle (souvent = date d'import ‚ùå)
- `youtube_published_at` : Vraie date YouTube API (parfois vide)
- `imported_at` : Date d'import dans le syst√®me
- `last_updated` : Derni√®re modification

#### üéØ **Action Imm√©diate Requise** :
1. **Cr√©er l'agent de correction** pour auditer toutes les dates
2. **Identifier les fonctions** qui utilisent mal `published_at`
3. **Re-fetch les vraies dates** YouTube pour les cha√Ænes importantes
4. **Recalculer les m√©triques** temporelles apr√®s correction

### üéØ Impl√©mentation dans le Syst√®me

#### Modules concern√©s :
- `yt_channel_analyzer/database/classification.py` : Logique de classification
- `yt_channel_analyzer/supervised_learning.py` : Entra√Ænement des mod√®les
- `yt_channel_analyzer/semantic_classifier.py` : Classification s√©mantique
- `app.py` : Routes de classification manuelle

#### Colonnes de tracking :
- `is_human_validated` : Flag de protection absolue
- `classification_source` : Source de la classification
- `human_verified` : Alias pour compatibilit√©

## üóÑÔ∏è CONFIGURATION BASE DE DONN√âES - R√àGLE CRITIQUE

### ‚ö†Ô∏è CHEMIN CORRECT DE LA BASE DE DONN√âES

**ABSOLUMENT CRUCIAL** : Le refactoring a caus√© une confusion sur l'emplacement de la vraie base de donn√©es.

#### üìç Localisation des bases de donn√©es :
- **‚ùå FAUSSE BASE** : `./instance/youtube_data.db` (20 comp√©titeurs, 5922 vid√©os)
- **‚úÖ VRAIE BASE** : `./instance/database.db` (30 comp√©titeurs, 8489 vid√©os)

#### üîß Configuration dans le code :
**Fichier** : `yt_channel_analyzer/database/base.py`
```python
# ‚úÖ CORRECT
DB_PATH = DB_DIR / 'database.db'

# ‚ùå INCORRECT (apr√®s refactoring)  
DB_PATH = DB_DIR / 'youtube_data.db'
```

#### üö® V√©rification automatique des donn√©es :
```python
# Script de v√©rification rapide
from yt_channel_analyzer.database import get_db_connection
conn = get_db_connection()
cursor = conn.cursor()

cursor.execute('SELECT COUNT(*) FROM concurrent')
competitors = cursor.fetchone()[0]

cursor.execute('SELECT COUNT(*) FROM video')
videos = cursor.fetchone()[0]

print(f'Comp√©titeurs: {competitors}, Vid√©os: {videos}')

# ‚úÖ R√©sultat attendu : 30 comp√©titeurs, 8489 vid√©os
# ‚ùå Si tu vois 20 comp√©titeurs, tu es sur la mauvaise base !
```

#### üìä Donn√©es attendues par pays :
- **International** : 9 comp√©titeurs, ~3547 vid√©os
- **France** : 8 comp√©titeurs, ~1671 vid√©os  
- **Germany** : 7 comp√©titeurs, ~1731 vid√©os
- **Netherlands** : 4 comp√©titeurs, ~1170 vid√©os
- **United Kingdom** : 1 comp√©titeur, ~42 vid√©os
- **1 pays vide** : 1 comp√©titeur, ~328 vid√©os (√† nettoyer)

#### üîÑ Action √† faire en cas d'erreur :
Si tu constates que l'application n'affiche que 20 comp√©titeurs au lieu de 30 :
1. V√©rifier `yt_channel_analyzer/database/base.py` ligne 15
2. S'assurer que `DB_PATH = DB_DIR / 'database.db'`
3. Red√©marrer l'application
4. Tester avec `/countries-analysis`

## Structure de la base de donn√©es

### Tables principales
- **concurrent**: Concurrents/cha√Ænes YouTube (355 playlists disponibles)
- **playlist**: Playlists des concurrents (355 entr√©es)
- **video**: Vid√©os des concurrents
- **playlist_video**: Liaison many-to-many entre playlists et vid√©os

### Tables de classification
- **classification_feedback**: Feedback utilisateur sur les classifications
- **classification_patterns**: Patterns de classification
- **custom_classification_rules**: R√®gles personnalis√©es
- **learned_patterns**: Patterns appris par l'IA

### Tables de statistiques
- **competitor_stats**: Statistiques des concurrents
- **competitor_frequency_stats**: Statistiques de fr√©quence
- **competitor_detailed_stats**: Statistiques d√©taill√©es
- **model_performance**: Performance des mod√®les

## Gestion des miniatures des concurrents

Les miniatures des cha√Ænes YouTube sont stock√©es dans `/static/competitors/images/` avec comme nom de fichier `{concurrent_id}.jpg`.

Par exemple : 
- Center Parcs Ferienparks (ID 122) ‚Üí `/static/competitors/images/122.jpg`

## Structure des playlists

### Colonnes disponibles
- `id`: ID unique
- `concurrent_id`: R√©f√©rence au concurrent
- `playlist_id`: ID YouTube de la playlist
- `name`: Nom de la playlist
- `description`: Description
- `thumbnail_url`: URL de la miniature
- `category`: Cat√©gorie (hero/hub/help)
- `video_count`: Nombre de vid√©os
- `created_at`: Date de cr√©ation
- `last_updated`: Derni√®re mise √† jour
- `classification_source`: Source de classification (ai/human)
- `classification_date`: Date de classification
- `classification_confidence`: Confiance de la classification
- `human_verified`: V√©rifi√© par un humain
- `is_human_validated`: Valid√© par un humain

### M√©triques √† calculer pour le top playlists
- **Nombre total de vues**: Somme des vues de toutes les vid√©os de la playlist
- **Nombre total de likes**: Somme des likes de toutes les vid√©os
- **Nombre total de commentaires**: Somme des commentaires
- **Ratio d'engagement**: (Likes + Commentaires) / Vues totales
- **Dur√©e moyenne des vid√©os**: Moyenne des dur√©es des vid√©os
- **Score de beaut√© moyen**: Moyenne des beauty_score des vid√©os
- **Score d'√©motion moyen**: Moyenne des emotion_score des vid√©os
- **Score de qualit√© info moyen**: Moyenne des info_quality_score des vid√©os
- **Score subjectif moyen**: Moyenne des scores subjectifs
- **Date de derni√®re vid√©o**: Date de publication de la vid√©o la plus r√©cente

## Mod√®le de la page top-videos

### Fonctionnalit√©s existantes
- Tri par diff√©rentes m√©triques (vues, likes, commentaires, etc.)
- Filtres par cat√©gorie (hero/hub/help)
- Filtres par type (organic/paid)
- Pagination/limite d'affichage
- Cache avec timeout de 300s
- Interface glassmorphism

### M√©triques affich√©es
- Miniature, titre, concurrent
- Cat√©gorie, statut organique
- Vues, likes, commentaires
- Ratio d'engagement, dur√©e
- Date de publication, heure
- Scores de beaut√©, √©motion, qualit√© info
- Score subjectif moyen

## Architecture technique

### Backend
- Flask avec SQLite
- Modules dans `yt_channel_analyzer/database/`
- Gestion des connexions via `base.py`
- Managers sp√©cialis√©s (VideoManager, etc.)

### Frontend
- Templates Jinja2 dans `templates/`
- Syst√®me de th√®mes CSS
- Interface glassmorphism
- JavaScript pour interactions

### Environnement
- Python 3.12 avec `venv_semantic`
- Dependencies dans `requirements-semantic.txt`
- Mod√®les Transformers pour classification

## Prochaines √©tapes pour /top-playlists

1. Cr√©er une table ou vue pour les statistiques des playlists
2. Calculer les m√©triques agr√©g√©es depuis les vid√©os li√©es
3. Impl√©menter la route `/top-playlists` similaire √† `/top-videos`
4. Cr√©er le template HTML bas√© sur `top_videos.html`
5. Ajouter la navigation vers cette nouvelle page

## ü§ñ Classification S√©mantique Avanc√©e

### Mod√®les de Sentence-Transformers
- **Mod√®le principal** : `all-mpnet-base-v2` (768 dimensions)
- **Performance** : +40% de pr√©cision vs mod√®le par d√©faut
- **Optimisation** : ONNX Runtime + quantization INT8
- **Gain de performance** : 75% r√©duction taille, +300% vitesse

### üåç Mod√®les d'Analyse √âmotionnelle Multilingue

#### ‚úÖ MOD√àLE CONFIRM√â FONCTIONNEL
- **cardiffnlp/twitter-xlm-roberta-base-sentiment** : 3 sentiments (positive, negative, neutral)
- **Support multilingue** : FR, EN, DE, NL, ES
- **URL** : https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment
- **Usage confirm√©** : Fonctionne parfaitement pour analyse multilingue

#### ‚ùå MOD√àLES NON FONCTIONNELS
- **cardiffnlp/twitter-xlm-roberta-base-emotion** : N'existe pas sur HuggingFace
- **j-hartmann/emotion-english-distilroberta-base** : Anglais uniquement, pas multilingue
- **SamLowe/roberta-base-go_emotions** : Anglais uniquement

#### üéØ Strat√©gie Recommand√©e
Pour l'analyse des 450 commentaires multilingues :
- Utiliser `cardiffnlp/twitter-xlm-roberta-base-sentiment` (3 sentiments)
- Base de donn√©es : `emotion_type IN ('positive', 'negative', 'neutral')`
- Langues support√©es : `language IN ('fr', 'en', 'de', 'nl', 'es')`

### Classes de Classification
1. **OptimizedSemanticClassifier** (`yt_channel_analyzer/semantic_classifier.py`)
   - Utilise ONNX Runtime pour l'acc√©l√©ration
   - Quantization INT8 pour optimiser la m√©moire
   - Cache Redis pour les embeddings fr√©quents
   
2. **AdvancedSemanticClassifier**
   - Mod√®le all-mpnet-base-v2 pour meilleure pr√©cision
   - Entra√Ænement avec 64 exemples manuels (49 playlists + 15 vid√©os)
   - Support multi-threading pour 24 threads + 64GB RAM

### Donn√©es d'Entra√Ænement
- **64 exemples valid√©s manuellement** extraits de la base
- **Cat√©gories** : HERO/HUB/HELP
- **Protection absolue** : `is_human_validated = 1` jamais √©cras√©
- **Sources** : human > semantic > keyword patterns

### Dependencies Optimisation
```txt
# Ajout√©es dans requirements-semantic.txt
optimum[onnxruntime]>=1.14.0
onnxruntime>=1.16.0
onnx>=1.14.0
accelerate>=0.22.0
datasets>=2.12.0
redis>=4.5.0
bitsandbytes>=0.41.0
```

## üé® Int√©gration Th√®me Sneat Bootstrap

### Compilation SCSS avec Dart Sass
- **Dart Sass 1.70.0** install√© pour compilation native
- **Script automatis√©** : `python build_theme.py`
- **Fichiers sources** : `/static/sneat/scss/`
- **Fichiers compil√©s** : `/static/sneat/assets/vendor/css/`

### Fichiers CSS G√©n√©r√©s
1. **core.css** (2,535 bytes) - Layout et composants de base
2. **theme-default.css** (3,674 bytes) - Th√®me et navbar complets

### Corrections Layout
- **Navbar height** : Fix√© √† 4rem au lieu de 400px
- **Menu actif** : Underline sur Dashboard et items actifs
- **Layout wrapper** : Structure layout-menu-fixed corrig√©e
- **JavaScript** : getCssVar function ajout√©e pour config.js

### Structure SCSS
```scss
// Variables Sneat dans core-simple.scss
:root {
  --bs-primary: #696cff;
  --bs-secondary: #8592a3;
  // ... autres variables de couleur
}

// Layout navbar dans theme-default-simple.scss
.layout-navbar {
  position: relative;
  z-index: 2;
  flex-wrap: nowrap;
  block-size: 4rem;  // Hauteur fixe 64px
  padding-block: 0.5rem;
}
```

### Pages Migr√©es vers Sneat
- ‚úÖ `/concurrents` - Template Sneat + fonction refresh data
- ‚úÖ `base.html` - Navbar Sneat compl√®te avec search et user dropdown
- üîÑ En cours : `/insights`, `/fix-problems`, `/learn`, `/api-usage`, `/top-videos`

## üìä Protocole de Comparaison √† Trois Niveaux - Architecture en Empilement

### ‚ö†Ô∏è R√àGLE FONDAMENTALE : INT√âGRIT√â DES DONN√âES PAR NIVEAU

**Architecture hi√©rarchique :** `CHANNEL < COUNTRY < EUROPE`

```
üåç EUROPE/INTERNATIONAL (Niveau 3)
    ‚Üë Consolidation depuis
üè† COUNTRY (Niveau 2) 
    ‚Üë Consolidation depuis
üì∫ CHANNEL (Niveau 1)
```

### üîí S√âCURISATION ABSOLUE DES STATS CHANNEL

**PRIORIT√â CRITIQUE** : Les statistiques de chaque cha√Æne individuelle doivent √™tre **blind√©es** car elles sont la fondation de tout le syst√®me.

#### Pourquoi c'est critique :
- **Effect domino** : Une erreur au niveau CHANNEL se propage √† COUNTRY puis EUROPE
- **Fausses consolidations** : Si les stats d'une cha√Æne sont erron√©es, toutes les analyses pays/europ√©ennes sont fausses
- **Perte de confiance** : Un seul mauvais chiffre invalide tout le syst√®me d'analyse

#### Contr√¥les obligatoires au niveau CHANNEL :
```sql
-- V√©rifications d'int√©grit√© par cha√Æne
SELECT 
    c.name,
    COUNT(v.id) as video_count,
    SUM(v.view_count) as total_views,
    AVG(v.view_count) as avg_views,
    -- D√©tection d'anomalies
    CASE WHEN AVG(v.view_count) > 1000000 THEN 'SUSPECT_HIGH' 
         WHEN AVG(v.view_count) < 100 THEN 'SUSPECT_LOW' 
         ELSE 'OK' END as integrity_check
FROM concurrent c 
LEFT JOIN video v ON c.id = v.concurrent_id 
GROUP BY c.id, c.name
ORDER BY integrity_check DESC, total_views DESC;
```

### üèóÔ∏è Niveaux Hi√©rarchiques

#### üì∫ Niveau 1 : CHANNEL (Base de donn√©es)
**Scope** : Statistiques par cha√Æne individuelle
- **Source** : Donn√©es directes YouTube API
- **Responsabilit√©** : Exactitude des m√©triques individuelles
- **Contr√¥les** : Validation des vues, likes, dur√©es, dates
- **Stockage** : Tables `concurrent`, `video`, `playlist`

#### üè† Niveau 2 : COUNTRY (Consolidation)
**Scope** : Agr√©gation par pays
- **Source** : Consolidation depuis les CHANNELS du pays
- **Calculs** :
  ```sql
  -- Exemple : Stats France
  SELECT 
      'France' as country,
      COUNT(DISTINCT c.id) as channel_count,
      COUNT(v.id) as total_videos,
      SUM(v.view_count) as country_views,
      AVG(v.view_count) as avg_views_per_video
  FROM concurrent c 
  JOIN video v ON c.id = v.concurrent_id 
  WHERE c.country = 'France'
  ```
- **D√©pendances** : Int√©grit√© des donn√©es CHANNEL

#### üåç Niveau 3 : EUROPE (Super-consolidation)
**Scope** : Vue globale europ√©enne/internationale
- **Source** : Consolidation depuis les COUNTRIES
- **Calculs** :
  ```sql
  -- Stats europ√©ennes
  SELECT 
      'Europe' as region,
      COUNT(DISTINCT c.country) as country_count,
      COUNT(DISTINCT c.id) as total_channels,
      COUNT(v.id) as total_videos,
      SUM(v.view_count) as europe_views
  FROM concurrent c 
  JOIN video v ON c.id = v.concurrent_id 
  WHERE c.country IN ('France', 'Germany', 'Netherlands', 'United Kingdom')
  ```
- **D√©pendances** : Int√©grit√© des agr√©gations COUNTRY

### üõ°Ô∏è Protocoles de S√©curisation

#### 1. Validation des donn√©es CHANNEL
- **Seuils de coh√©rence** : Vues min/max par vid√©o selon l'√¢ge de la cha√Æne
- **D√©tection d'anomalies** : Pics suspects, valeurs nulles, dates incoh√©rentes
- **Audit trail** : Tra√ßabilit√© des modifications de stats

#### 2. Contr√¥les de consolidation COUNTRY
- **Somme de contr√¥le** : V√©rification que SUM(channels) = country_total
- **Coh√©rence temporelle** : Dates de publication align√©es avec les pays
- **Distribution normale** : D√©tection des outliers par pays

#### 3. Validation de super-consolidation EUROPE
- **R√©conciliation** : SUM(countries) = europe_total
- **Benchmarks externes** : Comparaison avec sources publiques
- **Alertes automatiques** : Notification si √©carts > 5%

### üö® Syst√®me d'Alertes d'Int√©grit√©

```python
def validate_data_integrity():
    alerts = []
    
    # Niveau CHANNEL
    suspicious_channels = check_channel_anomalies()
    if suspicious_channels:
        alerts.append(f"‚ö†Ô∏è CHANNEL: {len(suspicious_channels)} cha√Ænes suspectes")
    
    # Niveau COUNTRY  
    country_discrepancies = validate_country_consolidation()
    if country_discrepancies:
        alerts.append(f"‚ö†Ô∏è COUNTRY: √âcarts de consolidation d√©tect√©s")
        
    # Niveau EUROPE
    europe_integrity = validate_europe_consolidation()
    if not europe_integrity:
        alerts.append(f"üö® EUROPE: Consolidation incoh√©rente")
    
    return alerts
```

### üìã TODO : Impl√©mentation S√©curis√©e

1. **Audit des donn√©es actuelles** : Identifier les incoh√©rences existantes
2. **Mise en place des contr√¥les** : Scripts de validation automatique  
3. **Dashboard d'int√©grit√©** : Monitoring temps r√©el des 3 niveaux
4. **Processus de correction** : Workflow pour corriger les anomalies d√©tect√©es
5. **Documentation des seuils** : D√©finir les limites acceptables par m√©trique

### üìà M√©triques Objectives par Dimension

#### 1. **Video Length** (Dur√©e des Vid√©os)
- **Donn√©es** : `video.duration_seconds`, `video.duration_text`
- **M√©triques** :
  - Dur√©e moyenne par niveau
  - Distribution par quartiles
  - Corr√©lation dur√©e/performance
  - Tendances temporelles

#### 2. **Video Frequency** (Fr√©quence de Publication)
- **Donn√©es** : `video.published_at`, table `competitor_frequency_stats`
- **M√©triques** :
  - Vid√©os par semaine/mois
  - R√©gularit√© de publication
  - Saisonnalit√©
  - Fr√©quence par cat√©gorie (Hero/Hub/Help)

#### 3. **Most Liked Topics** (Sujets les Plus Appr√©ci√©s)
- **Donn√©es** : `video.title`, `video.like_count`, analyse s√©mantique
- **M√©triques** :
  - Topics avec le meilleur engagement
  - Analyse lexicale des titres performants
  - Corr√©lation sujet/likes
  - √âvolution des pr√©f√©rences

#### 4. **Hub-Hero-Help Distribution**
- **Donn√©es** : `video.category`, `playlist.category`
- **M√©triques** :
  - % de r√©partition par cat√©gorie
  - Performance par cat√©gorie
  - √âquilibre strat√©gique
  - Comparaison avec la th√©orie Google

#### 5. **Organic vs Paid Distribution**
- **Donn√©es** : `video.view_count` vs `paid_threshold` (settings)
- **M√©triques** :
  - % de contenu organique vs pay√©
  - Performance comparative
  - Seuils de d√©tection
  - ROI estim√© par type

#### 6. **Thumbnail Consistency** (Coh√©rence des Miniatures)
- **Donn√©es** : `video.thumbnail_url`, `video.beauty_score`
- **M√©triques** :
  - Scores de beaut√© moyens
  - Coh√©rence visuelle (√† d√©velopper)
  - Patterns de couleurs
  - Efficacit√© par style

#### 7. **Tone of Voice** (Tonalit√© et Champs S√©mantiques)
- **Donn√©es** : `video.title`, `video.description`, analyse NLP
- **M√©triques** :
  - **Lexical Field** : Vocabulaire utilis√©, richesse lexicale
  - **Semantic Field** : Champs s√©mantiques dominants
  - Sentiment analysis
  - Coh√©rence de marque

### üîß Impl√©mentation Technique

#### Tables Concern√©es
```sql
-- Niveau g√©ographique
concurrent.country

-- Niveau marque  
concurrent.name (pattern matching)

-- M√©triques vid√©o
video.duration_seconds, video.published_at, video.category
video.view_count, video.like_count, video.thumbnail_url

-- Statistiques pr√©calcul√©es
competitor_stats, competitor_frequency_stats
```

#### Fonctions d'Analyse
- `calculate_video_length_metrics(level, scope)`
- `analyze_publication_frequency(level, scope)`
- `extract_top_topics(level, scope)`
- `calculate_hhh_distribution(level, scope)`
- `detect_organic_vs_paid(level, scope)`
- `analyze_thumbnail_consistency(level, scope)`
- `analyze_tone_of_voice(level, scope)`

### üìä Dashboard de Comparaison

#### Interface Utilisateur
- **S√©lecteur de Niveau** : Europ√©en/Local/Marque
- **S√©lecteur de Scope** : Pays/Marque selon le niveau
- **M√©triques Comparatives** : Tableaux et graphiques
- **Export des Donn√©es** : JSON/CSV pour analyse approfondie

#### Pages D√©di√©es
- `/comparison/european` - Vue europ√©enne/internationale
- `/comparison/local/<country>` - Vue par pays
- `/comparison/brand/<brand_name>` - Vue par marque

## üìã TODO FUTURES - Architecture Modulaire

### üéØ TODO 21.07.2025 : Strat√©gie modulaire pour "Competitors" et cohabitation YAML + SQLite

**Objectif :** Isoler l'affichage statique du processing lourd pour une architecture plus maintenable.

#### Structure de projet cible

```
yt-channel-analyzer/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ competitors.yaml     # source statique pour l'UI
‚îÇ   ‚îî‚îÄ‚îÄ competitors.db       # base SQLite pour le processing
‚îÇ
‚îú‚îÄ‚îÄ competitors/             # module ¬´ Vue ¬ª uniquement YAML‚Äëdriven
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ loader.py           # charge data/competitors.yaml
‚îÇ   ‚îú‚îÄ‚îÄ service.py          # logique m√©tier l√©g√®re (filtrage, tri, enrichissement)
‚îÇ   ‚îî‚îÄ‚îÄ renderer.py         # g√©n√®re le HTML/list CLI
‚îÇ
‚îî‚îÄ‚îÄ processing/             # module ¬´ Batch ¬ª uniquement DB‚Äëdriven
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ db.py              # wrapper sqlite3.connect(competitors.db)
    ‚îî‚îÄ‚îÄ tasks.py           # fonctions lourdes de calcul, agr√©gations, rapports
```

#### B√©n√©fices attendus

1. **Isolation compl√®te :**
   - L'UI "Competitors" ne touche jamais √† SQLite ‚Äî elle ne lit que le YAML
   - Les batchs ¬´ processing ¬ª ne g√©n√®rent pas de HTML ‚Äî ils ne touchent que la DB

2. **Responsabilit√© unique :**
   - `loader.py` = lecture de fichier YAML
   - `service.py` = r√®gles m√©tier (filtrage, tri, enrichment)
   - `renderer.py` = pr√©sentation
   - `db.py` = connexion SQLite
   - `tasks.py` = calculs & agr√©gations

3. **√âvolutivit√© :**
   - Changement d'API : modifier seulement `loader.py`
   - Changement de DB : modifier seulement `db.py`

4. **Testabilit√© :**
   - Mock `load_competitors()` pour tester la pr√©sentation
   - Mock connexion SQLite pour tester les calculs

#### Impl√©mentation propos√©e

```python
# competitors/loader.py
import yaml
from pathlib import Path
from functools import lru_cache

@lru_cache(1)
def load_competitors() -> list[dict]:
    path = Path(__file__).parent.parent / "data" / "competitors.yaml"
    with open(path, encoding="utf-8") as f:
        return yaml.safe_load(f).get("competitors", [])

# competitors/service.py
from .loader import load_competitors

def get_active_competitors() -> list[dict]:
    all_ = load_competitors()
    active = [c for c in all_ if c.get("active", True)]
    return sorted(active, key=lambda c: c["name"])

def enrich_with_rank(comps: list[dict]) -> list[dict]:
    for i, c in enumerate(comps, 1):
        c["rank"] = i
    return comps

# processing/db.py
import sqlite3
from pathlib import Path

DB = Path(__file__).parent.parent / "data" / "competitors.db"

def get_connection():
    return sqlite3.connect(DB)
```

**Flux :** loader ‚Üí service (logique m√©tier) ‚Üí renderer (UI)  
**S√©paration :** Vue YAML ‚Üî Processing SQLite

## Commandes utiles

```bash
# Activer l'environnement
source venv_semantic/bin/activate

# D√©marrer l'application
python app.py

# Compiler les th√®mes SCSS
python build_theme.py

# Examiner la base de donn√©es
sqlite3 instance/database.db

# Entra√Æner les mod√®les s√©mantiques avec toutes les donn√©es humaines
python train_semantic_model.py

# Ou directement en Python :
python -c "from yt_channel_analyzer.semantic_training import SemanticTrainingManager; trainer = SemanticTrainingManager(); trainer.extract_human_classifications(); trainer.train_semantic_model()"
```