"""
Module pour les interactions avec la base de donn√©es SQLite.
"""

import sqlite3
import json
from datetime import datetime
from typing import List, Dict, Optional
import re

DB_PATH = 'instance/database.db'

def get_db_connection():
    """Cr√©er une connexion √† la base de donn√©es"""
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row  # Pour acc√©der aux colonnes par nom
    return conn

def extract_video_id_from_url(video_url: str) -> str:
    """Extraire l'ID vid√©o depuis l'URL YouTube"""
    patterns = [
        r'(?:v=|\/)([0-9A-Za-z_-]{11}).*',
        r'(?:embed\/)([0-9A-Za-z_-]{11})',
        r'(?:v\/)([0-9A-Za-z_-]{11})'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, video_url)
        if match:
            return match.group(1)
    
    # Fallback: utiliser l'URL compl√®te comme ID
    return video_url.replace('/', '_').replace(':', '_')[:50]

def extract_channel_id_from_url(channel_url: str) -> str:
    """Extraire l'ID de cha√Æne depuis l'URL YouTube"""
    if '/channel/' in channel_url:
        return channel_url.split('/channel/')[-1].split('/')[0].split('?')[0]
    elif '/@' in channel_url:
        return channel_url.split('/@')[-1].split('/')[0].split('?')[0]
    elif '/c/' in channel_url:
        return channel_url.split('/c/')[-1].split('/')[0].split('?')[0]
    elif '/user/' in channel_url:
        return channel_url.split('/user/')[-1].split('/')[0].split('?')[0]
    else:
        return channel_url.replace('/', '_').replace(':', '_')[:100]

def save_competitor_and_videos(channel_url: str, videos: List[Dict], channel_info: Dict = None) -> int:
    """
    Sauvegarder un concurrent et ses vid√©os dans la base de donn√©es.
    Cr√©e automatiquement le concurrent s'il n'existe pas.
    """
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        # V√©rifier si le concurrent existe d√©j√†
        cursor.execute('SELECT id FROM concurrent WHERE channel_url = ?', (channel_url,))
        existing = cursor.fetchone()
        
        if existing:
            competitor_id = existing[0]
            print(f"[DB] Concurrent existant trouv√©: ID {competitor_id}")
        else:
            # Cr√©er un nouveau concurrent
            channel_id = extract_channel_id_from_url(channel_url)
            
            # Utiliser les infos de la cha√Æne si disponibles
            if channel_info:
                name = channel_info.get('title', 'Canal inconnu')
                thumbnail_url = channel_info.get('thumbnail', '')
                banner_url = channel_info.get('banner', '')
                description = channel_info.get('description', '')
                subscriber_count = channel_info.get('subscriber_count')
                view_count = channel_info.get('view_count')
                video_count = len(videos)
                country = channel_info.get('country', '')
                language = channel_info.get('language', '')
            else:
                # Valeurs par d√©faut
                name = channel_url.split('/')[-1] if '/' in channel_url else 'Canal inconnu'
                thumbnail_url = ''
                banner_url = ''
                description = ''
                subscriber_count = None
                view_count = None
                video_count = len(videos)
                country = ''
                language = ''
            
            cursor.execute('''
                INSERT INTO concurrent (
                    name, channel_id, channel_url, thumbnail_url, banner_url,
                    description, subscriber_count, view_count, video_count,
                    country, language, created_at, last_updated
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                name, channel_id, channel_url, thumbnail_url, banner_url,
                description, subscriber_count, view_count, video_count,
                country, language, datetime.now(), datetime.now()
            ))
            
            competitor_id = cursor.lastrowid
            print(f"[DB] Nouveau concurrent cr√©√©: {name} (ID {competitor_id})")
        
        # Sauvegarder les vid√©os
        videos_added = 0
        videos_updated = 0
        
        for video in videos:
            video_id = extract_video_id_from_url(video.get('url', ''))
            
            # V√©rifier si la vid√©o existe d√©j√†
            cursor.execute('SELECT id FROM video WHERE video_id = ?', (video_id,))
            existing_video = cursor.fetchone()
            
            # Pr√©parer les donn√©es de la vid√©o
            title = video.get('title', '')[:200]  # Limiter √† 200 caract√®res
            description = video.get('description', '')
            url = video.get('url', '')
            thumbnail_url = video.get('thumbnail', '')
            
            # Traiter la date de publication
            published_at = None
            if video.get('publication_date'):
                try:
                    # Essayer de parser diff√©rents formats de date
                    date_str = video['publication_date']
                    if 'il y a' in date_str:
                        # Pour les dates relatives, utiliser la date actuelle
                        published_at = datetime.now()
                    else:
                        # Essayer de parser la date directement
                        published_at = datetime.strptime(date_str, '%Y-%m-%d')
                except:
                    published_at = datetime.now()
            
            # Traiter la dur√©e
            duration_seconds = None
            duration_text = video.get('duration', '')
            if duration_text:
                try:
                    # Convertir "2:45" en secondes
                    parts = duration_text.split(':')
                    if len(parts) == 2:
                        duration_seconds = int(parts[0]) * 60 + int(parts[1])
                    elif len(parts) == 3:
                        duration_seconds = int(parts[0]) * 3600 + int(parts[1]) * 60 + int(parts[2])
                except:
                    pass
            
            # Traiter les m√©triques
            view_count = video.get('views') or video.get('view_count') or 0
            if isinstance(view_count, str):
                view_count = int(re.sub(r'[^\d]', '', view_count)) if re.sub(r'[^\d]', '', view_count) else 0
            
            like_count = video.get('likes') or video.get('like_count')
            comment_count = video.get('comments') or video.get('comment_count')
            
            if existing_video:
                # Mettre √† jour la vid√©o existante
                cursor.execute('''
                    UPDATE video SET
                        title = ?, description = ?, url = ?, thumbnail_url = ?,
                        published_at = ?, duration_seconds = ?, duration_text = ?,
                        view_count = ?, like_count = ?, comment_count = ?,
                        last_updated = ?
                    WHERE id = ?
                ''', (
                    title, description, url, thumbnail_url,
                    published_at, duration_seconds, duration_text,
                    view_count, like_count, comment_count,
                    datetime.now(), existing_video[0]
                ))
                videos_updated += 1
            else:
                # Ins√©rer une nouvelle vid√©o
                cursor.execute('''
                    INSERT INTO video (
                        concurrent_id, video_id, title, description, url, thumbnail_url,
                        published_at, duration_seconds, duration_text,
                        view_count, like_count, comment_count,
                        created_at, last_updated
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    competitor_id, video_id, title, description, url, thumbnail_url,
                    published_at, duration_seconds, duration_text,
                    view_count, like_count, comment_count,
                    datetime.now(), datetime.now()
                ))
                videos_added += 1
        
        # Mettre √† jour le nombre de vid√©os du concurrent
        cursor.execute('SELECT COUNT(*) FROM video WHERE concurrent_id = ?', (competitor_id,))
        total_videos = cursor.fetchone()[0]
        
        cursor.execute('''
            UPDATE concurrent SET video_count = ?, last_updated = ? WHERE id = ?
        ''', (total_videos, datetime.now(), competitor_id))
        
        conn.commit()
        print(f"[DB] Sauvegarde termin√©e: {videos_added} vid√©os ajout√©es, {videos_updated} mises √† jour, total: {total_videos}")
        
        return competitor_id
        
    except Exception as e:
        conn.rollback()
        print(f"[DB] Erreur lors de la sauvegarde: {e}")
        raise
    finally:
        conn.close()

def get_competitor_videos(competitor_id: int) -> List[Dict]:
    """R√©cup√©rer toutes les vid√©os d'un concurrent"""
    conn = get_db_connection()
    cursor = conn.cursor()
    
    cursor.execute('''
        SELECT * FROM video 
        WHERE concurrent_id = ? 
        ORDER BY published_at DESC
    ''', (competitor_id,))
    
    videos = []
    for row in cursor.fetchall():
        videos.append(dict(row))
    
    conn.close()
    return videos

def get_all_competitors() -> List[Dict]:
    """R√©cup√©rer tous les concurrents depuis la base de donn√©es avec vues totales calcul√©es"""
    conn = get_db_connection()
    cursor = conn.cursor()
    
    cursor.execute('''
        SELECT * FROM concurrent 
        ORDER BY name
    ''')
    
    competitors = []
    for row in cursor.fetchall():
        competitor = dict(row)
        
        # Calculer les vues totales en sommant les vues de toutes ses vid√©os
        cursor.execute('''
            SELECT COALESCE(SUM(view_count), 0) as total_views
            FROM video 
            WHERE concurrent_id = ?
        ''', (competitor['id'],))
        
        total_views_result = cursor.fetchone()
        competitor['total_views'] = total_views_result[0] if total_views_result else 0
        
        competitors.append(competitor)
    
    conn.close()
    return competitors

def get_competitor_by_url(channel_url: str) -> Optional[Dict]:
    """R√©cup√©rer un concurrent par son URL"""
    conn = get_db_connection()
    cursor = conn.cursor()
    
    cursor.execute('SELECT * FROM concurrent WHERE channel_url = ?', (channel_url,))
    row = cursor.fetchone()
    
    conn.close()
    return dict(row) if row else None

def add_competitor(competitor_data: Dict) -> int:
    """Ajouter un nouveau concurrent"""
    conn = get_db_connection()
    cursor = conn.cursor()
    
    cursor.execute('''
        INSERT INTO concurrent (
            name, channel_id, channel_url, thumbnail_url, banner_url,
            description, subscriber_count, view_count, video_count,
            country, language, created_at, last_updated
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    ''', (
        competitor_data.get('name'),
        competitor_data.get('channel_id'),
        competitor_data.get('channel_url'),
        competitor_data.get('thumbnail_url'),
        competitor_data.get('banner_url'),
        competitor_data.get('description'),
        competitor_data.get('subscriber_count'),
        competitor_data.get('view_count'),
        competitor_data.get('video_count'),
        competitor_data.get('country'),
        competitor_data.get('language'),
        datetime.now(),
        datetime.now()
    ))
    
    competitor_id = cursor.lastrowid
    conn.commit()
    conn.close()
    
    return competitor_id

def update_competitor(competitor_id: int, updates: Dict):
    """Mettre √† jour un concurrent"""
    conn = get_db_connection()
    cursor = conn.cursor()
    
    # Construire la requ√™te dynamiquement
    set_clause = []
    values = []
    
    for key, value in updates.items():
        if key in ['name', 'thumbnail_url', 'banner_url', 'description', 
                   'subscriber_count', 'view_count', 'video_count', 'country', 'language']:
            set_clause.append(f"{key} = ?")
            values.append(value)
    
    if set_clause:
        set_clause.append("last_updated = ?")
        values.append(datetime.now())
        values.append(competitor_id)
        
        query = f"UPDATE concurrent SET {', '.join(set_clause)} WHERE id = ?"
        cursor.execute(query, values)
        conn.commit()
    
    conn.close()

def delete_competitor(competitor_id: int):
    """Supprimer un concurrent et toutes ses vid√©os"""
    conn = get_db_connection()
    cursor = conn.cursor()
    
    # SQLite g√®re automatiquement la suppression en cascade des vid√©os
    cursor.execute('DELETE FROM concurrent WHERE id = ?', (competitor_id,))
    
    conn.commit()
    conn.close()

def competitors_to_legacy_format() -> Dict:
    """Convertir les concurrents de la base vers le format JSON legacy pour compatibilit√©"""
    conn = get_db_connection()
    cursor = conn.cursor()
    
    # R√©cup√©rer tous les concurrents avec leurs vid√©os
    cursor.execute('''
        SELECT c.*, COUNT(v.id) as video_count_actual
        FROM concurrent c
        LEFT JOIN video v ON c.id = v.concurrent_id
        GROUP BY c.id
        ORDER BY c.name
    ''')
    
    competitors = cursor.fetchall()
    legacy_data = {}
    
    for comp in competitors:
        # Cr√©er une cl√© compatible avec l'ancien format
        key = comp['channel_url'].replace('/', '_').replace(':', '_').replace('?', '_').replace('&', '_')
        
        # R√©cup√©rer les vid√©os de ce concurrent
        cursor.execute('''
            SELECT * FROM video WHERE concurrent_id = ? ORDER BY published_at DESC
        ''', (comp['id'],))
        
        videos = []
        for video_row in cursor.fetchall():
            video_dict = dict(video_row)
            # Convertir au format legacy
            videos.append({
                'title': video_dict['title'],
                'url': video_dict['url'],
                'views': video_dict['view_count'] or 0,
                'view_count': video_dict['view_count'] or 0,
                'publication_date': video_dict['published_at'].strftime('%Y-%m-%d') if video_dict['published_at'] and hasattr(video_dict['published_at'], 'strftime') else str(video_dict['published_at']) if video_dict['published_at'] else '',
                'duration': video_dict['duration_text'] or '',
                'thumbnail': video_dict['thumbnail_url'] or '',
                'description': video_dict['description'] or '',
                'likes': video_dict['like_count'],
                'comments': video_dict['comment_count']
            })
        
        legacy_data[key] = {
            'name': comp['name'],
            'channel_url': comp['channel_url'],
            'channel_id': comp['channel_id'],
            'thumbnail': comp['thumbnail_url'],
            'banner': comp['banner_url'],
            'description': comp['description'],
            'subscriber_count': comp['subscriber_count'],
            'view_count': comp['view_count'],
            'video_count': comp['video_count_actual'],  # Utiliser le vrai count
            'country': comp['country'],
            'language': comp['language'],
            'last_updated': comp['last_updated'].strftime('%Y-%m-%d %H:%M:%S') if comp['last_updated'] and hasattr(comp['last_updated'], 'strftime') else str(comp['last_updated']) if comp['last_updated'] else '',
            'videos': videos,
            'total_videos': len(videos),
            'total_views': sum(v.get('view_count', 0) for v in videos)
        }
    
    conn.close()
    return legacy_data

def save_competitor_playlists(competitor_id: int, playlists: List[Dict]):
    """Sauvegarder les playlists d'un concurrent"""
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        for playlist in playlists:
            playlist_id = playlist.get('playlist_id', '')
            name = playlist.get('name', '')[:200]
            description = playlist.get('description', '')
            thumbnail_url = playlist.get('thumbnail_url', '')
            video_count = playlist.get('video_count', 0)
            
            # V√©rifier si la playlist existe d√©j√†
            cursor.execute(
                'SELECT id FROM playlist WHERE playlist_id = ? AND concurrent_id = ?',
                (playlist_id, competitor_id)
            )
            existing = cursor.fetchone()
            
            if existing:
                # Mettre √† jour la playlist existante
                cursor.execute('''
                    UPDATE playlist SET
                        name = ?, description = ?, thumbnail_url = ?, video_count = ?,
                        last_updated = ?
                    WHERE id = ?
                ''', (name, description, thumbnail_url, video_count, datetime.now(), existing[0]))
            else:
                # Cr√©er une nouvelle playlist
                cursor.execute('''
                    INSERT INTO playlist (
                        concurrent_id, playlist_id, name, description, thumbnail_url, video_count,
                        created_at, last_updated
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    competitor_id, playlist_id, name, description, thumbnail_url, video_count,
                    datetime.now(), datetime.now()
                ))
        
        conn.commit()
        print(f"[DB] Sauvegarde termin√©e: {len(playlists)} playlists")
        
    except Exception as e:
        conn.rollback()
        print(f"[DB] Erreur lors de la sauvegarde des playlists: {e}")
        raise
    finally:
        conn.close()

def get_competitor_playlists(competitor_id: int) -> List[Dict]:
    """R√©cup√©rer toutes les playlists d'un concurrent"""
    conn = get_db_connection()
    cursor = conn.cursor()
    
    cursor.execute('''
        SELECT * FROM playlist 
        WHERE concurrent_id = ? 
        ORDER BY video_count DESC, name ASC
    ''', (competitor_id,))
    
    playlists = []
    for row in cursor.fetchall():
        playlists.append(dict(row))
    
    conn.close()
    return playlists

def update_playlist_category(playlist_id: int, category: str):
    """Mettre √† jour la cat√©gorie d'une playlist"""
    conn = get_db_connection()
    cursor = conn.cursor()
    
    cursor.execute('''
        UPDATE playlist SET category = ?, last_updated = ? WHERE id = ?
    ''', (category, datetime.now(), playlist_id))
    
    conn.commit()
    conn.close()

def apply_playlist_categories_to_videos(competitor_id: int):
    """Appliquer automatiquement les cat√©gories des playlists aux vid√©os"""
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        # R√©cup√©rer toutes les playlists cat√©goris√©es du concurrent
        cursor.execute('''
            SELECT id, category FROM playlist 
            WHERE concurrent_id = ? AND category IS NOT NULL
        ''', (competitor_id,))
        
        categorized_playlists = cursor.fetchall()
        videos_updated = 0
        
        for playlist_row in categorized_playlists:
            playlist_db_id = playlist_row[0]
            category = playlist_row[1]
            
            # Mettre √† jour toutes les vid√©os de cette playlist
            cursor.execute('''
                UPDATE video SET category = ?, last_updated = ?
                WHERE id IN (
                    SELECT pv.video_id FROM playlist_video pv
                    WHERE pv.playlist_id = ?
                )
            ''', (category, datetime.now(), playlist_db_id))
            
            videos_updated += cursor.rowcount
        
        conn.commit()
        print(f"[DB] Classification automatique termin√©e: {videos_updated} vid√©os mises √† jour")
        return {
            'videos_updated': videos_updated
        }
        
    except Exception as e:
        conn.rollback()
        print(f"[DB] Erreur lors de la classification automatique: {e}")
        raise
    finally:
        conn.close()

def link_playlist_videos(playlist_db_id: int, video_ids: List[str]):
    """Lier des vid√©os √† une playlist"""
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        for position, video_id in enumerate(video_ids):
            # R√©cup√©rer l'ID de la vid√©o dans notre base
            cursor.execute('SELECT id FROM video WHERE video_id = ?', (video_id,))
            video_row = cursor.fetchone()
            
            if video_row:
                video_db_id = video_row[0]
                
                # Ins√©rer la liaison (ignore si elle existe d√©j√†)
                cursor.execute('''
                    INSERT OR IGNORE INTO playlist_video (playlist_id, video_id, position)
                    VALUES (?, ?, ?)
                ''', (playlist_db_id, video_db_id, position))
        
        conn.commit()
        print(f"[DB] Liaison termin√©e: {len(video_ids)} vid√©os li√©es √† la playlist")
        
    except Exception as e:
        conn.rollback()
        print(f"[DB] Erreur lors de la liaison playlist-vid√©os: {e}")
        raise
    finally:
        conn.close() 

def refresh_competitor_data(channel_url: str, fresh_videos: List[Dict], channel_info: Dict = None) -> Dict:
    """
    Rafra√Æchir intelligemment les donn√©es d'un concurrent existant.
    - Ajoute les nouvelles vid√©os
    - Enrichit les vid√©os existantes en gardant les valeurs maximales (vues, likes, commentaires)
    - Met √† jour les informations de la cha√Æne
    
    Returns:
        Dict avec les statistiques de mise √† jour
    """
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        # V√©rifier si le concurrent existe
        cursor.execute('SELECT id, name FROM concurrent WHERE channel_url = ?', (channel_url,))
        existing = cursor.fetchone()
        
        if not existing:
            # Si le concurrent n'existe pas, utiliser la fonction normale
            competitor_id = save_competitor_and_videos(channel_url, fresh_videos, channel_info)
            return {
                'success': True,
                'action': 'created',
                'competitor_id': competitor_id,
                'new_videos': len(fresh_videos),
                'updated_videos': 0,
                'enriched_videos': 0
            }
        
        competitor_id = existing[0]
        competitor_name = existing[1]
        print(f"[REFRESH] üîÑ Rafra√Æchissement de {competitor_name} (ID {competitor_id})")
        
        # R√©cup√©rer les vid√©os existantes
        cursor.execute('''
            SELECT video_id, view_count, like_count, comment_count, title, url
            FROM video WHERE concurrent_id = ?
        ''', (competitor_id,))
        existing_videos = {row[0]: {
            'view_count': row[1] or 0,
            'like_count': row[2] or 0, 
            'comment_count': row[3] or 0,
            'title': row[4],
            'url': row[5]
        } for row in cursor.fetchall()}
        
        stats = {
            'new_videos': 0,
            'updated_videos': 0,
            'enriched_videos': 0,
            'total_processed': len(fresh_videos)
        }
        
        # Traiter chaque vid√©o fra√Æche
        for video in fresh_videos:
            video_id = extract_video_id_from_url(video.get('url', ''))
            
            # Pr√©parer les donn√©es de base
            title = video.get('title', '')[:200]
            description = video.get('description', '')
            url = video.get('url', '')
            thumbnail_url = video.get('thumbnail', '')
            
            # Traiter la date de publication
            published_at = None
            if video.get('publication_date'):
                try:
                    date_str = video['publication_date']
                    if 'il y a' in date_str:
                        published_at = datetime.now()
                    else:
                        published_at = datetime.strptime(date_str, '%Y-%m-%d')
                except:
                    published_at = datetime.now()
            
            # Traiter la dur√©e
            duration_seconds = None
            duration_text = video.get('duration', '')
            if duration_text:
                try:
                    parts = duration_text.split(':')
                    if len(parts) == 2:
                        duration_seconds = int(parts[0]) * 60 + int(parts[1])
                    elif len(parts) == 3:
                        duration_seconds = int(parts[0]) * 3600 + int(parts[1]) * 60 + int(parts[2])
                except:
                    pass
            
            # Traiter les m√©triques avec valeurs par d√©faut
            fresh_view_count = video.get('views') or video.get('view_count') or 0
            if isinstance(fresh_view_count, str):
                fresh_view_count = int(re.sub(r'[^\d]', '', fresh_view_count)) if re.sub(r'[^\d]', '', fresh_view_count) else 0
            
            fresh_like_count = video.get('likes') or video.get('like_count') or 0
            if isinstance(fresh_like_count, str):
                fresh_like_count = int(re.sub(r'[^\d]', '', fresh_like_count)) if re.sub(r'[^\d]', '', fresh_like_count) else 0
                
            fresh_comment_count = video.get('comments') or video.get('comment_count') or 0
            if isinstance(fresh_comment_count, str):
                fresh_comment_count = int(re.sub(r'[^\d]', '', fresh_comment_count)) if re.sub(r'[^\d]', '', fresh_comment_count) else 0
            
            if video_id in existing_videos:
                # Vid√©o existante : ENRICHIR avec les valeurs maximales
                existing = existing_videos[video_id]
                
                # Prendre les valeurs maximales
                max_views = max(existing['view_count'], fresh_view_count)
                max_likes = max(existing['like_count'], fresh_like_count)
                max_comments = max(existing['comment_count'], fresh_comment_count)
                
                # D√©terminer si on a enrichi les donn√©es
                enriched = (
                    max_views > existing['view_count'] or 
                    max_likes > existing['like_count'] or 
                    max_comments > existing['comment_count']
                )
                
                if enriched:
                    stats['enriched_videos'] += 1
                    print(f"[REFRESH] üìà Enrichi: {title[:50]}... "
                          f"(vues: {existing['view_count']} ‚Üí {max_views}, "
                          f"likes: {existing['like_count']} ‚Üí {max_likes})")
                
                # Mettre √† jour avec les valeurs maximales
                cursor.execute('''
                    UPDATE video SET
                        title = ?, description = ?, thumbnail_url = ?,
                        published_at = ?, duration_seconds = ?, duration_text = ?,
                        view_count = ?, like_count = ?, comment_count = ?,
                        last_updated = ?
                    WHERE concurrent_id = ? AND video_id = ?
                ''', (
                    title, description, thumbnail_url,
                    published_at, duration_seconds, duration_text,
                    max_views, max_likes, max_comments,
                    datetime.now(), competitor_id, video_id
                ))
                
                stats['updated_videos'] += 1
                
            else:
                # Nouvelle vid√©o : AJOUTER
                cursor.execute('''
                    INSERT INTO video (
                        concurrent_id, video_id, title, description, url, thumbnail_url,
                        published_at, duration_seconds, duration_text,
                        view_count, like_count, comment_count,
                        created_at, last_updated
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    competitor_id, video_id, title, description, url, thumbnail_url,
                    published_at, duration_seconds, duration_text,
                    fresh_view_count, fresh_like_count, fresh_comment_count,
                    datetime.now(), datetime.now()
                ))
                
                stats['new_videos'] += 1
                print(f"[REFRESH] ‚ú® Nouvelle: {title[:50]}... ({fresh_view_count} vues)")
        
        # Mettre √† jour les informations de la cha√Æne si disponibles
        if channel_info:
            updates = {
                'thumbnail_url': channel_info.get('thumbnail', ''),
                'banner_url': channel_info.get('banner', ''),
                'description': channel_info.get('description', ''),
                'subscriber_count': channel_info.get('subscriber_count'),
                'view_count': channel_info.get('view_count'),
                'country': channel_info.get('country', ''),
                'language': channel_info.get('language', ''),
                'last_updated': datetime.now()
            }
            
            # Construire la requ√™te de mise √† jour dynamiquement
            set_clauses = []
            values = []
            for key, value in updates.items():
                if value is not None:
                    set_clauses.append(f"{key} = ?")
                    values.append(value)
            
            if set_clauses:
                values.append(competitor_id)
                cursor.execute(f'''
                    UPDATE concurrent SET {', '.join(set_clauses)} WHERE id = ?
                ''', values)
                
                # Enregistrer l'√©volution des statistiques
                try:
                    # Analytics export supprim√© - analyse locale maintenant
                    track_competitor_update(competitor_id, channel_info)
                except Exception as e:
                    print(f"[REFRESH] ‚ö†Ô∏è Erreur lors du tracking: {e}")
        
        # Mettre √† jour le nombre total de vid√©os
        cursor.execute('SELECT COUNT(*) FROM video WHERE concurrent_id = ?', (competitor_id,))
        total_videos = cursor.fetchone()[0]
        
        cursor.execute('''
            UPDATE concurrent SET video_count = ?, last_updated = ? WHERE id = ?
        ''', (total_videos, datetime.now(), competitor_id))
        
        conn.commit()
        
        print(f"[REFRESH] ‚úÖ Rafra√Æchissement termin√© pour {competitor_name}:")
        print(f"  ‚Ä¢ {stats['new_videos']} nouvelles vid√©os")
        print(f"  ‚Ä¢ {stats['updated_videos']} vid√©os mises √† jour")
        print(f"  ‚Ä¢ {stats['enriched_videos']} vid√©os enrichies")
        print(f"  ‚Ä¢ {total_videos} vid√©os au total")
        
        return {
            'success': True,
            'action': 'refreshed',
            'competitor_id': competitor_id,
            'competitor_name': competitor_name,
            'total_videos': total_videos,
            **stats
        }
        
    except Exception as e:
        conn.rollback()
        print(f"[REFRESH] ‚ùå Erreur lors du rafra√Æchissement: {e}")
        return {
            'success': False,
            'error': str(e)
        }
    finally:
        conn.close() 

def get_all_competitors_with_videos() -> List[Dict]:
    """
    R√©cup√©rer tous les concurrents avec leurs vid√©os
    
    Returns:
        List[Dict]: Liste des concurrents avec leurs vid√©os
    """
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        # R√©cup√©rer tous les concurrents
        cursor.execute('''
            SELECT id, name, channel_id, channel_url, thumbnail_url, banner_url,
                   description, subscriber_count, view_count, video_count,
                   country, language, created_at, last_updated
            FROM concurrent
            ORDER BY last_updated DESC
        ''')
        
        competitors = []
        for row in cursor.fetchall():
            competitor = {
                'id': row[0],
                'name': row[1],
                'channel_id': row[2],
                'channel_url': row[3],
                'thumbnail_url': row[4],
                'banner_url': row[5],
                'description': row[6],
                'subscriber_count': row[7],
                'view_count': row[8],
                'video_count': row[9],
                'country': row[10],
                'language': row[11],
                'created_at': row[12],
                'last_updated': row[13]
            }
            
            # R√©cup√©rer les vid√©os pour ce concurrent
            cursor.execute('''
                SELECT video_id, title, description, url, thumbnail_url,
                       published_at, duration_seconds, duration_text,
                       view_count, like_count, comment_count, category
                FROM video
                WHERE concurrent_id = ?
                ORDER BY published_at DESC
            ''', (competitor['id'],))
            
            videos = []
            for video_row in cursor.fetchall():
                video = {
                    'video_id': video_row[0],
                    'title': video_row[1],
                    'description': video_row[2],
                    'url': video_row[3],
                    'thumbnail': video_row[4],
                    'published_at': video_row[5],
                    'duration_seconds': video_row[6],
                    'duration': video_row[7],
                    'view_count': video_row[8] or 0,
                    'like_count': video_row[9] or 0,
                    'comment_count': video_row[10] or 0,
                    'category': video_row[11]
                }
                videos.append(video)
            
            # Calculer les vues totales
            competitor['videos'] = videos
            competitor['total_views'] = sum(video.get('view_count', 0) or 0 for video in videos)
            competitors.append(competitor)
        
        return competitors
        
    finally:
        conn.close() 

def clean_duplicate_competitors() -> Dict:
    """
    Nettoyer les doublons de concurrents en gardant celui avec le plus de vid√©os.
    Utilise le nom ET l'URL de cha√Æne pour d√©tecter les doublons.
    
    Returns:
        Dict avec les statistiques de nettoyage
    """
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        print("[DB-CLEAN] üßπ D√©but du nettoyage des doublons...")
        
        # R√©cup√©rer tous les concurrents avec leur nombre de vid√©os
        cursor.execute('''
            SELECT c.id, c.name, c.channel_url, c.channel_id, 
                   COUNT(v.id) as video_count,
                   c.created_at, c.last_updated
            FROM concurrent c
            LEFT JOIN video v ON c.id = v.concurrent_id
            GROUP BY c.id
            ORDER BY c.name, video_count DESC
        ''')
        
        competitors = cursor.fetchall()
        
        if not competitors:
            return {'success': True, 'deleted_count': 0, 'message': 'Aucun concurrent trouv√©'}
        
        # Grouper par nom (insensible √† la casse) et URL similaire
        groups = {}
        for comp in competitors:
            comp_id, name, channel_url, channel_id, video_count, created_at, last_updated = comp
            
            # Cl√© de groupement : nom nettoy√© + channel_id si disponible
            name_clean = name.lower().strip()
            group_key = name_clean
            
            # Si on a un channel_id, l'utiliser comme cl√© plus pr√©cise
            if channel_id:
                group_key = f"{name_clean}_{channel_id}"
            
            if group_key not in groups:
                groups[group_key] = []
            
            groups[group_key].append({
                'id': comp_id,
                'name': name,
                'channel_url': channel_url,
                'channel_id': channel_id,
                'video_count': video_count,
                'created_at': created_at,
                'last_updated': last_updated
            })
        
        # Identifier et supprimer les doublons
        deleted_count = 0
        kept_competitors = []
        
        for group_key, group_competitors in groups.items():
            if len(group_competitors) > 1:
                # Trier par nombre de vid√©os (desc) puis par date de cr√©ation (plus r√©cent)
                group_competitors.sort(key=lambda x: (-x['video_count'], x['last_updated'] or ''), reverse=True)
                
                # Garder le premier (celui avec le plus de vid√©os)
                best = group_competitors[0]
                to_delete = group_competitors[1:]
                
                print(f"[DB-CLEAN] üîç Doublons trouv√©s pour '{best['name']}':")
                print(f"  ‚úÖ GARDE: ID {best['id']} - {best['video_count']} vid√©os - {best['channel_url']}")
                
                # Supprimer les doublons
                for duplicate in to_delete:
                    print(f"  ‚ùå SUPPRIME: ID {duplicate['id']} - {duplicate['video_count']} vid√©os - {duplicate['channel_url']}")
                    
                    # Supprimer le concurrent (les vid√©os sont supprim√©es par CASCADE)
                    cursor.execute('DELETE FROM concurrent WHERE id = ?', (duplicate['id'],))
                    deleted_count += 1
                
                kept_competitors.append(best)
            else:
                # Pas de doublon, garder tel quel
                kept_competitors.append(group_competitors[0])
        
        # Valider les changements
        conn.commit()
        
        print(f"[DB-CLEAN] ‚úÖ Nettoyage termin√©:")
        print(f"  ‚Ä¢ {deleted_count} doublons supprim√©s")
        print(f"  ‚Ä¢ {len(kept_competitors)} concurrents uniques conserv√©s")
        
        # Afficher le r√©sultat final
        for comp in kept_competitors:
            print(f"  üìä {comp['name']}: {comp['video_count']} vid√©os")
        
        return {
            'success': True,
            'deleted_count': deleted_count,
            'kept_count': len(kept_competitors),
            'competitors': kept_competitors,
            'message': f'{deleted_count} doublons supprim√©s, {len(kept_competitors)} concurrents uniques conserv√©s'
        }
        
    except Exception as e:
        conn.rollback()
        print(f"[DB-CLEAN] ‚ùå Erreur lors du nettoyage: {e}")
        return {
            'success': False,
            'error': str(e)
        }
    finally:
        conn.close() 

def get_all_competitors_urls():
    """R√©cup√®re toutes les URLs des concurrents en base de donn√©es"""
    try:
        connection = sqlite3.connect(DB_PATH)
        cursor = connection.cursor()
        
        cursor.execute("SELECT channel_url FROM concurrent")
        urls = [row[0] for row in cursor.fetchall()]
        
        connection.close()
        return urls
        
    except Exception as e:
        print(f"[DATABASE] Erreur lors de la r√©cup√©ration des URLs des concurrents: {e}")
        return [] 

def update_competitor_country(competitor_id, country):
    """Met √† jour le pays d'un concurrent"""
    try:
        connection = sqlite3.connect(DB_PATH)
        cursor = connection.cursor()
        
        cursor.execute("""
            UPDATE concurrent 
            SET country = ?, last_updated = CURRENT_TIMESTAMP
            WHERE id = ?
        """, (country, competitor_id))
        
        connection.commit()
        connection.close()
        
        return True
        
    except Exception as e:
        print(f"[DATABASE] Erreur lors de la mise √† jour du pays: {e}")
        return False

def get_competitors_by_country():
    """R√©cup√®re les concurrents group√©s par pays"""
    try:
        connection = sqlite3.connect(DB_PATH)
        cursor = connection.cursor()
        
        cursor.execute("""
            SELECT country, COUNT(*) as count, 
                   GROUP_CONCAT(name, ', ') as competitors
            FROM concurrent 
            GROUP BY country
            ORDER BY country
        """)
        
        results = []
        for row in cursor.fetchall():
            results.append({
                'country': row[0] if row[0] else 'Non d√©fini',
                'count': row[1],
                'competitors': row[2]
            })
        
        connection.close()
        return results
        
    except Exception as e:
        print(f"[DATABASE] Erreur lors de la r√©cup√©ration par pays: {e}")
        return [] 

def classify_playlist_with_ai(name: str, description: str = "") -> str:
    """
    Classifier automatiquement une playlist en analysant son nom et sa description
    Retourne 'hero', 'hub' ou 'help'
    """
    # Nettoyer et normaliser le texte
    text = f"{name} {description}".lower().strip()
    
    # Mots-cl√©s pour chaque cat√©gorie (50+ mots-cl√©s par cat√©gorie)
    hero_keywords = [
        # Exp√©riences exceptionnelles
        'best', 'meilleur', 'top', 'incroyable', 'amazing', 'incredible', 'spectacular',
        'luxury', 'luxe', 'premium', 'exclusive', 'exclusif', 'unique', 'extraordinary',
        'destination', 'voyage', 'travel', 'adventure', 'aventure', 'epic', '√©pique',
        'experience', 'exp√©rience', 'd√©couverte', 'discovery', 'exploration',
        'must', 'essentiels', 'featured', 'highlights', 'coup de coeur', 'unforgettable',
        'recommendation', 'recommandation', 'favorite', 'favori', 'preferred',
        'inspiration', 'dream', 'r√™ve', 'bucket list', 'wishlist', 'fantasy',
        # Performance et succ√®s
        'ultimate', 'ultime', 'supreme', 'supr√™me', 'world class', 'classe mondiale',
        'exceptional', 'exceptionnel', 'outstanding', 'remarquable', 'stunning',
        'breathtaking', '√† couper le souffle', 'magnificent', 'magnifique',
        'extraordinary', 'extraordinaire', 'legendary', 'l√©gendaire', 'iconic',
        'prestigious', 'prestigieux', 'award', 'prix', 'winner', 'gagnant',
        # √âmotions fortes
        'magical', 'magique', 'enchanting', 'enchanteur', 'mesmerizing',
        'captivating', 'captivant', 'thrilling', 'palpitant', 'exhilarating',
        'mind-blowing', '√©poustouflant', 'life-changing', 'transformant'
    ]
    
    hub_keywords = [
        # Contenu r√©gulier/hub
        'how to', 'comment', 'tutorial', 'tutoriel', 'guide', 'tips', 'conseils',
        'planning', 'planifier', 'organize', 'organiser', 'prepare', 'pr√©parer',
        'practical', 'pratique', 'useful', 'utile', 'everyday', 'quotidien',
        'general', 'g√©n√©ral', 'overview', 'aper√ßu', 'basics', 'base', 'introduction',
        'information', 'info', 'facts', 'faits', 'details', 'd√©tails', 'data',
        'series', 's√©rie', 'collection', 'regular', 'r√©gulier', 'weekly', 'monthly',
        # Organisation et structure
        'schedule', 'programme', 'agenda', 'calendar', 'calendrier', 'timeline',
        'checklist', 'liste', 'steps', '√©tapes', 'process', 'processus',
        'method', 'm√©thode', 'technique', 'approach', 'approche', 'strategy',
        'system', 'syst√®me', 'framework', 'structure', 'organization',
        # Contenu informatif
        'review', 'revue', 'analysis', 'analyse', 'comparison', 'comparaison',
        'update', 'mise √† jour', 'news', 'nouvelles', 'report', 'rapport',
        'summary', 'r√©sum√©', 'recap', 'r√©capitulatif', 'overview', 'survol',
        'breakdown', 'd√©composition', 'explanation', 'explication', 'insight',
        'behind the scenes', 'en coulisses', 'making of', 'process', 'workflow',
        # Cat√©gories g√©n√©rales
        'standard', 'normal', 'typical', 'typique', 'common', 'commun',
        'regular', 'r√©gulier', 'routine', 'habitual', 'ordinary', 'ordinaire'
    ]
    
    help_keywords = [
        # Support/aide
        'help', 'aide', 'support', 'problem', 'probl√®me', 'issue', 'question',
        'faq', 'frequently', 'fr√©quent', 'common', 'commun', 'typical', 'typique',
        'solve', 'r√©soudre', 'fix', 'r√©parer', 'troubleshoot', 'd√©pannage',
        'step by step', '√©tape par √©tape', 'beginner', 'd√©butant', 'basics', 'base',
        'learn', 'apprendre', 'understand', 'comprendre', 'explain', 'expliquer',
        'avoid', '√©viter', 'mistake', 'erreur', 'warning', 'attention', 'caution',
        # Apprentissage et formation
        'tutorial', 'tutoriel', 'lesson', 'le√ßon', 'course', 'cours', 'training',
        'workshop', 'atelier', 'masterclass', 'formation', 'education', '√©ducation',
        'instruction', 'instruction', 'demonstration', 'd√©monstration', 'example',
        'exemple', 'practice', 'pratique', 'exercise', 'exercice', 'drill',
        # R√©solution de probl√®mes
        'solution', 'resolution', 'answer', 'r√©ponse', 'remedy', 'rem√®de',
        'cure', 'gu√©rison', 'treatment', 'traitement', 'therapy', 'th√©rapie',
        'diagnosis', 'diagnostic', 'troubleshooting', 'd√©pannage', 'debugging',
        'repair', 'r√©paration', 'maintenance', 'entretien', 'service', 'assistance',
        # Orientation et conseils
        'guidance', 'orientation', 'advice', 'conseil', 'recommendation', 'recommandation',
        'suggestion', 'suggestion', 'tip', 'astuce', 'trick', 'truc', 'hack',
        'secret', 'secret', 'insider', 'initi√©', 'expert', 'specialist', 'professional',
        'consultation', 'mentoring', 'coaching', 'counseling', 'consulting'
    ]
    
    # Compter les occurrences pour chaque cat√©gorie
    hero_score = sum(1 for keyword in hero_keywords if keyword in text)
    hub_score = sum(1 for keyword in hub_keywords if keyword in text)
    help_score = sum(1 for keyword in help_keywords if keyword in text)
    
    # Heuristiques suppl√©mentaires bas√©es sur la structure du nom
    if any(word in text for word in ['best of', 'top 10', 'top 5', 'highlights', 'most beautiful', 'plus beaux']):
        hero_score += 3
    
    if any(word in text for word in ['guide complet', 'complete guide', 'everything about', 'tout sur']):
        hub_score += 3
        
    if any(word in text for word in ['how to', 'comment faire', 'tutorial step', 'pas √† pas']):
        help_score += 3
    
    # Patterns sp√©ciaux
    if any(word in text for word in ['collection', 'compilation', 'playlist officielle', 'official playlist']):
        hub_score += 2
        
    if any(word in text for word in ['d√©butant', 'beginner', 'first time', 'premi√®re fois']):
        help_score += 2
        
    if any(word in text for word in ['exclusive', 'premium', 'vip', 'special edition']):
        hero_score += 2
    
    # D√©terminer la cat√©gorie avec le score le plus √©lev√©
    scores = {'hero': hero_score, 'hub': hub_score, 'help': help_score}
    max_category = max(scores, key=scores.get)
    max_score = scores[max_category]
    
    # Si aucun score ou √©galit√©, classer comme 'hub' par d√©faut
    if max_score == 0 or list(scores.values()).count(max_score) > 1:
        return 'hub'
    
    return max_category

def auto_classify_uncategorized_playlists(competitor_id: int) -> Dict:
    """
    Classifier automatiquement avec l'IA toutes les playlists non cat√©goris√©es d'un concurrent
    """
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        # R√©cup√©rer toutes les playlists non cat√©goris√©es
        cursor.execute('''
            SELECT id, name, description FROM playlist 
            WHERE concurrent_id = ? AND (category IS NULL OR category = '')
        ''', (competitor_id,))
        
        uncategorized_playlists = cursor.fetchall()
        
        if not uncategorized_playlists:
            return {
                'success': True,
                'message': 'Aucune playlist non cat√©goris√©e trouv√©e',
                'classified_count': 0,
                'classifications': []
            }
        
        classifications = []
        classified_count = 0
        
        for playlist_row in uncategorized_playlists:
            playlist_id = playlist_row[0]
            name = playlist_row[1] or ''
            description = playlist_row[2] or ''
            
            # Classifier avec l'IA
            predicted_category = classify_playlist_with_ai(name, description)
            
            # Mettre √† jour en base
            cursor.execute('''
                UPDATE playlist SET category = ?, last_updated = ? WHERE id = ?
            ''', (predicted_category, datetime.now(), playlist_id))
            
            classifications.append({
                'name': name,
                'predicted_category': predicted_category,
                'confidence': 'medium'  # Pour l'instant toujours medium
            })
            
            classified_count += 1
            print(f"[IA-CLASSIFY] ‚ú® {name} ‚Üí {predicted_category.upper() if predicted_category else 'NON_CLASSE'}")
        
        conn.commit()
        
        return {
            'success': True,
            'message': f'{classified_count} playlists classifi√©es automatiquement',
            'classified_count': classified_count,
            'classifications': classifications
        }
        
    except Exception as e:
        conn.rollback()
        print(f"[IA-CLASSIFY] ‚ùå Erreur: {e}")
        return {
            'success': False,
            'error': str(e),
            'classified_count': 0
        }
    finally:
        conn.close() 

# --- GESTION DES PATTERNS IA ---

def get_classification_patterns() -> Dict:
    """R√©cup√©rer tous les patterns de classification IA"""
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        # V√©rifier si la table patterns existe, sinon la cr√©er
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS classification_patterns (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                category VARCHAR(10) NOT NULL,
                pattern VARCHAR(200) NOT NULL,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(category, pattern)
            )
        ''')
        
        # R√©cup√©rer les patterns existants
        cursor.execute('''
            SELECT category, pattern FROM classification_patterns 
            ORDER BY category, pattern
        ''')
        
        patterns = {'hero': [], 'hub': [], 'help': []}
        for row in cursor.fetchall():
            category, pattern = row
            if category in patterns:
                patterns[category].append(pattern)
        
        # Si aucun pattern n'existe, initialiser avec les patterns par d√©faut
        if not any(patterns.values()):
            default_patterns = get_default_classification_patterns()
            for category, pattern_list in default_patterns.items():
                for pattern in pattern_list:
                    cursor.execute('''
                        INSERT OR IGNORE INTO classification_patterns (category, pattern)
                        VALUES (?, ?)
                    ''', (category, pattern))
            conn.commit()
            patterns = default_patterns
        
        return patterns
        
    except Exception as e:
        print(f"[PATTERNS] Erreur: {e}")
        return get_default_classification_patterns()
    finally:
        conn.close()

def get_default_classification_patterns() -> Dict:
    """Patterns par d√©faut pour la classification IA"""
    return {
        'hero': [
            'best', 'meilleur', 'top', 'incroyable', 'amazing', 'incredible', 'spectacular',
            'luxury', 'luxe', 'premium', 'exclusive', 'exclusif', 'unique', 'extraordinary',
            'destination', 'voyage', 'travel', 'adventure', 'aventure', 'epic', '√©pique',
            'experience', 'exp√©rience', 'd√©couverte', 'discovery', 'exploration',
            'must', 'essentiels', 'featured', 'highlights', 'coup de coeur', 'unforgettable',
            'recommendation', 'recommandation', 'favorite', 'favori', 'preferred',
            'inspiration', 'dream', 'r√™ve', 'bucket list', 'wishlist', 'fantasy',
            'ultimate', 'ultime', 'supreme', 'supr√™me', 'world class', 'classe mondiale',
            'exceptional', 'exceptionnel', 'outstanding', 'remarquable', 'stunning',
            'breathtaking', '√† couper le souffle', 'magnificent', 'magnifique',
            'legendary', 'l√©gendaire', 'iconic', 'prestigious', 'prestigieux'
        ],
        'hub': [
            'how to', 'comment', 'tutorial', 'tutoriel', 'guide', 'tips', 'conseils',
            'planning', 'planifier', 'organize', 'organiser', 'prepare', 'pr√©parer',
            'practical', 'pratique', 'useful', 'utile', 'everyday', 'quotidien',
            'general', 'g√©n√©ral', 'overview', 'aper√ßu', 'basics', 'base', 'introduction',
            'information', 'info', 'facts', 'faits', 'details', 'd√©tails', 'data',
            'series', 's√©rie', 'collection', 'regular', 'r√©gulier', 'weekly', 'monthly',
            'schedule', 'programme', 'agenda', 'calendar', 'calendrier', 'timeline',
            'checklist', 'liste', 'steps', '√©tapes', 'process', 'processus',
            'method', 'm√©thode', 'technique', 'approach', 'approche', 'strategy',
            'review', 'revue', 'analysis', 'analyse', 'comparison', 'comparaison'
        ],
        'help': [
            'help', 'aide', 'support', 'problem', 'probl√®me', 'issue', 'question',
            'faq', 'frequently', 'fr√©quent', 'common', 'commun', 'typical', 'typique',
            'solve', 'r√©soudre', 'fix', 'r√©parer', 'troubleshoot', 'd√©pannage',
            'step by step', '√©tape par √©tape', 'beginner', 'd√©butant', 'basics', 'base',
            'learn', 'apprendre', 'understand', 'comprendre', 'explain', 'expliquer',
            'avoid', '√©viter', 'mistake', 'erreur', 'warning', 'attention', 'caution',
            'tutorial', 'tutoriel', 'lesson', 'le√ßon', 'course', 'cours', 'training',
            'solution', 'resolution', 'answer', 'r√©ponse', 'remedy', 'rem√®de',
            'guidance', 'orientation', 'advice', 'conseil', 'recommendation',
            'consultation', 'mentoring', 'coaching', 'counseling', 'consulting'
        ]
    }

def add_classification_pattern(category: str, pattern: str) -> bool:
    """Ajouter un nouveau pattern de classification"""
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        cursor.execute('''
            INSERT OR IGNORE INTO classification_patterns (category, pattern)
            VALUES (?, ?)
        ''', (category, pattern.lower().strip()))
        
        conn.commit()
        return cursor.rowcount > 0
        
    except Exception as e:
        print(f"[PATTERNS] Erreur ajout: {e}")
        return False
    finally:
        conn.close()

def remove_classification_pattern(category: str, pattern: str) -> bool:
    """Supprimer un pattern de classification"""
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        cursor.execute('''
            DELETE FROM classification_patterns 
            WHERE category = ? AND pattern = ?
        ''', (category, pattern.lower().strip()))
        
        conn.commit()
        return cursor.rowcount > 0
        
    except Exception as e:
        print(f"[PATTERNS] Erreur suppression: {e}")
        return False
    finally:
        conn.close()

def get_ai_classification_setting() -> bool:
    """R√©cup√©rer le param√®tre de classification IA automatique"""
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        # Cr√©er la table settings si elle n'existe pas
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS app_settings (
                key VARCHAR(50) PRIMARY KEY,
                value TEXT NOT NULL,
                updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        cursor.execute('''
            SELECT value FROM app_settings WHERE key = 'ai_classification_enabled'
        ''')
        
        result = cursor.fetchone()
        return result[0] == 'true' if result else False
        
    except Exception as e:
        print(f"[SETTINGS] Erreur: {e}")
        return False
    finally:
        conn.close()

def set_ai_classification_setting(enabled: bool) -> bool:
    """D√©finir le param√®tre de classification IA automatique"""
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        cursor.execute('''
            INSERT OR REPLACE INTO app_settings (key, value, updated_at)
            VALUES ('ai_classification_enabled', ?, ?)
        ''', ('true' if enabled else 'false', datetime.now()))
        
        conn.commit()
        return True
        
    except Exception as e:
        print(f"[SETTINGS] Erreur: {e}")
        return False
    finally:
        conn.close()

def classify_videos_directly_with_keywords(competitor_id: int) -> Dict:
    """
    Classifier directement les vid√©os non cat√©goris√©es en utilisant les mots-cl√©s configur√©s
    """
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        # R√©cup√©rer toutes les vid√©os non cat√©goris√©es du concurrent
        cursor.execute('''
            SELECT id, title, description FROM video 
            WHERE concurrent_id = ? AND (category IS NULL OR category = '')
        ''', (competitor_id,))
        
        uncategorized_videos = cursor.fetchall()
        
        if not uncategorized_videos:
            return {
                'success': True,
                'message': 'Aucune vid√©o non cat√©goris√©e trouv√©e',
                'videos_classified': 0
            }
        
        videos_classified = 0
        
        for video_row in uncategorized_videos:
            video_id = video_row[0]
            title = video_row[1] or ''
            description = video_row[2] or ''
            
            # Classifier avec les mots-cl√©s configur√©s
            predicted_category = classify_playlist_with_ai(title, description)
            
            # Mettre √† jour en base
            cursor.execute('''
                UPDATE video SET category = ?, last_updated = ? WHERE id = ?
            ''', (predicted_category, datetime.now(), video_id))
            
            videos_classified += 1
            
            # Log seulement quelques exemples pour √©viter le spam
            if videos_classified <= 5:
                print(f"[DIRECT-CLASSIFY] ‚ú® {title} ‚Üí {predicted_category.upper() if predicted_category else 'NON_CLASSE'}")
        
        conn.commit()
        
        if videos_classified > 5:
            print(f"[DIRECT-CLASSIFY] ‚ú® ... et {videos_classified - 5} vid√©os suppl√©mentaires classifi√©es")
        
        return {
            'success': True,
            'videos_classified': videos_classified,
            'message': f'{videos_classified} vid√©os classifi√©es directement'
        }
        
    except Exception as e:
        print(f"[DIRECT-CLASSIFY] ‚ùå Erreur: {e}")
        return {
            'success': False,
            'error': str(e),
            'videos_classified': 0
        }
    finally:
        conn.close()

def run_global_ai_classification() -> Dict:
    """
    Lance la classification IA globale sur tous les concurrents
    Classifie les playlists puis applique aux vid√©os, puis classifie directement les vid√©os restantes
    """
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        # R√©cup√©rer tous les concurrents
        cursor.execute('SELECT id, name FROM concurrent ORDER BY name')
        competitors = cursor.fetchall()
        
        if not competitors:
            return {
                'success': True,
                'message': 'Aucun concurrent trouv√©',
                'competitors_count': 0,
                'playlists_classified': 0,
                'videos_classified': 0
            }
        
        total_playlists_classified = 0
        total_videos_classified = 0
        competitors_with_playlists = 0
        
        for competitor_row in competitors:
            competitor_id = competitor_row[0]
            competitor_name = competitor_row[1]
            
            print(f"[GLOBAL-AI] üéØ Traitement de {competitor_name}...")
            
            # 1. Classifier les playlists non cat√©goris√©es
            playlist_result = auto_classify_uncategorized_playlists(competitor_id)
            if playlist_result.get('classified_count', 0) > 0:
                total_playlists_classified += playlist_result['classified_count']
                competitors_with_playlists += 1
                print(f"[GLOBAL-AI] ‚ú® {competitor_name}: {playlist_result['classified_count']} playlists classifi√©es")
            
            # 2. Appliquer les cat√©gories des playlists aux vid√©os
            video_result = apply_playlist_categories_to_videos(competitor_id)
            if video_result.get('videos_updated', 0) > 0:
                total_videos_classified += video_result['videos_updated']
                print(f"[GLOBAL-AI] üìπ {competitor_name}: {video_result['videos_updated']} vid√©os classifi√©es via playlists")
            
            # 3. Classifier directement les vid√©os restantes non cat√©goris√©es
            direct_result = classify_videos_directly_with_keywords(competitor_id)
            if direct_result.get('videos_classified', 0) > 0:
                total_videos_classified += direct_result['videos_classified']
                print(f"[GLOBAL-AI] üé¨ {competitor_name}: {direct_result['videos_classified']} vid√©os classifi√©es directement")
        
        conn.commit()
        
        return {
            'success': True,
            'competitors_count': len(competitors),
            'competitors_with_playlists': competitors_with_playlists,
            'playlists_classified': total_playlists_classified,
            'videos_classified': total_videos_classified,
            'message': f'Classification globale termin√©e: {len(competitors)} concurrents trait√©s'
        }
        
    except Exception as e:
        print(f"[GLOBAL-AI] ‚ùå Erreur: {e}")
        return {
            'success': False,
            'error': str(e),
            'competitors_count': 0,
            'playlists_classified': 0,
            'videos_classified': 0
        }
    finally:
        conn.close() 

def generate_country_insights() -> Dict:
    """
    G√©n√®re des insights et guidelines par pays bas√©s sur l'analyse des donn√©es r√©elles
    """
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        # R√©cup√©rer tous les concurrents avec leurs vid√©os par pays
        cursor.execute('''
            SELECT 
                c.country,
                c.name as competitor_name,
                v.title,
                v.duration_seconds,
                v.view_count,
                v.like_count,
                v.comment_count,
                v.published_at,
                v.category,
                strftime('%H', v.published_at) as hour_published,
                strftime('%w', v.published_at) as day_of_week
            FROM concurrent c
            LEFT JOIN video v ON c.id = v.concurrent_id
            WHERE v.view_count IS NOT NULL 
            AND v.view_count > 0
            AND c.country IS NOT NULL 
            AND c.country != ''
        ''')
        
        results = cursor.fetchall()
        
        # Organiser les donn√©es par pays
        countries_data = {}
        
        for row in results:
            country = row[0]
            if country not in countries_data:
                countries_data[country] = {
                    'videos': [],
                    'competitors': set()
                }
            
            countries_data[country]['competitors'].add(row[1])
            countries_data[country]['videos'].append({
                'title': row[2],
                'duration_seconds': row[3],
                'view_count': row[4] or 0,
                'like_count': row[5] or 0,
                'comment_count': row[6] or 0,
                'published_at': row[7],
                'category': row[8],
                'hour_published': int(row[9]) if row[9] else None,
                'day_of_week': int(row[10]) if row[10] else None
            })
        
        # G√©n√©rer les insights pour chaque pays
        insights = {}
        
        for country, data in countries_data.items():
            videos = data['videos']
            if len(videos) < 20:  # Pas assez de donn√©es
                continue
                
            # Calculer les statistiques
            insights[country] = _analyze_country_performance(country, videos, len(data['competitors']))
        
        return {
            'insights': insights,
            'generated_at': datetime.now().isoformat(),
            'total_countries': len(insights),
            'total_videos_analyzed': sum(len(data['videos']) for data in countries_data.values())
        }
        
    finally:
        conn.close()

def _analyze_country_performance(country: str, videos: List[Dict], competitor_count: int) -> Dict:
    """
    Analyse les performances d'un pays sp√©cifique et g√©n√®re des insights
    """
    if not videos:
        return {}
    
    # Trier par performance (vues)
    videos_sorted = sorted(videos, key=lambda x: x['view_count'], reverse=True)
    
    # Top 20% des vid√©os les plus performantes
    top_20_percent = videos_sorted[:max(1, len(videos_sorted) // 5)]
    
    # Analyse de la dur√©e optimale
    duration_insights = _analyze_optimal_duration(top_20_percent, videos)
    
    # Analyse des heures de publication optimales
    timing_insights = _analyze_optimal_timing(top_20_percent)
    
    # Analyse des cat√©gories performantes
    category_insights = _analyze_category_performance(top_20_percent, videos)
    
    # Analyse de l'engagement
    engagement_insights = _analyze_engagement_patterns(top_20_percent)
    
    # üÜï NOUVEAUX INSIGHTS ACTIONABLES
    # Analyse des hooks et patterns qui cr√©ent l'engagement
    hook_insights = _analyze_engagement_hooks(top_20_percent, videos)
    
    # Analyse du temps de d√©crochage (corr√©lation dur√©e vs engagement)
    dropoff_insights = _analyze_dropoff_patterns(top_20_percent, videos)
    
    # Analyse des mots-cl√©s qui performent
    keyword_insights = _analyze_performance_keywords(top_20_percent)
    
    # Calculer les scores globaux
    avg_views = sum(v['view_count'] for v in videos) / len(videos)
    avg_engagement = sum(v['like_count'] / max(v['view_count'], 1) for v in videos) / len(videos)
    
    return {
        'country': country,
        'competitor_count': competitor_count,
        'total_videos': len(videos),
        'avg_views': int(avg_views),
        'avg_engagement_rate': round(avg_engagement * 100, 2),
        'duration': duration_insights,
        'timing': timing_insights,
        'categories': category_insights,
        'engagement': engagement_insights,
        'hooks': hook_insights,  # üÜï Ce qui accroche
        'dropoff': dropoff_insights,  # üÜï Temps de d√©crochage
        'keywords': keyword_insights,  # üÜï Mots-cl√©s performants
        'performance_score': _calculate_country_performance_score(videos),
        'recommendations': _generate_country_recommendations(country, videos, top_20_percent)
    }

def _analyze_optimal_duration(top_videos: List[Dict], all_videos: List[Dict]) -> Dict:
    """Analyse la dur√©e optimale des vid√©os"""
    # Filtrer les vid√©os avec dur√©e
    top_with_duration = [v for v in top_videos if v.get('duration_seconds')]
    all_with_duration = [v for v in all_videos if v.get('duration_seconds')]
    
    if not top_with_duration:
        return {'status': 'insufficient_data'}
    
    # Dur√©e moyenne des top vid√©os vs toutes les vid√©os
    top_avg_duration = sum(v['duration_seconds'] for v in top_with_duration) / len(top_with_duration)
    all_avg_duration = sum(v['duration_seconds'] for v in all_with_duration) / len(all_with_duration)
    
    # Convertir en minutes
    top_avg_minutes = int(top_avg_duration / 60)
    all_avg_minutes = int(all_avg_duration / 60)
    
    # Trouver la plage optimale (dur√©es des top 20%)
    durations = sorted([v['duration_seconds'] for v in top_with_duration])
    optimal_min = int(durations[len(durations)//4] / 60)  # 25e percentile
    optimal_max = int(durations[3*len(durations)//4] / 60)  # 75e percentile
    
    return {
        'optimal_range_minutes': [optimal_min, optimal_max],
        'optimal_avg_minutes': top_avg_minutes,
        'global_avg_minutes': all_avg_minutes,
        'performance_diff': f"+{((top_avg_duration/all_avg_duration-1)*100):.0f}%" if all_avg_duration > 0 else "N/A",
        'recommendation': f"Privil√©gier des vid√©os de {optimal_min}-{optimal_max} minutes"
    }

def _analyze_optimal_timing(top_videos: List[Dict]) -> Dict:
    """Analyse les heures et jours optimaux de publication"""
    videos_with_timing = [v for v in top_videos if v.get('hour_published') is not None]
    
    if not videos_with_timing:
        return {'status': 'insufficient_data'}
    
    # Analyse des heures
    hour_counts = {}
    for video in videos_with_timing:
        hour = video['hour_published']
        if hour not in hour_counts:
            hour_counts[hour] = {'count': 0, 'total_views': 0}
        hour_counts[hour]['count'] += 1
        hour_counts[hour]['total_views'] += video['view_count']
    
    # Meilleure heure (par vues moyennes)
    best_hours = []
    for hour, data in hour_counts.items():
        if data['count'] >= 2:  # Au moins 2 vid√©os
            avg_views = data['total_views'] / data['count']
            best_hours.append((hour, avg_views, data['count']))
    
    best_hours.sort(key=lambda x: x[1], reverse=True)
    
    # Analyse des jours de la semaine
    day_counts = {}
    for video in videos_with_timing:
        day = video.get('day_of_week')
        if day is not None:
            if day not in day_counts:
                day_counts[day] = {'count': 0, 'total_views': 0}
            day_counts[day]['count'] += 1
            day_counts[day]['total_views'] += video['view_count']
    
    # Convertir jour de semaine en nom
    day_names = ['Dimanche', 'Lundi', 'Mardi', 'Mercredi', 'Jeudi', 'Vendredi', 'Samedi']
    best_days = []
    for day, data in day_counts.items():
        if data['count'] >= 2:
            avg_views = data['total_views'] / data['count']
            day_name = day_names[day] if 0 <= day <= 6 else f"Jour {day}"
            best_days.append((day_name, avg_views, data['count']))
    
    best_days.sort(key=lambda x: x[1], reverse=True)
    
    return {
        'best_hours': best_hours[:3],  # Top 3 heures
        'best_days': best_days[:3],    # Top 3 jours
        'recommendation_hour': f"{best_hours[0][0]}h" if best_hours else "Donn√©es insuffisantes",
        'recommendation_day': best_days[0][0] if best_days else "Donn√©es insuffisantes"
    }

def _analyze_category_performance(top_videos: List[Dict], all_videos: List[Dict]) -> Dict:
    """Analyse des performances par cat√©gorie"""
    # Compter les cat√©gories dans le top
    top_categories = {}
    for video in top_videos:
        category = video.get('category', 'non_class√©')
        top_categories[category] = top_categories.get(category, 0) + 1
    
    # Compter toutes les cat√©gories
    all_categories = {}
    for video in all_videos:
        category = video.get('category', 'non_class√©')
        all_categories[category] = all_categories.get(category, 0) + 1
    
    # Calculer les ratios de performance
    category_performance = {}
    for category in all_categories:
        top_count = top_categories.get(category, 0)
        all_count = all_categories[category]
        
        # Ratio de pr√©sence dans le top vs pr√©sence globale
        top_ratio = (top_count / len(top_videos)) if top_videos else 0
        all_ratio = (all_count / len(all_videos)) if all_videos else 0
        performance_ratio = (top_ratio / all_ratio) if all_ratio > 0 else 0
        
        category_performance[category] = {
            'top_count': top_count,
            'total_count': all_count,
            'performance_ratio': round(performance_ratio, 2),
            'success_rate': round((top_count / all_count) * 100, 1) if all_count > 0 else 0
        }
    
    # Trier par ratio de performance
    best_categories = sorted(
        category_performance.items(), 
        key=lambda x: x[1]['performance_ratio'], 
        reverse=True
    )
    
    return {
        'best_performing': best_categories[:3] if best_categories else [],
        'category_breakdown': category_performance
    }

def _analyze_engagement_patterns(top_videos: List[Dict]) -> Dict:
    """Analyse les patterns d'engagement"""
    videos_with_engagement = [v for v in top_videos if v.get('like_count', 0) > 0 and v.get('view_count', 0) > 0]
    
    if not videos_with_engagement:
        return {'status': 'insufficient_data'}
    
    # Calculer les ratios d'engagement
    engagement_rates = []
    like_rates = []
    comment_rates = []
    
    for video in videos_with_engagement:
        views = video['view_count']
        likes = video.get('like_count', 0)
        comments = video.get('comment_count', 0)
        
        like_rate = (likes / views) * 100
        comment_rate = (comments / views) * 100
        
        like_rates.append(like_rate)
        comment_rates.append(comment_rate)
        engagement_rates.append(like_rate + comment_rate)
    
    return {
        'avg_like_rate': round(sum(like_rates) / len(like_rates), 2),
        'avg_comment_rate': round(sum(comment_rates) / len(comment_rates), 2),
        'avg_total_engagement': round(sum(engagement_rates) / len(engagement_rates), 2),
        'top_engagement_threshold': round(max(engagement_rates), 2) if engagement_rates else 0
    }

def _calculate_country_performance_score(videos: List[Dict]) -> float:
    """Calcule un score de performance global pour un pays"""
    if not videos:
        return 0.0
    
    # M√©triques de base
    avg_views = sum(v['view_count'] for v in videos) / len(videos)
    
    # Normaliser sur une √©chelle 0-10
    # 100k vues = score 5, 1M vues = score 10
    view_score = min(10, (avg_views / 100000) * 5)
    
    # Ajouter le facteur d'engagement
    videos_with_engagement = [v for v in videos if v.get('like_count', 0) > 0]
    if videos_with_engagement:
        avg_engagement = sum(v['like_count'] / max(v['view_count'], 1) for v in videos_with_engagement) / len(videos_with_engagement)
        engagement_score = min(3, avg_engagement * 1000)  # Max 3 points bonus
    else:
        engagement_score = 0
    
    return round(view_score + engagement_score, 1)

def _analyze_engagement_hooks(top_videos: List[Dict], all_videos: List[Dict]) -> Dict:
    """Analyse ce qui cr√©e l'engagement - patterns de titres, mots-cl√©s, formats"""
    import re
    from collections import Counter
    
    # Analyser les titres des vid√©os les plus engageantes
    top_titles = [v.get('title', '').lower() for v in top_videos if v.get('title')]
    all_titles = [v.get('title', '').lower() for v in all_videos if v.get('title')]
    
    if not top_titles:
        return {'status': 'insufficient_data'}
    
    # Mots-cl√©s qui apparaissent plus souvent dans les top vid√©os
    def extract_keywords(titles):
        # Extraire les mots significatifs (ignorer les mots vides)
        stop_words = {'le', 'la', 'les', 'de', 'du', 'des', 'un', 'une', 'et', 'ou', '√†', 'au', 'aux', 'pour', 'avec', 'dans', 'sur', 'par', 'ce', 'cette', 'ces', 'comment', 'que', 'qui', 'quoi', 'o√π', 'quand', 'the', 'a', 'an', 'and', 'or', 'to', 'at', 'in', 'on', 'by', 'for', 'with', 'how', 'what', 'when', 'where', 'why'}
        keywords = []
        for title in titles:
            words = re.findall(r'\b\w+\b', title)
            keywords.extend([w for w in words if len(w) > 3 and w not in stop_words])
        return keywords
    
    top_keywords = Counter(extract_keywords(top_titles))
    all_keywords = Counter(extract_keywords(all_titles))
    
    # Mots-cl√©s surrepr√©sent√©s dans les top vid√©os
    engagement_keywords = {}
    for keyword, top_count in top_keywords.most_common(20):
        if keyword in all_keywords:
            all_count = all_keywords[keyword]
            # Ratio de surrepr√©sentation
            overrepresentation = (top_count / len(top_titles)) / (all_count / len(all_titles))
            if overrepresentation > 1.2:  # Au moins 20% de surrepr√©sentation
                engagement_keywords[keyword] = {
                    'count': top_count,
                    'ratio': round(overrepresentation, 2)
                }
    
    # Patterns de titres qui performent
    title_patterns = []
    
    # Titres avec questions
    question_titles = [t for t in top_titles if any(q in t for q in ['?', 'comment', 'pourquoi', 'how', 'why', 'what'])]
    if question_titles:
        title_patterns.append(f"Questions: {len(question_titles)}/{len(top_titles)} des top vid√©os")
    
    # Titres avec chiffres
    number_titles = [t for t in top_titles if re.search(r'\d+', t)]
    if number_titles:
        title_patterns.append(f"Chiffres: {len(number_titles)}/{len(top_titles)} contiennent des chiffres")
    
    # Titres avec √©motions fortes
    emotion_words = ['incroyable', 'fou', 'choc', 'r√©v√©l√©', 'secret', 'amazing', 'incredible', 'shocking', 'revealed', 'secret']
    emotion_titles = [t for t in top_titles if any(word in t for word in emotion_words)]
    if emotion_titles:
        title_patterns.append(f"√âmotions: {len(emotion_titles)}/{len(top_titles)} avec mots √©motionnels")
    
    return {
        'engagement_keywords': dict(list(engagement_keywords.items())[:10]),  # Top 10
        'title_patterns': title_patterns,
        'total_analyzed': len(top_videos)
    }

def _analyze_dropoff_patterns(top_videos: List[Dict], all_videos: List[Dict]) -> Dict:
    """Analyse les temps de d√©crochage - corr√©lation dur√©e vs engagement"""
    
    # Analyser les vid√©os avec donn√©es compl√®tes
    complete_videos = [v for v in all_videos if v.get('duration_seconds') and v.get('view_count') and v.get('like_count')]
    
    if len(complete_videos) < 10:
        return {'status': 'insufficient_data'}
    
    # Grouper par tranches de dur√©e
    duration_groups = {
        'courte': [],    # 0-3 minutes
        'moyenne': [],   # 3-10 minutes
        'longue': []     # 10+ minutes
    }
    
    for video in complete_videos:
        duration_min = video['duration_seconds'] / 60
        engagement_rate = video['like_count'] / max(video['view_count'], 1)
        
        if duration_min <= 3:
            duration_groups['courte'].append(engagement_rate)
        elif duration_min <= 10:
            duration_groups['moyenne'].append(engagement_rate)
        else:
            duration_groups['longue'].append(engagement_rate)
    
    # Calculer l'engagement moyen par groupe
    group_stats = {}
    for group_name, rates in duration_groups.items():
        if rates:
            avg_engagement = sum(rates) / len(rates)
            group_stats[group_name] = {
                'avg_engagement': round(avg_engagement * 100, 2),
                'video_count': len(rates)
            }
    
    # D√©terminer le point de d√©crochage optimal
    best_group = max(group_stats.items(), key=lambda x: x[1]['avg_engagement']) if group_stats else None
    
    # Analyse des vid√©os longues vs courtes dans le top
    top_short = [v for v in top_videos if v.get('duration_seconds', 0) <= 180]  # 3 minutes
    top_long = [v for v in top_videos if v.get('duration_seconds', 0) > 600]   # 10 minutes
    
    insights = {
        'duration_groups': group_stats,
        'optimal_length': best_group[0] if best_group else 'moyenne',
        'top_short_count': len(top_short),
        'top_long_count': len(top_long),
        'dropoff_recommendation': f"Les vid√©os {best_group[0]}s performent mieux ({best_group[1]['avg_engagement']}% d'engagement)" if best_group else "Donn√©es insuffisantes"
    }
    
    return insights

def _analyze_performance_keywords(top_videos: List[Dict]) -> Dict:
    """Analyse les mots-cl√©s qui performent le mieux"""
    import re
    from collections import Counter
    
    # Extraire tous les mots des titres des top vid√©os
    all_words = []
    for video in top_videos:
        title = video.get('title', '').lower()
        if title:
            # Extraire les mots significatifs
            words = re.findall(r'\b\w+\b', title)
            all_words.extend([w for w in words if len(w) > 3])
    
    if not all_words:
        return {'status': 'insufficient_data'}
    
    # Compter les occurrences
    word_counts = Counter(all_words)
    
    # Associer chaque mot √† la performance moyenne des vid√©os qui le contiennent
    word_performance = {}
    for word, count in word_counts.most_common(30):
        if count >= 2:  # Au moins 2 occurrences
            videos_with_word = [v for v in top_videos if word in v.get('title', '').lower()]
            if videos_with_word:
                avg_views = sum(v.get('view_count', 0) for v in videos_with_word) / len(videos_with_word)
                avg_engagement = sum(v.get('like_count', 0) / max(v.get('view_count', 1), 1) for v in videos_with_word) / len(videos_with_word)
                
                word_performance[word] = {
                    'count': count,
                    'avg_views': int(avg_views),
                    'avg_engagement': round(avg_engagement * 100, 2),
                    'videos_count': len(videos_with_word)
                }
    
    # Trier par engagement
    top_keywords = sorted(word_performance.items(), key=lambda x: x[1]['avg_engagement'], reverse=True)
    
    return {
        'top_keywords': dict(top_keywords[:10]),  # Top 10 mots-cl√©s
        'total_analyzed': len(top_videos)
    }

def _generate_country_recommendations(country: str, all_videos: List[Dict], top_videos: List[Dict]) -> List[str]:
    """G√©n√®re des recommandations sp√©cifiques pour un pays"""
    recommendations = []
    
    # Recommandation de dur√©e
    if top_videos:
        durations = [v.get('duration_seconds', 0) for v in top_videos if v.get('duration_seconds')]
        if durations:
            avg_duration = sum(durations) / len(durations)
            recommendations.append(f"üéØ Dur√©e optimale: {int(avg_duration/60)} minutes en moyenne")
    
    # Recommandation de timing
    hours = [v.get('hour_published') for v in top_videos if v.get('hour_published') is not None]
    if hours:
        best_hour = max(set(hours), key=hours.count)
        recommendations.append(f"‚è∞ Heure optimale: {best_hour}h pour maximiser l'engagement")
    
    # Recommandation de cat√©gorie
    categories = [v.get('category') for v in top_videos if v.get('category')]
    if categories:
        best_category = max(set(categories), key=categories.count)
        category_names = {'hero': 'HERO', 'hub': 'HUB', 'help': 'HELP'}
        recommendations.append(f"üìà Cat√©gorie recommand√©e: {category_names.get(best_category, best_category)}")
    
    # üÜï Recommandations bas√©es sur les hooks d'engagement
    import re
    top_titles = [v.get('title', '').lower() for v in top_videos if v.get('title')]
    if top_titles:
        # Analyser les patterns de succ√®s
        question_count = sum(1 for t in top_titles if any(q in t for q in ['?', 'comment', 'pourquoi', 'how', 'why']))
        number_count = sum(1 for t in top_titles if re.search(r'\d+', t))
        
        if question_count > len(top_titles) * 0.3:  # Plus de 30% de questions
            recommendations.append(f"‚ùì Utilisez des questions dans vos titres ({question_count}/{len(top_titles)} vid√©os top)")
        
        if number_count > len(top_titles) * 0.4:  # Plus de 40% avec des chiffres
            recommendations.append(f"üî¢ Int√©grez des chiffres dans vos titres ({number_count}/{len(top_titles)} vid√©os top)")
    
    # üÜï Recommandation sur le temps de d√©crochage
    complete_videos = [v for v in top_videos if v.get('duration_seconds') and v.get('view_count') and v.get('like_count')]
    if len(complete_videos) >= 5:
        short_videos = [v for v in complete_videos if v['duration_seconds'] <= 180]  # 3 minutes
        long_videos = [v for v in complete_videos if v['duration_seconds'] > 600]   # 10 minutes
        
        short_engagement = sum(v['like_count'] / max(v['view_count'], 1) for v in short_videos) / len(short_videos) if short_videos else 0
        long_engagement = sum(v['like_count'] / max(v['view_count'], 1) for v in long_videos) / len(long_videos) if long_videos else 0
        
        if short_engagement > long_engagement * 1.2:  # 20% de plus d'engagement
            recommendations.append(f"‚ö° Privil√©giez les vid√©os courtes (<3min) pour l'engagement")
        elif long_engagement > short_engagement * 1.2:
            recommendations.append(f"üé¨ Les vid√©os longues (>10min) g√©n√®rent plus d'engagement")
    
    # Recommandation d'engagement standard
    engagement_rates = [
        v['like_count'] / max(v['view_count'], 1) 
        for v in top_videos 
        if v.get('like_count', 0) > 0 and v.get('view_count', 0) > 0
    ]
    if engagement_rates:
        target_engagement = sum(engagement_rates) / len(engagement_rates)
        recommendations.append(f"üí¨ Viser {target_engagement*100:.1f}% d'engagement (likes/vues)")
    
    return recommendations 