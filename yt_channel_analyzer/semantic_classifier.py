"""
Module de classification s√©mantique pour HUB/HERO/HELP
Utilise des embeddings s√©mantiques pour une vraie compr√©hension du contenu
"""

import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from typing import List, Dict, Tuple, Optional
import pickle
import os
from datetime import datetime

class SemanticHubHeroHelpClassifier:
    """
    Classificateur s√©mantique bas√© sur les embeddings de phrases
    Comprend r√©ellement le sens plut√¥t que de faire du matching de mots-cl√©s
    """
    
    def __init__(self, model_name: str = "sentence-transformers/all-MiniLM-L6-v2"):
        """
        Initialise le classificateur s√©mantique
        
        Args:
            model_name: Nom du mod√®le sentence-transformers √† utiliser
                      - all-MiniLM-L6-v2: Petit, rapide (22MB, 384 dimensions)
                      - all-MiniLM-L12-v2: Plus pr√©cis (33MB, 384 dimensions)
                      - paraphrase-MiniLM-L6-v2: Optimis√© pour paraphrases
        """
        print(f"[SEMANTIC] üß† Initialisation du classificateur s√©mantique avec {model_name}")
        
        try:
            self.model = SentenceTransformer(model_name)
            print(f"[SEMANTIC] ‚úÖ Mod√®le {model_name} charg√© avec succ√®s")
        except Exception as e:
            print(f"[SEMANTIC] ‚ùå Erreur lors du chargement du mod√®le: {e}")
            print("[SEMANTIC] üîÑ Installation automatique de sentence-transformers...")
            import subprocess
            subprocess.run(["pip", "install", "sentence-transformers"], check=True)
            self.model = SentenceTransformer(model_name)
        
        # D√©finition des exemples prototypes pour chaque cat√©gorie
        self.category_prototypes = {
            'hero': [
                "Nouvelle collection exclusive lanc√©e en avant-premi√®re",
                "√âv√©nement sp√©cial et lancement de produit r√©volutionnaire", 
                "Actualit√© importante et annonce majeure",
                "Premi√®re mondiale et r√©v√©lation exclusive",
                "Campagne marketing de grande envergure",
                "Contenu viral et buzz m√©diatique",
                "Innovation r√©volutionnaire et technologie de pointe"
            ],
            'hub': [
                "S√©rie r√©guli√®re de voyage et d√©couverte de destinations",
                "Contenu hebdomadaire sur les exp√©riences client",
                "Programme r√©current de pr√©sentation des services",
                "Collection de t√©moignages et retours d'exp√©rience",
                "S√©rie documentaire sur les coulisses",
                "Contenu √©ducatif et informatif r√©gulier",
                "Pr√©sentation des √©quipes et des m√©tiers"
            ],
            'help': [
                "Comment r√©soudre un probl√®me technique",
                "Guide √©tape par √©tape pour utiliser un service",
                "Tutoriel d√©taill√© et mode d'emploi",
                "R√©ponses aux questions fr√©quentes",
                "Aide pour configurer et param√©trer",
                "Support technique et d√©pannage",
                "Instructions d√©taill√©es et marche √† suivre"
            ]
        }
        
        # Calcul des embeddings pour les prototypes
        self.prototype_embeddings = {}
        for category, prototypes in self.category_prototypes.items():
            embeddings = self.model.encode(prototypes)
            # Moyenne des embeddings des prototypes pour cette cat√©gorie
            self.prototype_embeddings[category] = np.mean(embeddings, axis=0)
            print(f"[SEMANTIC] üìä Prototypes {category.upper()}: {len(prototypes)} exemples")
    
    def classify_text(self, text: str, description: str = "") -> Tuple[str, float, Dict]:
        """
        Classifie un texte selon HUB/HERO/HELP avec compr√©hension s√©mantique
        
        Args:
            text: Texte principal (titre)
            description: Description additionnelle (optionnel)
            
        Returns:
            Tuple[str, float, Dict]: (cat√©gorie, confiance, d√©tails)
        """
        # Combinaison du texte et de la description
        combined_text = f"{text} {description}".strip()
        
        # G√©n√©ration de l'embedding pour le texte
        text_embedding = self.model.encode([combined_text])[0]
        
        # Calcul de la similarit√© avec chaque prototype
        similarities = {}
        for category, prototype_embedding in self.prototype_embeddings.items():
            similarity = cosine_similarity(
                [text_embedding], 
                [prototype_embedding]
            )[0][0]
            similarities[category] = similarity
        
        # D√©termination de la cat√©gorie avec la plus forte similarit√©
        best_category = max(similarities, key=similarities.get)
        confidence = similarities[best_category]
        
        # Conversion en pourcentage et ajustement
        confidence_percentage = min(95, max(50, confidence * 100))
        
        details = {
            'similarities': similarities,
            'method': 'semantic_embedding',
            'model': self.model._modules['0'].auto_model.config.name_or_path,
            'embedding_dimension': len(text_embedding),
            'text_length': len(combined_text)
        }
        
        print(f"[SEMANTIC] üéØ '{text[:50]}...' ‚Üí {best_category.upper()} ({confidence_percentage:.1f}%)")
        
        return best_category, confidence_percentage, details
    
    def add_example(self, text: str, category: str, description: str = ""):
        """
        Ajoute un nouvel exemple d'apprentissage pour am√©liorer la classification
        
        Args:
            text: Texte de l'exemple
            category: Cat√©gorie correcte (hero/hub/help)
            description: Description additionnelle
        """
        if category not in self.category_prototypes:
            print(f"[SEMANTIC] ‚ùå Cat√©gorie invalide: {category}")
            return
        
        combined_text = f"{text} {description}".strip()
        
        # Ajout √† la liste des prototypes
        self.category_prototypes[category].append(combined_text)
        
        # Recalcul des embeddings pour cette cat√©gorie
        prototypes = self.category_prototypes[category]
        embeddings = self.model.encode(prototypes)
        self.prototype_embeddings[category] = np.mean(embeddings, axis=0)
        
        print(f"[SEMANTIC] ‚úÖ Exemple ajout√© pour {category.upper()}: '{text[:50]}...'")
        print(f"[SEMANTIC] üìä Total prototypes {category.upper()}: {len(prototypes)}")
    
    def explain_classification(self, text: str, description: str = "") -> Dict:
        """
        Explique pourquoi un texte a √©t√© classifi√© dans une cat√©gorie donn√©e
        
        Args:
            text: Texte √† analyser
            description: Description additionnelle
            
        Returns:
            Dict: Explication d√©taill√©e de la classification
        """
        combined_text = f"{text} {description}".strip()
        text_embedding = self.model.encode([combined_text])[0]
        
        # Calcul des similarit√©s avec tous les prototypes individuels
        detailed_similarities = {}
        
        for category, prototypes in self.category_prototypes.items():
            category_similarities = []
            prototype_embeddings = self.model.encode(prototypes)
            
            for i, prototype in enumerate(prototypes):
                similarity = cosine_similarity(
                    [text_embedding], 
                    [prototype_embeddings[i]]
                )[0][0]
                category_similarities.append({
                    'prototype': prototype,
                    'similarity': similarity
                })
            
            # Tri par similarit√© d√©croissante
            category_similarities.sort(key=lambda x: x['similarity'], reverse=True)
            detailed_similarities[category] = category_similarities
        
        # Classification finale
        category, confidence, details = self.classify_text(text, description)
        
        return {
            'text': combined_text,
            'predicted_category': category,
            'confidence': confidence,
            'top_matches_per_category': {
                cat: sims[:3] for cat, sims in detailed_similarities.items()
            },
            'reasoning': self._generate_reasoning(category, detailed_similarities)
        }
    
    def _generate_reasoning(self, predicted_category: str, detailed_similarities: Dict) -> str:
        """
        G√©n√®re une explication textuelle de la classification
        """
        top_match = detailed_similarities[predicted_category][0]
        reasoning = f"Classifi√© comme {predicted_category.upper()} car le texte ressemble le plus √†: "
        reasoning += f"'{top_match['prototype']}' (similarit√©: {top_match['similarity']:.3f})"
        
        return reasoning
    
    def save_model(self, filepath: str):
        """
        Sauvegarde le mod√®le et ses prototypes
        """
        model_data = {
            'category_prototypes': self.category_prototypes,
            'prototype_embeddings': self.prototype_embeddings,
            'model_name': self.model._modules['0'].auto_model.config.name_or_path,
            'created_at': datetime.now().isoformat()
        }
        
        with open(filepath, 'wb') as f:
            pickle.dump(model_data, f)
        
        print(f"[SEMANTIC] üíæ Mod√®le sauvegard√©: {filepath}")
    
    def load_model(self, filepath: str):
        """
        Charge un mod√®le sauvegard√©
        """
        if not os.path.exists(filepath):
            print(f"[SEMANTIC] ‚ùå Fichier non trouv√©: {filepath}")
            return
        
        with open(filepath, 'rb') as f:
            model_data = pickle.load(f)
        
        self.category_prototypes = model_data['category_prototypes']
        self.prototype_embeddings = model_data['prototype_embeddings']
        
        print(f"[SEMANTIC] üìÇ Mod√®le charg√©: {filepath}")
        print(f"[SEMANTIC] üìä Prototypes charg√©s: {sum(len(p) for p in self.category_prototypes.values())}")


def test_semantic_classifier():
    """
    Fonction de test pour d√©montrer l'utilisation du classificateur s√©mantique
    """
    print("\n" + "="*60)
    print("üß™ TEST DU CLASSIFICATEUR S√âMANTIQUE")
    print("="*60)
    
    # Initialisation
    classifier = SemanticHubHeroHelpClassifier()
    
    # Tests avec diff√©rents types de contenus
    test_cases = [
        {
            'text': "D√©couvrez notre nouvelle collection √©t√© 2024",
            'description': "Lancement exclusif de notre gamme estivale avec des mod√®les in√©dits",
            'expected': 'hero'
        },
        {
            'text': "Comment bien choisir sa destination de vacances",
            'description': "Guide complet pour s√©lectionner l'endroit parfait selon vos crit√®res",
            'expected': 'help'
        },
        {
            'text': "Voyage en Toscane - Episode 3",
            'description': "Suite de notre s√©rie documentaire sur les r√©gions italiennes",
            'expected': 'hub'
        },
        {
            'text': "Tutoriel r√©servation en ligne",
            'description': "√âtapes d√©taill√©es pour r√©server votre s√©jour sur notre site web",
            'expected': 'help'
        }
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nüß™ Test {i}:")
        print(f"üìù Texte: {test_case['text']}")
        print(f"üìÑ Description: {test_case['description']}")
        
        category, confidence, details = classifier.classify_text(
            test_case['text'], 
            test_case['description']
        )
        
        # Explication d√©taill√©e
        explanation = classifier.explain_classification(
            test_case['text'], 
            test_case['description']
        )
        
        print(f"üéØ Pr√©diction: {category.upper()} ({confidence:.1f}%)")
        print(f"‚úÖ Attendu: {test_case['expected'].upper()}")
        print(f"üí≠ Explication: {explanation['reasoning']}")
        
        if category == test_case['expected']:
            print("‚úÖ SUCC√àS")
        else:
            print("‚ùå √âCHEC")
    
    print("\n" + "="*60)
    print("üèÅ FIN DES TESTS")
    print("="*60)


if __name__ == "__main__":
    test_semantic_classifier() 