"""
Module d'entraÃ®nement sÃ©mantique avec les classifications humaines
Utilise les donnÃ©es classifiÃ©es manuellement pour amÃ©liorer le modÃ¨le
"""

import os
import json
import pickle
import numpy as np
from datetime import datetime
from typing import Dict, List, Tuple, Optional, Any
from collections import defaultdict, Counter

from .database import get_db_connection
from .semantic_classifier import SemanticHubHeroHelpClassifier, create_optimized_classifier

class SemanticTrainingManager:
    """
    Gestionnaire d'entraÃ®nement du modÃ¨le sÃ©mantique avec les donnÃ©es humaines
    """
    
    def __init__(self, semantic_classifier = None, use_optimized: bool = True):
        """
        Initialise le gestionnaire d'entraÃ®nement
        
        Args:
            semantic_classifier: Instance du classificateur sÃ©mantique Ã  entraÃ®ner
            use_optimized: Si True, utilise le classificateur optimisÃ© all-mpnet-base-v2
        """
        if semantic_classifier:
            self.classifier = semantic_classifier
        elif use_optimized:
            print("[SEMANTIC-TRAINING] ğŸš€ Utilisation du classificateur optimisÃ© all-mpnet-base-v2")
            self.classifier = create_optimized_classifier(use_quantization=False)  # Pas de quantification pour training
        else:
            self.classifier = SemanticHubHeroHelpClassifier()
        self.training_data = {
            'hero': [],
            'hub': [],
            'help': []
        }
        self.training_stats = {
            'playlists_extracted': 0,
            'videos_extracted': 0,
            'total_examples': 0,
            'last_training': None,
            'training_history': []
        }
        
        print("[SEMANTIC-TRAINING] ğŸ“ Gestionnaire d'entraÃ®nement initialisÃ©")
    
    def extract_human_classifications(self) -> Dict[str, Any]:
        """
        Extrait toutes les classifications humaines de la base de donnÃ©es
        
        Returns:
            Dict: Statistiques et donnÃ©es extraites
        """
        print("[SEMANTIC-TRAINING] ğŸ“Š Extraction des classifications humaines...")
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        try:
            # RÃ©initialiser les donnÃ©es d'entraÃ®nement
            self.training_data = {'hero': [], 'hub': [], 'help': []}
            
            # 1. Extraire les playlists classifiÃ©es manuellement
            print("[SEMANTIC-TRAINING] ğŸ“‹ Extraction des playlists humaines...")
            
            cursor.execute('''
                SELECT p.name, p.description, p.category, c.name as competitor_name, p.classification_date
                FROM playlist p
                JOIN concurrent c ON p.concurrent_id = c.id
                WHERE (p.classification_source = 'human' OR p.human_verified = 1)
                AND p.category IN ('hero', 'hub', 'help')
                AND p.name IS NOT NULL
                ORDER BY p.classification_date DESC
            ''')
            
            playlist_results = cursor.fetchall()
            
            for row in playlist_results:
                name, description, category, competitor, date = row
                
                # Nettoyage et validation
                if name and category:
                    example = {
                        'title': name.strip(),
                        'description': (description or '').strip(),
                        'category': category.lower(),
                        'source': 'playlist_human',
                        'competitor': competitor,
                        'date': date,
                        'confidence': 100  # Classification humaine = confiance max
                    }
                    
                    self.training_data[category.lower()].append(example)
                    self.training_stats['playlists_extracted'] += 1
            
            print(f"[SEMANTIC-TRAINING] âœ… {self.training_stats['playlists_extracted']} playlists extraites")
            
            # 2. Extraire les vidÃ©os classifiÃ©es manuellement (corrections)
            print("[SEMANTIC-TRAINING] ğŸ¥ Extraction des vidÃ©os humaines...")
            
            cursor.execute('''
                SELECT v.title, v.description, cf.corrected_category, c.name as competitor_name, cf.feedback_timestamp
                FROM classification_feedback cf
                JOIN video v ON cf.video_id = v.id
                JOIN concurrent c ON v.concurrent_id = c.id
                WHERE cf.user_feedback_type IN ('correction', 'human_correction')
                AND cf.corrected_category IN ('hero', 'hub', 'help')
                AND v.title IS NOT NULL
                ORDER BY cf.feedback_timestamp DESC
            ''')
            
            video_results = cursor.fetchall()
            
            for row in video_results:
                title, description, category, competitor, date = row
                
                if title and category:
                    example = {
                        'title': title.strip(),
                        'description': (description or '').strip(),
                        'category': category.lower(),
                        'source': 'video_human_correction',
                        'competitor': competitor,
                        'date': date,
                        'confidence': 100
                    }
                    
                    self.training_data[category.lower()].append(example)
                    self.training_stats['videos_extracted'] += 1
            
            print(f"[SEMANTIC-TRAINING] âœ… {self.training_stats['videos_extracted']} vidÃ©os extraites")
            
            # 3. Extraire les vidÃ©os directement marquÃ©es humaines
            cursor.execute('''
                SELECT v.title, v.description, v.category, c.name as competitor_name, v.classification_date
                FROM video v
                JOIN concurrent c ON v.concurrent_id = c.id
                WHERE (v.classification_source = 'human' OR v.human_verified = 1)
                AND v.category IN ('hero', 'hub', 'help')
                AND v.title IS NOT NULL
                ORDER BY v.classification_date DESC
                LIMIT 500
            ''')
            
            direct_videos = cursor.fetchall()
            videos_direct_count = 0
            
            for row in direct_videos:
                title, description, category, competitor, date = row
                
                if title and category:
                    # Ã‰viter les doublons avec les corrections
                    duplicate = any(
                        ex['title'] == title.strip() and ex['source'].startswith('video')
                        for ex in self.training_data[category.lower()]
                    )
                    
                    if not duplicate:
                        example = {
                            'title': title.strip(),
                            'description': (description or '').strip(),
                            'category': category.lower(),
                            'source': 'video_human_direct',
                            'competitor': competitor,
                            'date': date,
                            'confidence': 100
                        }
                        
                        self.training_data[category.lower()].append(example)
                        videos_direct_count += 1
            
            print(f"[SEMANTIC-TRAINING] âœ… {videos_direct_count} vidÃ©os directes extraites")
            
            # Calcul des statistiques
            self.training_stats['total_examples'] = sum(len(examples) for examples in self.training_data.values())
            self.training_stats['last_extraction'] = datetime.now().isoformat()
            
            # Affichage des statistiques
            print(f"\n[SEMANTIC-TRAINING] ğŸ“Š STATISTIQUES D'EXTRACTION:")
            print(f"   ğŸ¯ HERO: {len(self.training_data['hero'])} exemples")
            print(f"   ğŸ  HUB: {len(self.training_data['hub'])} exemples")
            print(f"   ğŸ†˜ HELP: {len(self.training_data['help'])} exemples")
            print(f"   ğŸ“Š TOTAL: {self.training_stats['total_examples']} exemples")
            
            return {
                'success': True,
                'stats': self.training_stats,
                'distribution': {cat: len(examples) for cat, examples in self.training_data.items()},
                'examples_by_competitor': self._analyze_by_competitor()
            }
            
        except Exception as e:
            print(f"[SEMANTIC-TRAINING] âŒ Erreur extraction: {e}")
            return {'success': False, 'error': str(e)}
        finally:
            conn.close()
    
    def _analyze_by_competitor(self) -> Dict:
        """
        Analyse la distribution des exemples par concurrent
        """
        competitor_stats = defaultdict(lambda: {'hero': 0, 'hub': 0, 'help': 0})
        
        for category, examples in self.training_data.items():
            for example in examples:
                competitor = example.get('competitor', 'Unknown')
                competitor_stats[competitor][category] += 1
        
        return dict(competitor_stats)
    
    def train_semantic_model(self) -> Dict[str, Any]:
        """
        EntraÃ®ne le modÃ¨le sÃ©mantique avec les donnÃ©es extraites
        
        Returns:
            Dict: RÃ©sultats de l'entraÃ®nement
        """
        if self.training_stats['total_examples'] == 0:
            print("[SEMANTIC-TRAINING] âš ï¸ Pas de donnÃ©es d'entraÃ®nement. Extraction d'abord...")
            extraction_result = self.extract_human_classifications()
            if not extraction_result['success']:
                return extraction_result
        
        print(f"[SEMANTIC-TRAINING] ğŸ“ EntraÃ®nement avec {self.training_stats['total_examples']} exemples...")
        
        training_results = {
            'examples_added': 0,
            'categories_trained': [],
            'success': True,
            'training_time': datetime.now().isoformat()
        }
        
        try:
            # Ajouter tous les exemples au classificateur
            for category, examples in self.training_data.items():
                if examples:
                    print(f"[SEMANTIC-TRAINING] ğŸ“š EntraÃ®nement {category.upper()}: {len(examples)} exemples")
                    
                    for example in examples:
                        # Ajouter l'exemple au classificateur sÃ©mantique
                        self.classifier.add_example(
                            text=example['title'],
                            category=category,
                            description=example['description']
                        )
                        training_results['examples_added'] += 1
                    
                    training_results['categories_trained'].append(category)
            
            # Mise Ã  jour des statistiques
            self.training_stats['last_training'] = training_results['training_time']
            self.training_stats['training_history'].append({
                'date': training_results['training_time'],
                'examples_added': training_results['examples_added'],
                'categories': training_results['categories_trained']
            })
            
            print(f"[SEMANTIC-TRAINING] âœ… EntraÃ®nement terminÃ©: {training_results['examples_added']} exemples ajoutÃ©s")
            
            return training_results
            
        except Exception as e:
            print(f"[SEMANTIC-TRAINING] âŒ Erreur entraÃ®nement: {e}")
            return {'success': False, 'error': str(e)}
    
    def validate_training(self, test_size: int = 10) -> Dict[str, Any]:
        """
        Valide l'entraÃ®nement en testant sur un Ã©chantillon
        
        Args:
            test_size: Nombre d'exemples Ã  tester par catÃ©gorie
            
        Returns:
            Dict: RÃ©sultats de validation
        """
        print(f"[SEMANTIC-TRAINING] ğŸ§ª Validation avec {test_size} exemples par catÃ©gorie...")
        
        validation_results = {
            'accuracy_by_category': {},
            'overall_accuracy': 0,
            'total_tests': 0,
            'correct_predictions': 0,
            'confusion_matrix': defaultdict(lambda: defaultdict(int)),
            'sample_results': []
        }
        
        try:
            for category, examples in self.training_data.items():
                if len(examples) < test_size:
                    print(f"[SEMANTIC-TRAINING] âš ï¸ Pas assez d'exemples pour {category}: {len(examples)} < {test_size}")
                    continue
                
                # Prendre un Ã©chantillon alÃ©atoire
                import random
                test_examples = random.sample(examples, min(test_size, len(examples)))
                
                correct = 0
                category_results = []
                
                for example in test_examples:
                    predicted_category, confidence, _ = self.classifier.classify_text(
                        example['title'], example['description']
                    )
                    
                    is_correct = predicted_category == category
                    if is_correct:
                        correct += 1
                        validation_results['correct_predictions'] += 1
                    
                    # Matrice de confusion
                    validation_results['confusion_matrix'][category][predicted_category] += 1
                    
                    # Ã‰chantillon de rÃ©sultats
                    category_results.append({
                        'title': example['title'][:50] + '...',
                        'expected': category,
                        'predicted': predicted_category,
                        'confidence': confidence,
                        'correct': is_correct
                    })
                    
                    validation_results['total_tests'] += 1
                
                # PrÃ©cision par catÃ©gorie
                accuracy = correct / len(test_examples) if test_examples else 0
                validation_results['accuracy_by_category'][category] = {
                    'accuracy': accuracy,
                    'correct': correct,
                    'total': len(test_examples),
                    'percentage': f"{accuracy*100:.1f}%"
                }
                
                validation_results['sample_results'].extend(category_results[:3])  # 3 exemples par catÃ©gorie
                
                print(f"[SEMANTIC-TRAINING] ğŸ“Š {category.upper()}: {correct}/{len(test_examples)} ({accuracy*100:.1f}%)")
            
            # PrÃ©cision globale
            if validation_results['total_tests'] > 0:
                overall_accuracy = validation_results['correct_predictions'] / validation_results['total_tests']
                validation_results['overall_accuracy'] = overall_accuracy
                
                print(f"[SEMANTIC-TRAINING] ğŸ¯ PrÃ©cision globale: {validation_results['correct_predictions']}/{validation_results['total_tests']} ({overall_accuracy*100:.1f}%)")
            
            return validation_results
            
        except Exception as e:
            print(f"[SEMANTIC-TRAINING] âŒ Erreur validation: {e}")
            return {'success': False, 'error': str(e)}
    
    def get_training_quality_report(self) -> Dict[str, Any]:
        """
        GÃ©nÃ¨re un rapport de qualitÃ© des donnÃ©es d'entraÃ®nement
        
        Returns:
            Dict: Rapport dÃ©taillÃ©
        """
        print("[SEMANTIC-TRAINING] ğŸ“‹ GÃ©nÃ©ration du rapport de qualitÃ©...")
        
        report = {
            'data_distribution': {},
            'text_quality': {},
            'competitor_coverage': {},
            'temporal_distribution': {},
            'recommendations': []
        }
        
        try:
            # 1. Distribution des donnÃ©es
            total = sum(len(examples) for examples in self.training_data.values())
            if total == 0:
                return {'error': 'Aucune donnÃ©e d\'entraÃ®nement disponible'}
            
            for category, examples in self.training_data.items():
                count = len(examples)
                percentage = count / total * 100
                report['data_distribution'][category] = {
                    'count': count,
                    'percentage': f"{percentage:.1f}%",
                    'balanced': 20 <= percentage <= 50  # Ã‰quilibre acceptable
                }
            
            # 2. QualitÃ© des textes
            all_examples = []
            for examples in self.training_data.values():
                all_examples.extend(examples)
            
            if all_examples:
                titles_lengths = [len(ex['title'].split()) for ex in all_examples]
                descriptions_lengths = [len(ex['description'].split()) for ex in all_examples if ex['description']]
                
                report['text_quality'] = {
                    'total_examples': len(all_examples),
                    'avg_title_length': np.mean(titles_lengths) if titles_lengths else 0,
                    'avg_description_length': np.mean(descriptions_lengths) if descriptions_lengths else 0,
                    'examples_with_description': len(descriptions_lengths),
                    'description_coverage': f"{len(descriptions_lengths)/len(all_examples)*100:.1f}%"
                }
            
            # 3. Couverture par concurrent
            competitor_counts = Counter()
            for examples in self.training_data.values():
                for ex in examples:
                    competitor_counts[ex.get('competitor', 'Unknown')] += 1
            
            report['competitor_coverage'] = dict(competitor_counts.most_common())
            
            # 4. Recommandations
            recommendations = []
            
            # DÃ©sÃ©quilibre des classes
            hero_pct = report['data_distribution'].get('hero', {}).get('percentage', '0%')
            hub_pct = report['data_distribution'].get('hub', {}).get('percentage', '0%')
            help_pct = report['data_distribution'].get('help', {}).get('percentage', '0%')
            
            hero_val = float(hero_pct.rstrip('%'))
            hub_val = float(hub_pct.rstrip('%'))
            help_val = float(help_pct.rstrip('%'))
            
            if max(hero_val, hub_val, help_val) > 60:
                recommendations.append("âš ï¸ DÃ©sÃ©quilibre des classes dÃ©tectÃ© - considÃ©rer Ã©quilibrer les donnÃ©es")
            
            if report['text_quality'].get('description_coverage', '0%').rstrip('%') and float(report['text_quality']['description_coverage'].rstrip('%')) < 50:
                recommendations.append("ğŸ“„ Peu de descriptions disponibles - enrichir avec plus de contexte")
            
            if total < 50:
                recommendations.append("ğŸ“Š Dataset petit - collecter plus de classifications humaines")
            
            if len(competitor_counts) == 1:
                recommendations.append("ğŸ¢ Un seul concurrent - diversifier les sources de donnÃ©es")
            
            report['recommendations'] = recommendations
            
            return report
            
        except Exception as e:
            print(f"[SEMANTIC-TRAINING] âŒ Erreur rapport: {e}")
            return {'error': str(e)}
    
    def save_training_data(self, filepath: str):
        """
        Sauvegarde les donnÃ©es d'entraÃ®nement
        
        Args:
            filepath: Chemin de sauvegarde
        """
        training_export = {
            'training_data': self.training_data,
            'training_stats': self.training_stats,
            'export_date': datetime.now().isoformat(),
            'version': '1.0'
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(training_export, f, indent=2, ensure_ascii=False)
        
        print(f"[SEMANTIC-TRAINING] ğŸ’¾ DonnÃ©es sauvegardÃ©es: {filepath}")
    
    def load_training_data(self, filepath: str):
        """
        Charge des donnÃ©es d'entraÃ®nement sauvegardÃ©es
        
        Args:
            filepath: Chemin de chargement
        """
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            self.training_data = data['training_data']
            self.training_stats = data['training_stats']
            
            print(f"[SEMANTIC-TRAINING] ğŸ“‚ DonnÃ©es chargÃ©es: {filepath}")
            print(f"[SEMANTIC-TRAINING] ğŸ“Š {sum(len(ex) for ex in self.training_data.values())} exemples chargÃ©s")
            
        except Exception as e:
            print(f"[SEMANTIC-TRAINING] âŒ Erreur chargement: {e}")


def create_domain_specific_model() -> Dict[str, Any]:
    """
    Fonction principale pour crÃ©er un modÃ¨le spÃ©cialisÃ© sur le domaine utilisateur
    
    Returns:
        Dict: RÃ©sultats complets du processus
    """
    print("ğŸ“ CRÃ‰ATION D'UN MODÃˆLE SÃ‰MANTIQUE SPÃ‰CIALISÃ‰")
    print("=" * 60)
    
    # 1. Initialisation
    trainer = SemanticTrainingManager()
    
    # 2. Extraction des donnÃ©es
    print("\nğŸ“Š Ã‰TAPE 1: Extraction des classifications humaines")
    extraction_result = trainer.extract_human_classifications()
    
    if not extraction_result['success']:
        return extraction_result
    
    # 3. Rapport de qualitÃ©
    print("\nğŸ“‹ Ã‰TAPE 2: Analyse de la qualitÃ© des donnÃ©es")
    quality_report = trainer.get_training_quality_report()
    
    # 4. EntraÃ®nement
    print("\nğŸ“ Ã‰TAPE 3: EntraÃ®nement du modÃ¨le")
    training_result = trainer.train_semantic_model()
    
    if not training_result['success']:
        return training_result
    
    # 5. Validation
    print("\nğŸ§ª Ã‰TAPE 4: Validation du modÃ¨le")
    validation_result = trainer.validate_training()
    
    # 6. Sauvegarde
    print("\nğŸ’¾ Ã‰TAPE 5: Sauvegarde")
    save_path = "trained_semantic_model.json"
    trainer.save_training_data(save_path)
    
    # RÃ©sultats finaux
    final_results = {
        'success': True,
        'extraction': extraction_result,
        'quality_report': quality_report,
        'training': training_result,
        'validation': validation_result,
        'model_path': save_path,
        'trained_classifier': trainer.classifier
    }
    
    print("\nâœ… MODÃˆLE SPÃ‰CIALISÃ‰ CRÃ‰Ã‰ AVEC SUCCÃˆS!")
    print(f"ğŸ“Š {extraction_result['stats']['total_examples']} exemples utilisÃ©s")
    if 'overall_accuracy' in validation_result:
        print(f"ğŸ¯ PrÃ©cision: {validation_result['overall_accuracy']*100:.1f}%")
    
    return final_results


if __name__ == "__main__":
    # Test du systÃ¨me d'entraÃ®nement
    result = create_domain_specific_model()
    
    if result['success']:
        print("\nğŸ‰ SuccÃ¨s! Votre modÃ¨le sÃ©mantique est maintenant spÃ©cialisÃ©")
        print("   sur vos donnÃ©es Club Med et voyage.")
    else:
        print(f"\nâŒ Erreur: {result.get('error', 'Erreur inconnue')}") 