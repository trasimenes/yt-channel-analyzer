"""
Adaptateur pour remplacer le scraping par l'API YouTube
Compatible avec l'interface existante de l'application
"""

from datetime import datetime
from typing import List, Dict, Optional
from .youtube_api_client import create_youtube_client

def get_channel_videos_data_api(channel_url: str, video_limit: int = 1000) -> List[Dict]:
    """
    Remplace get_channel_videos_data() de selenium_scraper.py
    Utilise l'API YouTube au lieu du scraping
    
    Args:
        channel_url (str): URL de la cha√Æne YouTube
        video_limit (int): Nombre maximum de vid√©os √† r√©cup√©rer
        
    Returns:
        List[Dict]: Liste des vid√©os au format compatible avec l'app existante
    """
    try:
        youtube = create_youtube_client()
        
        # R√©cup√©rer les vid√©os via l'API
        api_videos = youtube.get_channel_videos(channel_url, max_results=video_limit)
        
        # Convertir au format attendu par l'application
        formatted_videos = []
        for video in api_videos:
            formatted_video = {
                # Champs obligatoires pour l'application existante
                'title': video['title'],
                'url': video['url'],
                'views': format_views_for_app(video['view_count']),  # Nombre exact
                'publication_date': format_date_for_app(video['published_at']),
                
                # Champs suppl√©mentaires de l'API avec donn√©es exactes
                'view_count': video['view_count'],  # Nombre exact de vues
                'like_count': video['like_count'],  # Nombre exact de likes
                'comment_count': video['comment_count'],  # Nombre exact de commentaires
                'duration': video['duration'],
                'thumbnail': video['thumbnail'],
                'description': video['description'][:200] + '...' if len(video['description']) > 200 else video['description'],
                
                # Champs pour compatibilit√© et affichage
                'video_id': video['id'],
                'channel_title': video['channel_title'],
                'views_display': format_views_for_display(video['view_count']),  # Pour l'affichage format√©
                'likes_display': format_views_for_display(video['like_count']),  # Pour l'affichage format√©
                'published_at_iso': video['published_at']  # Date ISO pour tri/calculs
            }
            formatted_videos.append(formatted_video)
        
        print(f"‚úÖ API YouTube: {len(formatted_videos)} vid√©os r√©cup√©r√©es pour {channel_url}")
        return formatted_videos
        
    except Exception as e:
        print(f"‚ùå Erreur API YouTube: {e}")
        # Fallback vers le scraping en cas d'erreur
        print("‚ö†Ô∏è Tentative de fallback vers le scraping...")
        return fallback_to_scraping(channel_url, video_limit)

def get_video_data_api(video_url: str) -> Dict:
    """
    Remplace get_video_data() de selenium_scraper.py
    R√©cup√®re les donn√©es d'une vid√©o via l'API
    
    Args:
        video_url (str): URL de la vid√©o
        
    Returns:
        Dict: Donn√©es de la vid√©o
    """
    try:
        youtube = create_youtube_client()
        
        # Extraire l'ID de la vid√©o
        video_id = extract_video_id_from_url(video_url)
        if not video_id:
            raise ValueError(f"Impossible d'extraire l'ID vid√©o de: {video_url}")
        
        # R√©cup√©rer les d√©tails
        videos = youtube.get_videos_details([video_id])
        if not videos:
            raise ValueError(f"Vid√©o non trouv√©e: {video_url}")
        
        video = videos[0]
        
        return {
            'title': video['title'],
            'url': video['url'],
            'views': format_views_for_app(video['view_count']),
            'publication_date': format_date_for_app(video['published_at']),
            'like_count': video['like_count'],
            'comment_count': video['comment_count'],
            'duration': video['duration'],
            'thumbnail': video['thumbnail'],
            'description': video['description'],
            'channel_title': video['channel_title']
        }
        
    except Exception as e:
        print(f"‚ùå Erreur API YouTube pour vid√©o {video_url}: {e}")
        return {}

def autocomplete_youtube_channels_api(query: str, max_results: int = 10) -> List[Dict]:
    """
    Remplace autocomplete_youtube_channels() de scraper.py
    Recherche des cha√Ænes via l'API avec miniatures
    
    Args:
        query (str): Terme de recherche
        max_results (int): Nombre maximum de r√©sultats
        
    Returns:
        List[Dict]: Liste des cha√Ænes trouv√©es avec miniatures
    """
    try:
        youtube = create_youtube_client()
        channels = youtube.search_channels(query, max_results)
        
        # Convertir au format attendu avec miniatures
        formatted_channels = []
        for channel in channels:
            formatted_channel = {
                'name': channel.get('title', 'Nom inconnu'),
                'url': channel.get('url', ''),
                'thumbnail': channel.get('thumbnail', ''),  # Vraie miniature de la cha√Æne
                'description': channel.get('description', '')[:100] + '...' if len(channel.get('description', '')) > 100 else channel.get('description', '')
            }
            formatted_channels.append(formatted_channel)
        
        print(f"‚úÖ API YouTube autocomplete: {len(formatted_channels)} cha√Ænes trouv√©es avec miniatures")
        return formatted_channels
        
    except Exception as e:
        print(f"‚ùå Erreur recherche API YouTube: {e}")
        return []

def get_channel_info_api(channel_url: str) -> Dict:
    """
    R√©cup√®re les informations compl√®tes d'une cha√Æne
    
    Args:
        channel_url (str): URL de la cha√Æne
        
    Returns:
        Dict: Informations de la cha√Æne
    """
    try:
        youtube = create_youtube_client()
        return youtube.get_channel_info(channel_url)
    except Exception as e:
        print(f"‚ùå Erreur info cha√Æne API YouTube: {e}")
        return {}

# === FONCTIONS UTILITAIRES ===

def format_views_for_app(view_count: int) -> int:
    """Retourne le nombre exact de vues (pas de formatage)"""
    return int(view_count) if view_count else 0

def format_views_for_display(view_count: int) -> str:
    """Formate le nombre de vues pour l'affichage"""
    if view_count >= 1000000:
        return f"{view_count/1000000:.1f}M vues"
    elif view_count >= 1000:
        return f"{view_count/1000:.1f}k vues"
    else:
        return f"{view_count:,} vues".replace(',', ' ')

def format_date_for_app(published_at: str) -> str:
    """Formate la date de publication pour l'application existante"""
    try:
        # Convertir de ISO 8601 vers format fran√ßais
        dt = datetime.fromisoformat(published_at.replace('Z', '+00:00'))
        
        # Calculer "il y a X jours/mois"
        now = datetime.now(dt.tzinfo)
        diff = now - dt
        
        if diff.days == 0:
            return "aujourd'hui"
        elif diff.days == 1:
            return "il y a 1 jour"
        elif diff.days < 30:
            return f"il y a {diff.days} jours"
        elif diff.days < 365:
            months = diff.days // 30
            return f"il y a {months} mois"
        else:
            years = diff.days // 365
            return f"il y a {years} an" + ("s" if years > 1 else "")
    except:
        return published_at[:10]  # Fallback: juste la date

def extract_video_id_from_url(video_url: str) -> Optional[str]:
    """Extrait l'ID d'une vid√©o YouTube depuis son URL"""
    if 'watch?v=' in video_url:
        return video_url.split('watch?v=')[1].split('&')[0]
    elif 'youtu.be/' in video_url:
        return video_url.split('youtu.be/')[1].split('?')[0]
    return None

def fallback_to_scraping(channel_url: str, video_limit: int) -> List[Dict]:
    """Fallback vers le scraping en cas d'erreur API"""
    try:
        # Importer ici pour √©viter les d√©pendances circulaires
        from .selenium_scraper import get_channel_videos_data
        print("üîÑ Utilisation du scraping Selenium en fallback...")
        return get_channel_videos_data(channel_url, video_limit)
    except Exception as e:
        print(f"‚ùå √âchec du fallback scraping: {e}")
        return []

def get_channel_videos_data_api_incremental_background(
    channel_url: str, 
    existing_videos: Optional[List[Dict]] = None, 
    progress_callback=None,
    task_id: Optional[str] = None,
    max_videos: int = 0  # 0 = illimit√©, r√©cup√®re TOUTES les vid√©os
) -> List[Dict]:
    """
    Version API pour remplacer get_channel_videos_data_incremental_background de selenium_scraper.py
    R√©cup√®re les vid√©os d'une cha√Æne de mani√®re incr√©mentale via l'API YouTube
    
    Args:
        channel_url (str): URL de la cha√Æne YouTube
        existing_videos (List[Dict]): Vid√©os d√©j√† r√©cup√©r√©es (pour √©viter les doublons)
        progress_callback (callable): Fonction de callback pour les mises √† jour de progression
        task_id (str): ID de la t√¢che pour les logs
        max_videos (int): Nombre maximum de vid√©os √† r√©cup√©rer
        
    Returns:
        List[Dict]: Liste compl√®te des vid√©os (anciennes + nouvelles)
    """
    try:
        print(f"[API-BACKGROUND] üöÄ D√©but r√©cup√©ration API pour {channel_url}")
        
        if existing_videos is None:
            existing_videos = []
        
        # √âtape 1: Initialisation
        if progress_callback:
            progress_callback("Connexion √† l'API YouTube...", 5, len(existing_videos), 0)
        
        youtube = create_youtube_client()
        
        # √âtape 2: R√©cup√©ration des informations de la cha√Æne
        if progress_callback:
            progress_callback("R√©cup√©ration des informations de la cha√Æne...", 10, len(existing_videos), 0)
        
        channel_info = youtube.get_channel_info(channel_url)
        if not channel_info:
            raise ValueError(f"Impossible de r√©cup√©rer les informations de la cha√Æne: {channel_url}")
        
        print(f"[API-BACKGROUND] üìä Cha√Æne trouv√©e: {channel_info.get('title', 'Nom inconnu')}")
        
        # √âtape 3: R√©cup√©ration de toutes les vid√©os via l'API
        all_videos = list(existing_videos)  # Copier les vid√©os existantes
        existing_video_ids = {extract_video_id_from_url(v.get('url', '')) for v in existing_videos if v.get('url')}
        existing_video_ids.discard(None)  # Supprimer les None
        
        if progress_callback:
            progress_callback("R√©cup√©ration des vid√©os via API...", 20, len(all_videos), 0)
        
        # R√©cup√©rer TOUTES les vid√©os de la cha√Æne d'un coup
        api_videos = youtube.get_channel_videos(channel_url, max_results=max_videos)
        
        if progress_callback:
            progress_callback("Traitement des vid√©os...", 60, len(all_videos), 0)
        
        new_videos_count = 0
        
        # Traiter chaque vid√©o
        for i, video in enumerate(api_videos):
            # Callback de progression pendant le traitement
            if progress_callback and i % 50 == 0 and len(api_videos) > 0:
                current_progress = 60 + int((i / len(api_videos)) * 30)  # 60-90%
                progress_callback(
                    f"Traitement des vid√©os... ({i}/{len(api_videos)})", 
                    current_progress, 
                    len(all_videos), 
                    i
                )
            
            # V√©rifier si on a d√©j√† cette vid√©o
            video_id = video.get('id')
            if video_id in existing_video_ids:
                continue  # Skip, on l'a d√©j√†
            
            # Nouvelle vid√©o trouv√©e
            formatted_video = {
                # Champs obligatoires pour l'application existante
                'title': video['title'],
                'url': video['url'],
                'views': format_views_for_app(video['view_count']),  # Nombre exact
                'publication_date': format_date_for_app(video['published_at']),
                
                # Champs suppl√©mentaires de l'API avec donn√©es exactes
                'view_count': video['view_count'],  # Nombre exact de vues
                'like_count': video['like_count'],  # Nombre exact de likes
                'comment_count': video['comment_count'],  # Nombre exact de commentaires
                'duration': video['duration'],
                'thumbnail': video['thumbnail'],
                'description': video['description'][:200] + '...' if len(video['description']) > 200 else video['description'],
                
                # Champs pour compatibilit√© et affichage
                'video_id': video['id'],
                'channel_title': video['channel_title'],
                'views_display': format_views_for_display(video['view_count']),  # Pour l'affichage format√©
                'likes_display': format_views_for_display(video['like_count']),  # Pour l'affichage format√©
                'published_at_iso': video['published_at']  # Date ISO pour tri/calculs
            }
            
            all_videos.append(formatted_video)
            existing_video_ids.add(video_id)
            new_videos_count += 1
        
        print(f"[API-BACKGROUND] ‚úÖ Traitement termin√©: {len(api_videos)} vid√©os API, {new_videos_count} nouvelles")
        
        # √âtape finale: Sauvegarde et finalisation
        if progress_callback:
            progress_callback("Finalisation...", 95, len(all_videos), new_videos_count)
        
        print(f"[API-BACKGROUND] üéâ R√©cup√©ration termin√©e: {len(all_videos)} vid√©os total ({len(all_videos) - len(existing_videos)} nouvelles)")
        
        return all_videos
        
    except Exception as e:
        error_msg = f"Erreur API YouTube: {e}"
        print(f"[API-BACKGROUND] ‚ùå {error_msg}")
        
        # En cas d'erreur critique, essayer un fallback vers le scraping
        existing_videos_safe = existing_videos or []
        if len(existing_videos_safe) == 0:  # Seulement si on n'a rien du tout
            print(f"[API-BACKGROUND] üîÑ Tentative de fallback vers Selenium...")
            try:
                from .selenium_scraper import get_channel_videos_data_incremental_background
                return get_channel_videos_data_incremental_background(
                    channel_url, existing_videos_safe, progress_callback, task_id or ""
                )
            except Exception as fallback_error:
                print(f"[API-BACKGROUND] ‚ùå Fallback √©chou√©: {fallback_error}")
        
        # Retourner au moins les vid√©os existantes
        return existing_videos_safe

# === FONCTIONS POUR COMPATIBILIT√â ===

def get_api_quota_status() -> Dict:
    """Retourne le statut du quota API"""
    try:
        youtube = create_youtube_client()
        return youtube.get_quota_usage()
    except:
        return {
            'requests_made': 0,
            'quota_used': 0,
            'daily_limit': 10000,
            'remaining': 10000
        } 