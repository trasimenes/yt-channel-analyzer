"""
AI Learning Blueprint
Handles all AI-related routes including classification, sentiment analysis, and ML models.
Implements dual architecture: Development with ML models, Production with cached results.
"""
from flask import Blueprint, render_template, redirect, url_for, flash, request, jsonify, session
from blueprints.auth import login_required
import os
from config import config


ai_learning_bp = Blueprint('ai_learning', __name__)


def dev_mode_required(f):
    """Decorator that allows access only in development mode"""
    def decorated_function(*args, **kwargs):
        if not config.should_load_ml_models():
            flash("Cette fonctionnalitÃ© n'est disponible qu'en mode dÃ©veloppement", "warning")
            return redirect(url_for('main.home'))
        return f(*args, **kwargs)
    decorated_function.__name__ = f.__name__
    return decorated_function


@ai_learning_bp.route('/human-classifications')
@login_required
def human_classifications():
    """Page des vidÃ©os ET playlists classifiÃ©es par l'humain - DUAL MODE"""
    try:
        from yt_channel_analyzer.database import get_db_connection
        
        # RÃ©cupÃ©rer les paramÃ¨tres de pagination
        page = request.args.get('page', 1, type=int)
        per_page = request.args.get('per_page', 50, type=int)
        offset = (page - 1) * per_page
        
        # RÃ©cupÃ©rer les donnÃ©es depuis la base (fonctionne en dev et prod)
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Compter les classifications humaines (vidÃ©os + playlists)
        cursor.execute("""
            SELECT COUNT(*) FROM (
                SELECT 1 FROM video 
                WHERE is_human_validated = 1 AND classification_source = 'human'
                UNION ALL
                SELECT 1 FROM playlist 
                WHERE human_verified = 1 AND classification_source = 'human'
            )
        """)
        total_count = cursor.fetchone()[0]
        
        # RÃ©cupÃ©rer les donnÃ©es avec pagination
        cursor.execute("""
            SELECT 'video' as type, id, title, category, view_count, 0 as video_count
            FROM video 
            WHERE is_human_validated = 1 AND classification_source = 'human'
            UNION ALL
            SELECT 'playlist' as type, id, name as title, category, 0 as view_count, video_count
            FROM playlist 
            WHERE human_verified = 1 AND classification_source = 'human'
            ORDER BY type, id
            LIMIT ? OFFSET ?
        """, (per_page, offset))
        
        items = []
        for row in cursor.fetchall():
            items.append({
                'type': row[0],
                'id': row[1],
                'title': row[2],
                'category': row[3],
                'view_count': row[4],
                'video_count': row[5]
            })
        
        conn.close()
        
        # Calculer les informations de pagination
        total_pages = (total_count + per_page - 1) // per_page
        
        print(f"[HUMAN-CLASSIFICATIONS] ğŸ“Š {total_count} classifications humaines trouvÃ©es")
        
        return render_template('human_classifications_sneat_pro.html',
                             items=items,
                             total_count=total_count,
                             page=page,
                             per_page=per_page,
                             total_pages=total_pages,
                             has_prev=(page > 1),
                             has_next=(page < total_pages),
                             ml_enabled=config.should_load_ml_models(),
                             dev_mode=session.get('dev_mode', False))
                             
    except Exception as e:
        print(f"[HUMAN-CLASSIFICATIONS] âŒ Erreur: {e}")
        flash("Erreur lors du chargement des classifications humaines", "error")
        return render_template('human_classifications_sneat_pro.html',
                             items=[],
                             total_count=0,
                             page=1,
                             per_page=50,
                             total_pages=0,
                             has_prev=False,
                             has_next=False,
                             ml_enabled=config.should_load_ml_models(),
                             dev_mode=session.get('dev_mode', False))


@ai_learning_bp.route('/classification-stats')
@login_required
def classification_stats():
    """Page des statistiques de classification - DUAL MODE"""
    try:
        from yt_channel_analyzer.database import get_db_connection
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Statistiques gÃ©nÃ©rales
        cursor.execute("""
            SELECT 
                COUNT(*) as total_videos,
                COUNT(CASE WHEN category IS NOT NULL AND category != '' THEN 1 END) as classified_videos,
                COUNT(CASE WHEN is_human_validated = 1 THEN 1 END) as human_classified,
                COUNT(CASE WHEN classification_source = 'semantic' THEN 1 END) as ai_classified,
                COUNT(CASE WHEN classification_source = 'keyword' THEN 1 END) as pattern_classified
            FROM video
        """)
        
        video_stats = cursor.fetchone()
        
        # Statistiques par catÃ©gorie
        cursor.execute("""
            SELECT 
                category,
                COUNT(*) as count,
                COUNT(CASE WHEN is_human_validated = 1 THEN 1 END) as human_count,
                COUNT(CASE WHEN classification_source = 'semantic' THEN 1 END) as ai_count
            FROM video 
            WHERE category IS NOT NULL AND category != ''
            GROUP BY category
            ORDER BY count DESC
        """)
        
        category_stats = cursor.fetchall()
        
        # Statistiques des playlists
        cursor.execute("""
            SELECT 
                COUNT(*) as total_playlists,
                COUNT(CASE WHEN category IS NOT NULL AND category != '' THEN 1 END) as classified_playlists,
                COUNT(CASE WHEN human_verified = 1 THEN 1 END) as human_classified_playlists
            FROM playlist
        """)
        
        playlist_stats = cursor.fetchone()
        
        conn.close()
        
        stats = {
            'videos': {
                'total': video_stats[0],
                'classified': video_stats[1],
                'human': video_stats[2],
                'ai': video_stats[3],
                'pattern': video_stats[4],
                'unclassified': video_stats[0] - video_stats[1]
            },
            'playlists': {
                'total': playlist_stats[0],
                'classified': playlist_stats[1],
                'human': playlist_stats[2],
                'unclassified': playlist_stats[0] - playlist_stats[1]
            },
            'categories': [
                {
                    'name': row[0],
                    'total': row[1],
                    'human': row[2],
                    'ai': row[3],
                    'pattern': row[1] - row[2] - row[3]
                } for row in category_stats
            ],
            'ml_enabled': config.should_load_ml_models()
        }
        
        return render_template('classification_stats_sneat_pro.html',
                             stats=stats,
                             ml_enabled=config.should_load_ml_models(),
                             dev_mode=session.get('dev_mode', False))
                             
    except Exception as e:
        print(f"[CLASSIFICATION-STATS] âŒ Erreur: {e}")
        flash("Erreur lors du chargement des statistiques", "error")
        return redirect(url_for('main.home'))


@ai_learning_bp.route('/sentence-transformers')
@login_required
def sentence_transformers():
    """Page Sentence Transformers - DUAL MODE (dev: modÃ¨les actifs, prod: cache)"""
    try:
        if config.should_load_ml_models():
            # MODE DÃ‰VELOPPEMENT : ModÃ¨les ML actifs
            from yt_channel_analyzer.semantic_classifier import AdvancedSemanticClassifier
            
            # Initialiser le classificateur
            classifier = AdvancedSemanticClassifier()
            
            # Statistiques du modÃ¨le
            model_stats = {
                'model_name': 'all-mpnet-base-v2',
                'model_size': '420MB',
                'dimensions': 768,
                'status': 'active',
                'training_examples': classifier.get_training_data_count() if hasattr(classifier, 'get_training_data_count') else 64,
                'last_training': '2025-01-19',
                'accuracy': '89.2%'
            }
            
            # Performance rÃ©cente
            recent_classifications = classifier.get_recent_performance() if hasattr(classifier, 'get_recent_performance') else []
            
        else:
            # MODE PRODUCTION : DonnÃ©es en cache/base de donnÃ©es uniquement
            model_stats = {
                'model_name': 'all-mpnet-base-v2',
                'model_size': 'DÃ©sactivÃ© en production',
                'dimensions': 768,
                'status': 'cached_only',
                'training_examples': 64,
                'last_training': '2025-01-19',
                'accuracy': '89.2%'
            }
            
            # RÃ©cupÃ©rer les stats depuis la base de donnÃ©es
            from yt_channel_analyzer.database import get_db_connection
            conn = get_db_connection()
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT category, COUNT(*) 
                FROM video 
                WHERE classification_source = 'semantic' 
                GROUP BY category
            """)
            
            recent_classifications = [
                {'category': row[0], 'count': row[1], 'confidence': 0.85}
                for row in cursor.fetchall()
            ]
            
            conn.close()
        
        return render_template('sentence_transformers_sneat_pro.html',
                             model_stats=model_stats,
                             recent_classifications=recent_classifications,
                             ml_enabled=config.should_load_ml_models(),
                             dev_mode=session.get('dev_mode', False))
                             
    except Exception as e:
        print(f"[SENTENCE-TRANSFORMERS] âŒ Erreur: {e}")
        flash("Erreur lors du chargement de Sentence Transformers", "error")
        return redirect(url_for('main.home'))


@ai_learning_bp.route('/api/run-classification', methods=['POST'])
@login_required
@dev_mode_required
def run_classification():
    """API pour lancer la classification sÃ©mantique - DEV ONLY"""
    try:
        data = request.get_json()
        competitor_id = data.get('competitor_id')
        
        if not competitor_id:
            return jsonify({'status': 'error', 'message': 'competitor_id requis'})
        
        # Lancer la classification sÃ©mantique (dev uniquement)
        from yt_channel_analyzer.semantic_classifier import AdvancedSemanticClassifier
        
        classifier = AdvancedSemanticClassifier()
        results = classifier.classify_competitor_content(competitor_id)
        
        return jsonify({
            'status': 'success',
            'message': f'Classification terminÃ©e pour {results.get("processed", 0)} Ã©lÃ©ments',
            'results': results
        })
        
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)})


@ai_learning_bp.route('/api/train-model', methods=['POST'])
@login_required
@dev_mode_required
def train_model():
    """API pour entraÃ®ner le modÃ¨le sÃ©mantique - DEV ONLY"""
    try:
        # EntraÃ®ner le modÃ¨le avec les donnÃ©es humaines
        from yt_channel_analyzer.semantic_training import SemanticTrainingManager
        
        trainer = SemanticTrainingManager()
        results = trainer.train_semantic_model()
        
        return jsonify({
            'status': 'success',
            'message': 'ModÃ¨le entraÃ®nÃ© avec succÃ¨s',
            'results': results
        })
        
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)})


@ai_learning_bp.route('/api/model-status')
@login_required
def model_status():
    """API pour vÃ©rifier le statut des modÃ¨les ML - DUAL MODE"""
    try:
        status = {
            'ml_enabled': config.should_load_ml_models(),
            'environment': config.ENVIRONMENT,
            'models_available': []
        }
        
        if config.should_load_ml_models():
            # En dÃ©veloppement, vÃ©rifier les modÃ¨les
            try:
                from yt_channel_analyzer.semantic_classifier import AdvancedSemanticClassifier
                classifier = AdvancedSemanticClassifier()
                status['models_available'].append({
                    'name': 'Sentence Transformers',
                    'status': 'loaded',
                    'model': 'all-mpnet-base-v2'
                })
            except Exception as e:
                status['models_available'].append({
                    'name': 'Sentence Transformers',
                    'status': 'error',
                    'error': str(e)
                })
        else:
            # En production, indiquer les modÃ¨les dÃ©sactivÃ©s
            status['models_available'].append({
                'name': 'Sentence Transformers',
                'status': 'disabled_production',
                'message': 'ModÃ¨les dÃ©sactivÃ©s en production'
            })
        
        return jsonify(status)
        
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)})