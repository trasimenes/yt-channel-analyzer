#!/usr/bin/env python3
"""
Key Metrics Validator - Agent de validation des m√©triques cl√©s
=============================================================

Valide la coh√©rence et la plausibilit√© de toutes les Key Metrics de chaque competitor
avant leur utilisation dans les PowerPoint et analyses.

8 Key Metrics valid√©es :
1. Dur√©e des Vid√©os (moyenne en minutes, % courts/longs)
2. Fr√©quence de Publication (vid√©os/semaine, jour optimal)
3. Distribution HHH (Hero-Hub-Help en %)
4. Organique vs Pay√© (% organic/paid)
5. Shorts vs Vid√©os 16:9 (% format)
6. Coh√©rence des Miniatures (%)
7. Champ Lexical (% coh√©rence tonalit√©)
8. Sujet le Plus Appr√©ci√© (titre performance)

Crit√®res de validation :
- Distribution HHH : au moins une cat√©gorie > 0%
- Dur√©e moyenne : > 0 min et < 60 min (plausible YouTube)
- Fr√©quence : > 0 et < 100 vid√©os/semaine (plausible)
- Pourcentages : entre 0-100%
- Coh√©rence : pas tous √† 0% ou 100%
- Sujet populaire : existe et non vide
"""

import sqlite3
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
import json
import statistics
import re
from dataclasses import dataclass
from enum import Enum

# Configuration
PROJECT_ROOT = Path(__file__).parent
DB_PATH = PROJECT_ROOT / 'instance' / 'database.db'

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('key_metrics_validation.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class ValidationStatus(Enum):
    """Statuts de validation possibles."""
    EXCELLENT = "excellent"      # Toutes les m√©triques sont valides et coh√©rentes
    GOOD = "good"               # M√©triques majoritairement valides avec alertes mineures
    WARNING = "warning"         # Probl√®mes de coh√©rence d√©tect√©s
    CRITICAL = "critical"       # M√©triques invalides ou aberrantes
    INSUFFICIENT_DATA = "insufficient_data"  # Pas assez de donn√©es


@dataclass
class ValidationResult:
    """R√©sultat de validation pour une m√©trique."""
    metric_name: str
    status: ValidationStatus
    value: Any
    expected_range: str
    message: str
    recommendation: str


@dataclass
class CompetitorValidationReport:
    """Rapport de validation complet pour un competitor."""
    competitor_id: int
    competitor_name: str
    country: str
    overall_status: ValidationStatus
    metrics_results: List[ValidationResult]
    total_videos: int
    powerpoint_ready: bool
    summary: str
    critical_issues: List[str]
    warnings: List[str]
    validation_date: datetime


class KeyMetricsValidator:
    """Agent de validation des m√©triques cl√©s pour tous les competitors."""
    
    def __init__(self, db_path: str = DB_PATH):
        self.db_path = db_path
        self.paid_threshold = 10000  # Seuil pour consid√©rer une vid√©o comme pay√©e
        
    def get_db_connection(self) -> sqlite3.Connection:
        """Cr√©e une connexion √† la base de donn√©es."""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        return conn
    
    def validate_all_competitors(self) -> List[CompetitorValidationReport]:
        """Valide les m√©triques de tous les competitors."""
        logger.info("üöÄ D√©marrage de la validation compl√®te de tous les competitors")
        
        with self.get_db_connection() as conn:
            # R√©cup√©rer tous les competitors
            competitors = conn.execute("""
                SELECT c.id, c.name, c.country, COUNT(v.id) as video_count
                FROM concurrent c
                LEFT JOIN video v ON c.id = v.concurrent_id
                GROUP BY c.id, c.name, c.country
                ORDER BY c.country, c.name
            """).fetchall()
        
        reports = []
        for competitor in competitors:
            try:
                report = self.validate_competitor(competitor['id'])
                reports.append(report)
                logger.info(f"‚úÖ Competitor {competitor['name']} - Status: {report.overall_status.value}")
            except Exception as e:
                logger.error(f"‚ùå Erreur lors de la validation du competitor {competitor['name']}: {e}")
        
        logger.info(f"üèÅ Validation termin√©e pour {len(reports)} competitors")
        return reports
    
    def validate_competitor(self, competitor_id: int) -> CompetitorValidationReport:
        """Valide les m√©triques d'un competitor sp√©cifique."""
        with self.get_db_connection() as conn:
            # R√©cup√©rer les donn√©es du competitor
            competitor = conn.execute(
                "SELECT * FROM concurrent WHERE id = ?", (competitor_id,)
            ).fetchone()
            
            if not competitor:
                raise ValueError(f"Competitor {competitor_id} non trouv√©")
            
            # R√©cup√©rer toutes les vid√©os
            videos = conn.execute("""
                SELECT * FROM video 
                WHERE concurrent_id = ? 
                ORDER BY published_at DESC
            """, (competitor_id,)).fetchall()
        
        # Ex√©cuter toutes les validations
        metrics_results = []
        critical_issues = []
        warnings = []
        
        # 1. Validation Dur√©e des Vid√©os
        duration_result = self._validate_video_duration(videos)
        metrics_results.append(duration_result)
        if duration_result.status == ValidationStatus.CRITICAL:
            critical_issues.append(duration_result.message)
        elif duration_result.status == ValidationStatus.WARNING:
            warnings.append(duration_result.message)
        
        # 2. Validation Fr√©quence de Publication
        frequency_result = self._validate_publishing_frequency(videos)
        metrics_results.append(frequency_result)
        if frequency_result.status == ValidationStatus.CRITICAL:
            critical_issues.append(frequency_result.message)
        elif frequency_result.status == ValidationStatus.WARNING:
            warnings.append(frequency_result.message)
        
        # 3. Validation Distribution HHH
        hhh_result = self._validate_hhh_distribution(videos)
        metrics_results.append(hhh_result)
        if hhh_result.status == ValidationStatus.CRITICAL:
            critical_issues.append(hhh_result.message)
        elif hhh_result.status == ValidationStatus.WARNING:
            warnings.append(hhh_result.message)
        
        # 4. Validation Organique vs Pay√©
        organic_paid_result = self._validate_organic_vs_paid(videos)
        metrics_results.append(organic_paid_result)
        if organic_paid_result.status == ValidationStatus.CRITICAL:
            critical_issues.append(organic_paid_result.message)
        elif organic_paid_result.status == ValidationStatus.WARNING:
            warnings.append(organic_paid_result.message)
        
        # 5. Validation Shorts vs Vid√©os 16:9
        shorts_result = self._validate_shorts_distribution(videos)
        metrics_results.append(shorts_result)
        if shorts_result.status == ValidationStatus.CRITICAL:
            critical_issues.append(shorts_result.message)
        elif shorts_result.status == ValidationStatus.WARNING:
            warnings.append(shorts_result.message)
        
        # 6. Validation Coh√©rence des Miniatures
        thumbnail_result = self._validate_thumbnail_consistency(videos)
        metrics_results.append(thumbnail_result)
        if thumbnail_result.status == ValidationStatus.WARNING:
            warnings.append(thumbnail_result.message)
        
        # 7. Validation Champ Lexical
        lexical_result = self._validate_lexical_consistency(videos)
        metrics_results.append(lexical_result)
        if lexical_result.status == ValidationStatus.WARNING:
            warnings.append(lexical_result.message)
        
        # 8. Validation Sujet le Plus Appr√©ci√©
        top_subject_result = self._validate_top_performing_subject(videos)
        metrics_results.append(top_subject_result)
        if top_subject_result.status == ValidationStatus.CRITICAL:
            critical_issues.append(top_subject_result.message)
        elif top_subject_result.status == ValidationStatus.WARNING:
            warnings.append(top_subject_result.message)
        
        # D√©terminer le statut global
        overall_status = self._determine_overall_status(metrics_results)
        
        # D√©terminer si pr√™t pour PowerPoint
        powerpoint_ready = (
            overall_status in [ValidationStatus.EXCELLENT, ValidationStatus.GOOD] 
            and len(critical_issues) == 0
            and len(videos) > 0
        )
        
        # G√©n√©rer le r√©sum√©
        summary = self._generate_summary(overall_status, len(videos), len(critical_issues), len(warnings))
        
        return CompetitorValidationReport(
            competitor_id=competitor_id,
            competitor_name=competitor['name'],
            country=competitor['country'],
            overall_status=overall_status,
            metrics_results=metrics_results,
            total_videos=len(videos),
            powerpoint_ready=powerpoint_ready,
            summary=summary,
            critical_issues=critical_issues,
            warnings=warnings,
            validation_date=datetime.now()
        )
    
    def _validate_video_duration(self, videos: List[sqlite3.Row]) -> ValidationResult:
        """Valide les m√©triques de dur√©e des vid√©os."""
        if not videos:
            return ValidationResult(
                metric_name="Dur√©e des Vid√©os",
                status=ValidationStatus.INSUFFICIENT_DATA,
                value=0,
                expected_range="0.5-60 minutes",
                message="Aucune vid√©o trouv√©e",
                recommendation="Importer des vid√©os pour cette cha√Æne"
            )
        
        # Calculer les dur√©es
        durations = [v['duration_seconds'] for v in videos if v['duration_seconds'] and v['duration_seconds'] > 0]
        
        if not durations:
            return ValidationResult(
                metric_name="Dur√©e des Vid√©os",
                status=ValidationStatus.CRITICAL,
                value=0,
                expected_range="0.5-60 minutes",
                message="Aucune dur√©e de vid√©o disponible",
                recommendation="R√©cup√©rer les dur√©es des vid√©os via l'API YouTube"
            )
        
        avg_duration_minutes = statistics.mean(durations) / 60
        short_videos = sum(1 for d in durations if d < 60)  # < 1 minute
        long_videos = sum(1 for d in durations if d > 3600)  # > 1 heure
        short_percentage = (short_videos / len(durations)) * 100
        long_percentage = (long_videos / len(durations)) * 100
        
        # Validation
        if avg_duration_minutes <= 0 or avg_duration_minutes > 120:  # Plus de 2h suspect
            return ValidationResult(
                metric_name="Dur√©e des Vid√©os",
                status=ValidationStatus.CRITICAL,
                value=f"{avg_duration_minutes:.1f} min",
                expected_range="0.5-60 minutes",
                message=f"Dur√©e moyenne aberrante: {avg_duration_minutes:.1f} minutes",
                recommendation="V√©rifier les donn√©es de dur√©e des vid√©os"
            )
        elif avg_duration_minutes > 60:  # Plus d'1h attention
            return ValidationResult(
                metric_name="Dur√©e des Vid√©os",
                status=ValidationStatus.WARNING,
                value=f"{avg_duration_minutes:.1f} min",
                expected_range="0.5-60 minutes",
                message=f"Dur√©e moyenne √©lev√©e: {avg_duration_minutes:.1f} minutes",
                recommendation="V√©rifier si ce sont des livestreams ou des contenus longs normaux"
            )
        elif short_percentage > 80:  # Trop de vid√©os tr√®s courtes
            return ValidationResult(
                metric_name="Dur√©e des Vid√©os",
                status=ValidationStatus.WARNING,
                value=f"{avg_duration_minutes:.1f} min ({short_percentage:.0f}% courts)",
                expected_range="0.5-60 minutes",
                message=f"{short_percentage:.0f}% des vid√©os sont < 1 minute",
                recommendation="Cha√Æne principalement orient√©e Shorts YouTube"
            )
        else:
            return ValidationResult(
                metric_name="Dur√©e des Vid√©os",
                status=ValidationStatus.EXCELLENT,
                value=f"{avg_duration_minutes:.1f} min",
                expected_range="0.5-60 minutes",
                message=f"Dur√©e moyenne coh√©rente: {avg_duration_minutes:.1f} minutes",
                recommendation="Dur√©es optimales pour l'engagement"
            )
    
    def _validate_publishing_frequency(self, videos: List[sqlite3.Row]) -> ValidationResult:
        """Valide la fr√©quence de publication."""
        if not videos or len(videos) < 2:
            return ValidationResult(
                metric_name="Fr√©quence de Publication",
                status=ValidationStatus.INSUFFICIENT_DATA,
                value="0 vid√©os/semaine",
                expected_range="0.1-10 vid√©os/semaine",
                message="Pas assez de vid√©os pour calculer la fr√©quence",
                recommendation="Importer plus de vid√©os"
            )
        
        # Parser les dates de publication
        valid_dates = []
        for video in videos:
            if video['published_at']:
                try:
                    # Essayer diff√©rents formats de date
                    date_str = video['published_at']
                    if 'T' in date_str:
                        date = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
                    else:
                        date = datetime.strptime(date_str, '%Y-%m-%d')
                    valid_dates.append(date)
                except Exception:
                    continue
        
        if len(valid_dates) < 2:
            return ValidationResult(
                metric_name="Fr√©quence de Publication",
                status=ValidationStatus.CRITICAL,
                value="Dates invalides",
                expected_range="0.1-10 vid√©os/semaine",
                message="Dates de publication non valides",
                recommendation="Corriger les dates avec l'agent de correction YouTube"
            )
        
        valid_dates.sort()
        
        # Calculer la fr√©quence
        date_range = (valid_dates[-1] - valid_dates[0]).days
        if date_range == 0:
            # Toutes les vid√©os publi√©es le m√™me jour (suspect)
            return ValidationResult(
                metric_name="Fr√©quence de Publication",
                status=ValidationStatus.CRITICAL,
                value="Toutes le m√™me jour",
                expected_range="0.1-10 vid√©os/semaine",
                message="Toutes les vid√©os ont la m√™me date de publication",
                recommendation="CRITIQUE: Dates d'import utilis√©es au lieu des vraies dates YouTube"
            )
        
        weeks = max(date_range / 7, 1)
        videos_per_week = len(valid_dates) / weeks
        
        # Validation
        if videos_per_week > 50:  # Plus de 50 vid√©os/semaine = aberrant
            return ValidationResult(
                metric_name="Fr√©quence de Publication",
                status=ValidationStatus.CRITICAL,
                value=f"{videos_per_week:.1f} vid√©os/semaine",
                expected_range="0.1-10 vid√©os/semaine",
                message=f"Fr√©quence aberrante: {videos_per_week:.1f} vid√©os/semaine",
                recommendation="V√©rifier les donn√©es d'import et les dates de publication"
            )
        elif videos_per_week > 15:  # Plus de 15 vid√©os/semaine = suspect
            return ValidationResult(
                metric_name="Fr√©quence de Publication",
                status=ValidationStatus.WARNING,
                value=f"{videos_per_week:.1f} vid√©os/semaine",
                expected_range="0.1-10 vid√©os/semaine",
                message=f"Fr√©quence tr√®s √©lev√©e: {videos_per_week:.1f} vid√©os/semaine",
                recommendation="V√©rifier s'il s'agit d'une cha√Æne tr√®s active ou de donn√©es incorrectes"
            )
        elif videos_per_week < 0.1:  # Moins d'1 vid√©o tous les 10 semaines
            return ValidationResult(
                metric_name="Fr√©quence de Publication",
                status=ValidationStatus.WARNING,
                value=f"{videos_per_week:.2f} vid√©os/semaine",
                expected_range="0.1-10 vid√©os/semaine",
                message="Fr√©quence tr√®s faible de publication",
                recommendation="Cha√Æne peu active ou donn√©es incompl√®tes"
            )
        else:
            return ValidationResult(
                metric_name="Fr√©quence de Publication",
                status=ValidationStatus.EXCELLENT,
                value=f"{videos_per_week:.1f} vid√©os/semaine",
                expected_range="0.1-10 vid√©os/semaine",
                message=f"Fr√©quence coh√©rente: {videos_per_week:.1f} vid√©os/semaine",
                recommendation="Rythme de publication optimal"
            )
    
    def _validate_hhh_distribution(self, videos: List[sqlite3.Row]) -> ValidationResult:
        """Valide la distribution Hero-Hub-Help."""
        if not videos:
            return ValidationResult(
                metric_name="Distribution HHH",
                status=ValidationStatus.INSUFFICIENT_DATA,
                value="0/0/0%",
                expected_range="Au moins une cat√©gorie > 0%",
                message="Aucune vid√©o pour calculer la distribution HHH",
                recommendation="Importer des vid√©os"
            )
        
        # Compter les cat√©gories
        hero_count = sum(1 for v in videos if v['category'] == 'hero')
        hub_count = sum(1 for v in videos if v['category'] == 'hub')
        help_count = sum(1 for v in videos if v['category'] == 'help')
        uncategorized_count = sum(1 for v in videos if v['category'] is None or v['category'] == '')
        
        total_categorized = hero_count + hub_count + help_count
        total_videos = len(videos)
        
        # Calculer les pourcentages
        if total_categorized > 0:
            hero_pct = (hero_count / total_categorized) * 100
            hub_pct = (hub_count / total_categorized) * 100
            help_pct = (help_count / total_categorized) * 100
            categorized_pct = (total_categorized / total_videos) * 100
        else:
            hero_pct = hub_pct = help_pct = categorized_pct = 0
        
        # Validation
        if total_categorized == 0:
            return ValidationResult(
                metric_name="Distribution HHH",
                status=ValidationStatus.CRITICAL,
                value="0/0/0% (0% cat√©goris√©)",
                expected_range="Au moins une cat√©gorie > 0%",
                message="Aucune vid√©o cat√©goris√©e",
                recommendation="CRITIQUE: Lancer la classification manuelle ou automatique"
            )
        elif categorized_pct < 50:  # Moins de 50% cat√©goris√©
            return ValidationResult(
                metric_name="Distribution HHH",
                status=ValidationStatus.WARNING,
                value=f"{hero_pct:.0f}/{hub_pct:.0f}/{help_pct:.0f}% ({categorized_pct:.0f}% cat√©goris√©)",
                expected_range="Au moins une cat√©gorie > 0%",
                message=f"Seulement {categorized_pct:.0f}% des vid√©os sont cat√©goris√©es",
                recommendation="Terminer la classification des vid√©os restantes"
            )
        elif (hero_pct == 100 and hub_pct == 0 and help_pct == 0) or \
             (hub_pct == 100 and hero_pct == 0 and help_pct == 0) or \
             (help_pct == 100 and hero_pct == 0 and hub_pct == 0):
            return ValidationResult(
                metric_name="Distribution HHH",
                status=ValidationStatus.WARNING,
                value=f"{hero_pct:.0f}/{hub_pct:.0f}/{help_pct:.0f}%",
                expected_range="Distribution √©quilibr√©e",
                message="Distribution mono-cat√©gorie (100% dans une seule cat√©gorie)",
                recommendation="V√©rifier la strat√©gie de contenu - diversification recommand√©e"
            )
        else:
            return ValidationResult(
                metric_name="Distribution HHH",
                status=ValidationStatus.EXCELLENT,
                value=f"{hero_pct:.0f}/{hub_pct:.0f}/{help_pct:.0f}%",
                expected_range="Distribution √©quilibr√©e",
                message=f"Distribution √©quilibr√©e - {categorized_pct:.0f}% cat√©goris√©",
                recommendation="Distribution strat√©gique optimale"
            )
    
    def _validate_organic_vs_paid(self, videos: List[sqlite3.Row]) -> ValidationResult:
        """Valide la distribution Organique vs Pay√©."""
        if not videos:
            return ValidationResult(
                metric_name="Organique vs Pay√©",
                status=ValidationStatus.INSUFFICIENT_DATA,
                value="0/0%",
                expected_range="√âquilibre coh√©rent",
                message="Aucune vid√©o pour calculer la distribution",
                recommendation="Importer des vid√©os"
            )
        
        # Calculer les m√©triques de vues
        videos_with_views = [v for v in videos if v['view_count'] is not None and v['view_count'] > 0]
        
        if not videos_with_views:
            return ValidationResult(
                metric_name="Organique vs Pay√©",
                status=ValidationStatus.CRITICAL,
                value="Pas de donn√©es de vues",
                expected_range="√âquilibre coh√©rent",
                message="Aucune donn√©e de vues disponible",
                recommendation="R√©cup√©rer les donn√©es de vues via l'API YouTube"
            )
        
        # Classifier en pay√©/organique bas√© sur le seuil
        paid_count = sum(1 for v in videos_with_views if v['view_count'] >= self.paid_threshold)
        organic_count = len(videos_with_views) - paid_count
        
        paid_pct = (paid_count / len(videos_with_views)) * 100
        organic_pct = (organic_count / len(videos_with_views)) * 100
        
        # Validation
        if paid_pct == 100:
            return ValidationResult(
                metric_name="Organique vs Pay√©",
                status=ValidationStatus.WARNING,
                value=f"{organic_pct:.0f}/{paid_pct:.0f}%",
                expected_range="√âquilibre coh√©rent",
                message="100% de contenu √† fort impact (possiblement pay√©)",
                recommendation="V√©rifier si le seuil de d√©tection est appropri√©"
            )
        elif organic_pct == 100:
            return ValidationResult(
                metric_name="Organique vs Pay√©",
                status=ValidationStatus.GOOD,
                value=f"{organic_pct:.0f}/{paid_pct:.0f}%",
                expected_range="√âquilibre coh√©rent",
                message="100% de contenu organique",
                recommendation="Strat√©gie organique pure - bon pour l'authenticit√©"
            )
        else:
            return ValidationResult(
                metric_name="Organique vs Pay√©",
                status=ValidationStatus.EXCELLENT,
                value=f"{organic_pct:.0f}/{paid_pct:.0f}%",
                expected_range="√âquilibre coh√©rent",
                message=f"√âquilibre organique/pay√©: {organic_pct:.0f}%/{paid_pct:.0f}%",
                recommendation="Bon √©quilibre entre contenu organique et promotionnel"
            )
    
    def _validate_shorts_distribution(self, videos: List[sqlite3.Row]) -> ValidationResult:
        """Valide la distribution Shorts vs Vid√©os format 16:9."""
        if not videos:
            return ValidationResult(
                metric_name="Shorts vs Vid√©os 16:9",
                status=ValidationStatus.INSUFFICIENT_DATA,
                value="0/0%",
                expected_range="Distribution selon strat√©gie",
                message="Aucune vid√©o pour calculer la distribution",
                recommendation="Importer des vid√©os"
            )
        
        # Compter les Shorts (is_short = 1) vs vid√©os normales
        shorts_count = sum(1 for v in videos if v['is_short'] == 1)
        regular_count = len(videos) - shorts_count
        
        shorts_pct = (shorts_count / len(videos)) * 100
        regular_pct = (regular_count / len(videos)) * 100
        
        # Validation
        if shorts_count == 0 and regular_count == 0:
            return ValidationResult(
                metric_name="Shorts vs Vid√©os 16:9",
                status=ValidationStatus.CRITICAL,
                value="Donn√©es manquantes",
                expected_range="Distribution selon strat√©gie",
                message="Aucune information sur le format des vid√©os",
                recommendation="Mettre √† jour la d√©tection des Shorts dans la base de donn√©es"
            )
        else:
            return ValidationResult(
                metric_name="Shorts vs Vid√©os 16:9",
                status=ValidationStatus.EXCELLENT,
                value=f"{regular_pct:.0f}/{shorts_pct:.0f}%",
                expected_range="Distribution selon strat√©gie",
                message=f"R√©partition: {regular_pct:.0f}% vid√©os 16:9, {shorts_pct:.0f}% Shorts",
                recommendation="Distribution coh√©rente avec la strat√©gie de contenu"
            )
    
    def _validate_thumbnail_consistency(self, videos: List[sqlite3.Row]) -> ValidationResult:
        """Valide la coh√©rence des miniatures."""
        if not videos:
            return ValidationResult(
                metric_name="Coh√©rence des Miniatures",
                status=ValidationStatus.INSUFFICIENT_DATA,
                value="0%",
                expected_range="70-95%",
                message="Aucune vid√©o pour analyser les miniatures",
                recommendation="Importer des vid√©os"
            )
        
        # Compter les vid√©os avec des miniatures
        videos_with_thumbnails = sum(1 for v in videos if v['thumbnail_url'])
        thumbnail_coverage = (videos_with_thumbnails / len(videos)) * 100
        
        # Analyse basique de coh√©rence (placeholder - n√©cessiterait analyse d'image)
        if thumbnail_coverage < 50:
            consistency_score = 0
        elif thumbnail_coverage < 80:
            consistency_score = 50
        else:
            consistency_score = 75  # Score par d√©faut
        
        # Validation
        if consistency_score == 0:
            return ValidationResult(
                metric_name="Coh√©rence des Miniatures",
                status=ValidationStatus.CRITICAL,
                value=f"{consistency_score}%",
                expected_range="70-95%",
                message=f"Miniatures manquantes ({thumbnail_coverage:.0f}% de couverture)",
                recommendation="R√©cup√©rer les URLs des miniatures"
            )
        elif consistency_score < 60:
            return ValidationResult(
                metric_name="Coh√©rence des Miniatures",
                status=ValidationStatus.WARNING,
                value=f"{consistency_score}%",
                expected_range="70-95%",
                message="Coh√©rence visuelle faible des miniatures",
                recommendation="Am√©liorer la coh√©rence du design des miniatures"
            )
        else:
            return ValidationResult(
                metric_name="Coh√©rence des Miniatures",
                status=ValidationStatus.GOOD,
                value=f"{consistency_score}%",
                expected_range="70-95%",
                message="Coh√©rence des miniatures acceptable",
                recommendation="Maintenir la qualit√© visuelle des miniatures"
            )
    
    def _validate_lexical_consistency(self, videos: List[sqlite3.Row]) -> ValidationResult:
        """Valide la coh√©rence du champ lexical et de la tonalit√©."""
        if not videos:
            return ValidationResult(
                metric_name="Champ Lexical",
                status=ValidationStatus.INSUFFICIENT_DATA,
                value="0%",
                expected_range="60-90%",
                message="Aucune vid√©o pour analyser le champ lexical",
                recommendation="Importer des vid√©os"
            )
        
        # Analyser les titres des vid√©os
        titles = [v['title'] for v in videos if v['title']]
        
        if not titles:
            return ValidationResult(
                metric_name="Champ Lexical",
                status=ValidationStatus.CRITICAL,
                value="0%",
                expected_range="60-90%",
                message="Aucun titre de vid√©o disponible",
                recommendation="R√©cup√©rer les titres des vid√©os"
            )
        
        # Analyse basique de coh√©rence lexicale
        total_words = []
        for title in titles:
            words = re.findall(r'\w+', title.lower())
            total_words.extend(words)
        
        if not total_words:
            consistency_score = 0
        else:
            # Calculer la diversit√© lexicale (ratio mots uniques / total)
            unique_words = len(set(total_words))
            lexical_diversity = unique_words / len(total_words)
            
            # Score de coh√©rence bas√© sur la diversit√© (inversement proportionnel)
            # Plus la diversit√© est faible, plus la coh√©rence est √©lev√©e
            consistency_score = max(0, min(100, (1 - lexical_diversity) * 100))
        
        # Validation
        if consistency_score < 40:
            return ValidationResult(
                metric_name="Champ Lexical",
                status=ValidationStatus.WARNING,
                value=f"{consistency_score:.0f}%",
                expected_range="60-90%",
                message="Champ lexical tr√®s dispers√©",
                recommendation="Harmoniser le vocabulaire et la tonalit√© des titres"
            )
        elif consistency_score > 90:
            return ValidationResult(
                metric_name="Champ Lexical",
                status=ValidationStatus.WARNING,
                value=f"{consistency_score:.0f}%",
                expected_range="60-90%",
                message="Champ lexical trop r√©p√©titif",
                recommendation="Diversifier le vocabulaire pour √©viter la r√©p√©tition"
            )
        else:
            return ValidationResult(
                metric_name="Champ Lexical",
                status=ValidationStatus.EXCELLENT,
                value=f"{consistency_score:.0f}%",
                expected_range="60-90%",
                message="Coh√©rence lexicale optimale",
                recommendation="Maintenir cette coh√©rence de vocabulaire"
            )
    
    def _validate_top_performing_subject(self, videos: List[sqlite3.Row]) -> ValidationResult:
        """Valide l'existence d'un sujet le plus appr√©ci√©."""
        if not videos:
            return ValidationResult(
                metric_name="Sujet le Plus Appr√©ci√©",
                status=ValidationStatus.INSUFFICIENT_DATA,
                value="Aucun",
                expected_range="Sujet identifiable",
                message="Aucune vid√©o pour identifier le sujet performant",
                recommendation="Importer des vid√©os"
            )
        
        # Filtrer les vid√©os avec des m√©triques d'engagement
        videos_with_metrics = [
            v for v in videos 
            if v['view_count'] is not None and v['like_count'] is not None
            and v['view_count'] > 0
        ]
        
        if not videos_with_metrics:
            return ValidationResult(
                metric_name="Sujet le Plus Appr√©ci√©",
                status=ValidationStatus.CRITICAL,
                value="Donn√©es manquantes",
                expected_range="Sujet identifiable",
                message="Aucune donn√©e d'engagement disponible",
                recommendation="R√©cup√©rer les m√©triques de vues et likes"
            )
        
        # Trouver la vid√©o avec le meilleur engagement
        best_video = max(
            videos_with_metrics, 
            key=lambda v: (v['like_count'] or 0) / max(v['view_count'], 1)
        )
        
        best_title = best_video['title'] if best_video['title'] else 'Sans titre'
        engagement_rate = (best_video['like_count'] or 0) / max(best_video['view_count'], 1) * 100
        
        # Validation
        if not best_title or best_title == 'Sans titre':
            return ValidationResult(
                metric_name="Sujet le Plus Appr√©ci√©",
                status=ValidationStatus.CRITICAL,
                value="Titre manquant",
                expected_range="Sujet identifiable",
                message="Vid√©o performante sans titre",
                recommendation="R√©cup√©rer les titres des vid√©os"
            )
        elif engagement_rate < 0.1:  # Moins de 0.1% d'engagement
            return ValidationResult(
                metric_name="Sujet le Plus Appr√©ci√©",
                status=ValidationStatus.WARNING,
                value=f"'{best_title[:50]}...' ({engagement_rate:.2f}%)",
                expected_range="Engagement > 1%",
                message="Faible engagement sur le contenu le plus performant",
                recommendation="Analyser pourquoi l'engagement est faible"
            )
        else:
            return ValidationResult(
                metric_name="Sujet le Plus Appr√©ci√©",
                status=ValidationStatus.EXCELLENT,
                value=f"'{best_title[:50]}...' ({engagement_rate:.2f}%)",
                expected_range="Engagement > 1%",
                message="Sujet performant identifi√© avec bon engagement",
                recommendation="Capitaliser sur ce type de contenu"
            )
    
    def _determine_overall_status(self, metrics_results: List[ValidationResult]) -> ValidationStatus:
        """D√©termine le statut global bas√© sur tous les r√©sultats de m√©triques."""
        status_counts = {}
        for result in metrics_results:
            status = result.status
            status_counts[status] = status_counts.get(status, 0) + 1
        
        # R√®gles de d√©cision
        if status_counts.get(ValidationStatus.CRITICAL, 0) >= 3:
            return ValidationStatus.CRITICAL
        elif status_counts.get(ValidationStatus.CRITICAL, 0) >= 1:
            return ValidationStatus.WARNING
        elif status_counts.get(ValidationStatus.WARNING, 0) >= 4:
            return ValidationStatus.WARNING
        elif status_counts.get(ValidationStatus.EXCELLENT, 0) >= 6:
            return ValidationStatus.EXCELLENT
        else:
            return ValidationStatus.GOOD
    
    def _generate_summary(self, overall_status: ValidationStatus, total_videos: int, 
                         critical_count: int, warning_count: int) -> str:
        """G√©n√®re un r√©sum√© textuel du statut de validation."""
        status_messages = {
            ValidationStatus.EXCELLENT: "üü¢ Toutes les m√©triques sont excellentes",
            ValidationStatus.GOOD: "üü° M√©triques majoritairement bonnes",
            ValidationStatus.WARNING: "üü† Probl√®mes de coh√©rence d√©tect√©s", 
            ValidationStatus.CRITICAL: "üî¥ M√©triques critiques invalides",
            ValidationStatus.INSUFFICIENT_DATA: "‚ö™ Donn√©es insuffisantes"
        }
        
        base_message = status_messages.get(overall_status, "Statut inconnu")
        details = f" - {total_videos} vid√©os"
        
        if critical_count > 0:
            details += f", {critical_count} probl√®me(s) critique(s)"
        if warning_count > 0:
            details += f", {warning_count} alerte(s)"
            
        return base_message + details
    
    def generate_validation_report(self, reports: List[CompetitorValidationReport]) -> str:
        """G√©n√®re un rapport complet de validation au format markdown."""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # Statistiques globales
        total_competitors = len(reports)
        powerpoint_ready = sum(1 for r in reports if r.powerpoint_ready)
        critical_competitors = sum(1 for r in reports if r.overall_status == ValidationStatus.CRITICAL)
        excellent_competitors = sum(1 for r in reports if r.overall_status == ValidationStatus.EXCELLENT)
        
        report = f"""# üìä Rapport de Validation des Key Metrics
**Date de g√©n√©ration :** {timestamp}
**Competitors analys√©s :** {total_competitors}

## üéØ R√©sum√© Ex√©cutif

- **‚úÖ Pr√™ts pour PowerPoint :** {powerpoint_ready}/{total_competitors} ({powerpoint_ready/total_competitors*100:.0f}%)
- **üü¢ Excellents :** {excellent_competitors} competitors
- **üî¥ Critiques :** {critical_competitors} competitors n√©cessitent une intervention

## üìà D√©tails par Competitor

"""

        # Grouper par pays
        competitors_by_country = {}
        for report_item in reports:
            country = report_item.country or "Non sp√©cifi√©"
            if country not in competitors_by_country:
                competitors_by_country[country] = []
            competitors_by_country[country].append(report_item)
        
        for country, country_reports in competitors_by_country.items():
            report += f"\n### üåç {country}\n\n"
            
            for comp_report in country_reports:
                status_emoji = {
                    ValidationStatus.EXCELLENT: "üü¢",
                    ValidationStatus.GOOD: "üü°", 
                    ValidationStatus.WARNING: "üü†",
                    ValidationStatus.CRITICAL: "üî¥",
                    ValidationStatus.INSUFFICIENT_DATA: "‚ö™"
                }.get(comp_report.overall_status, "‚ùì")
                
                powerpoint_status = "‚úÖ" if comp_report.powerpoint_ready else "‚ùå"
                
                report += f"#### {status_emoji} {comp_report.competitor_name} {powerpoint_status}\n"
                report += f"**Statut :** {comp_report.summary}\n\n"
                
                # M√©triques d√©taill√©es
                report += "**M√©triques :**\n"
                for metric in comp_report.metrics_results:
                    metric_emoji = {
                        ValidationStatus.EXCELLENT: "‚úÖ",
                        ValidationStatus.GOOD: "‚úÖ",
                        ValidationStatus.WARNING: "‚ö†Ô∏è",
                        ValidationStatus.CRITICAL: "‚ùå",
                        ValidationStatus.INSUFFICIENT_DATA: "‚ùì"
                    }.get(metric.status, "‚ùì")
                    
                    report += f"- {metric_emoji} **{metric.metric_name}:** {metric.value} - {metric.message}\n"
                
                # Probl√®mes critiques
                if comp_report.critical_issues:
                    report += "\n**üö® Probl√®mes critiques :**\n"
                    for issue in comp_report.critical_issues:
                        report += f"- {issue}\n"
                
                # Recommandations principales
                critical_metrics = [m for m in comp_report.metrics_results if m.status == ValidationStatus.CRITICAL]
                if critical_metrics:
                    report += "\n**üîß Actions prioritaires :**\n"
                    for metric in critical_metrics:
                        report += f"- {metric.recommendation}\n"
                
                report += "\n---\n"
        
        # Recommandations globales
        report += f"""
## üîß Recommandations Globales

### Probl√®mes les plus fr√©quents :
1. **Dates de publication corrompues** - Utiliser l'agent de correction des dates YouTube
2. **Vid√©os non cat√©goris√©es** - Compl√©ter la classification Hero/Hub/Help
3. **Donn√©es de vues manquantes** - Rafra√Æchir via l'API YouTube

### Actions imm√©diates :
1. Corriger les {critical_competitors} competitors critiques avant PowerPoint
2. Mettre √† jour les donn√©es manquantes pour {total_competitors - powerpoint_ready} competitors
3. Valider manuellement les m√©triques suspectes

### Prochaines √©tapes :
1. Re-lancer la validation apr√®s corrections
2. Automatiser la surveillance des m√©triques
3. Int√©grer la validation dans le pipeline de donn√©es
"""

        return report
    
    def save_report_to_file(self, reports: List[CompetitorValidationReport], 
                           filename: str = None) -> str:
        """Sauvegarde le rapport dans un fichier."""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"key_metrics_validation_report_{timestamp}.md"
        
        report_content = self.generate_validation_report(reports)
        
        filepath = PROJECT_ROOT / filename
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        logger.info(f"üìÑ Rapport sauvegard√© dans {filepath}")
        return str(filepath)


def main():
    """Fonction principale pour lancer la validation compl√®te."""
    logger.info("üöÄ D√©marrage de l'agent de validation des Key Metrics")
    
    try:
        # Cr√©er l'agent de validation
        validator = KeyMetricsValidator()
        
        # Valider tous les competitors
        reports = validator.validate_all_competitors()
        
        # G√©n√©rer et sauvegarder le rapport
        report_file = validator.save_report_to_file(reports)
        
        # Statistiques finales
        total = len(reports)
        powerpoint_ready = sum(1 for r in reports if r.powerpoint_ready)
        critical = sum(1 for r in reports if r.overall_status == ValidationStatus.CRITICAL)
        
        logger.info(f"‚úÖ Validation termin√©e !")
        logger.info(f"üìä {powerpoint_ready}/{total} competitors pr√™ts pour PowerPoint")
        logger.info(f"üî¥ {critical} competitors n√©cessitent une intervention critique")
        logger.info(f"üìÑ Rapport d√©taill√© : {report_file}")
        
        return reports, report_file
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la validation : {e}")
        raise


if __name__ == "__main__":
    main()